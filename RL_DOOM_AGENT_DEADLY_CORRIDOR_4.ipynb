{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12fc83a-bd4b-4157-897d-f6774342f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import vizdoom as vzd\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb647e0-6368-4af8-816b-8ea3caf011d3",
   "metadata": {},
   "source": [
    "# SETUP-GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15493055-d156-464b-a203-8dbf12e75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config(r'./scenarios/deadly_corridor-skill-4.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47bd952-7230-418f-90eb-ba3a6ea570b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "actions = np.identity(7, dtype=np.uint8)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840aeaf7-c157-4b3e-90e8-770464c9de85",
   "metadata": {},
   "source": [
    "1. actions[0] : MOVE_LEFT\n",
    "2. actions[1] : MOVE_RIGHT\n",
    "3. actions[2] : ATTACK\n",
    "4. actions[3] : MOVE_FORWARD\n",
    "5. actions[4] : MOVE_BACKWARD\n",
    "6. actions[5] : TURN_LEFT\n",
    "7. actions[6] : TURN_RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd199ad-9ef9-4ad8-996e-4e75ca491654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.new_episode()\n",
    "game.is_episode_finished()\n",
    "game.make_action(random.choice(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2065135d-48a4-46bc-bf99-b2ee30a3ad1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "ammo [100.   0.  -1.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CE7B0>\n",
      "reward: -0.78125\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E58EE70>\n",
      "reward: -2.458099365234375\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: -1.6581268310546875\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CE7B0>\n",
      "reward: -1.1185302734375\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7E30>\n",
      "reward: -0.7545623779296875\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B054976030>\n",
      "reward: -0.5091094970703125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CE7B0>\n",
      "reward: 6.606719970703125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE0B0>\n",
      "reward: 8.106048583984375\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B054976330>\n",
      "reward: 5.4675750732421875\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CE7B0>\n",
      "reward: 3.6878814697265625\n",
      "ammo [100.   1.  24.   1.   0.   5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: 2.4874114990234375\n",
      "ammo [100.   1.  24.   1.   0.   5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B054976330>\n",
      "reward: 8.737091064453125\n",
      "ammo [100.   1.  24.   1.   0.   5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CE7B0>\n",
      "reward: 8.764358520507812\n",
      "ammo [100.   1.  24.   1.   0.   5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE030>\n",
      "reward: 5.4726104736328125\n",
      "ammo [100.   1.  24.   1.   0.   5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE570>\n",
      "reward: -15.0291748046875\n",
      "ammo [100.   1.  24.   1.   0.   5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CE7B0>\n",
      "reward: -15.245941162109375\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0546BE530>\n",
      "reward: -13.316665649414062\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE570>\n",
      "reward: -10.575103759765625\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CE7B0>\n",
      "reward: -3.824951171875\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE570>\n",
      "reward: 6.6626129150390625\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DEA30>\n",
      "reward: 7.849212646484375\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 5.7332763671875\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE570>\n",
      "reward: 3.8671112060546875\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -4.5054168701171875\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: -13.888504028320312\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE570>\n",
      "reward: -5.6695709228515625\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: 0.8306884765625\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 0.9964752197265625\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 0.6720123291015625\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: 0.453155517578125\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: -3.0350189208984375\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -192.9406280517578\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE6B0>\n",
      "////////////////// Result: -208.91641235351562\n",
      "reward: 0.0\n",
      "ammo [100.   0.  -1.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 0.0\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: -7.11376953125\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE6B0>\n",
      "reward: -8.534164428710938\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: -0.300262451171875\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DEC70>\n",
      "reward: -0.0046844482421875\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE6B0>\n",
      "reward: -0.039398193359375\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5A94F0>\n",
      "reward: 0.0\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DEC70>\n",
      "reward: 0.0\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 6.354736328125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5A94F0>\n",
      "reward: 9.203842163085938\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0549770F0>\n",
      "reward: 7.076690673828125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 7.2260894775390625\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: 12.15716552734375\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0549770F0>\n",
      "reward: 10.437820434570312\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: -8.721527099609375\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B054976070>\n",
      "reward: -6.15545654296875\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B054976330>\n",
      "reward: 0.7542572021484375\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 2.1652679443359375\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B054976070>\n",
      "reward: 1.46044921875\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DEC70>\n",
      "reward: -4.77197265625\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: -11.585678100585938\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B054976070>\n",
      "reward: -10.614273071289062\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DEC70>\n",
      "reward: -7.1596221923828125\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: -7.7670745849609375\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D6730>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: -0.0616455078125\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AB530>\n",
      "reward: -0.000213623046875\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: -200.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AB530>\n",
      "////////////////// Result: -215.99342346191406\n",
      "reward: 0.0\n",
      "ammo [100.   0.  -1.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -0.78125\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF270>\n",
      "reward: -2.458099365234375\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: -1.6581268310546875\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -8.1781005859375\n",
      "ammo [100.   0.  26.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF270>\n",
      "reward: -2.84918212890625\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: -0.069549560546875\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AB530>\n",
      "reward: 1.6591796875\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF270>\n",
      "reward: 1.9903564453125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: 7.977386474609375\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AB530>\n",
      "reward: 11.322738647460938\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 8.927886962890625\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: 5.9815521240234375\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AB530>\n",
      "reward: -2.4768829345703125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 3.1076202392578125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: -13.22784423828125\n",
      "ammo [100.   0.  25.   0.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: -14.017044067382812\n",
      "ammo [40.  0. 25.  0. 60.  0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -11.160369873046875\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: -0.08251953125\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: -0.0030059814453125\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: 0.976959228515625\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DE5F0>\n",
      "reward: -0.957855224609375\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: 0.0\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: -0.01885986328125\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B05486F670>\n",
      "reward: 6.948944091796875\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: 6.876068115234375\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: 9.887237548828125\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B05486F670>\n",
      "reward: 2.8600616455078125\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: -1.72021484375\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -1.1604156494140625\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: -7.4935150146484375\n",
      "ammo [40.  1. 24.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: -10.83990478515625\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -5.34759521484375\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: 5.5193328857421875\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: 6.9261322021484375\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: 6.1269378662109375\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B05486F670>\n",
      "reward: 4.89678955078125\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: 3.3028411865234375\n",
      "ammo [40.  1. 23.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: 2.2277069091796875\n",
      "ammo [40.  1. 22.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B05486F670>\n",
      "reward: 3.7266082763671875\n",
      "ammo [40.  1. 22.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: -1.48541259765625\n",
      "ammo [40.  1. 22.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -2.189483642578125\n",
      "ammo [40.  1. 22.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DCE70>\n",
      "reward: -8.554214477539062\n",
      "ammo [40.  1. 22.  1. 60.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: -8.139984130859375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -0.405548095703125\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1D7630>\n",
      "reward: 3.3755340576171875\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0547FCE70>\n",
      "reward: -0.1139984130859375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -3.2930755615234375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1D7630>\n",
      "reward: 3.318359375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0547FCE70>\n",
      "reward: 5.5549163818359375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: 0.6767425537109375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: 5.0258636474609375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0547FCE70>\n",
      "reward: 4.5726318359375\n",
      "ammo [22.  1. 22.  1. 78.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -1.769439697265625\n",
      "ammo [ 4.  1. 22.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: -1.193634033203125\n",
      "ammo [ 4.  1. 21.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: 0.0306396484375\n",
      "ammo [ 4.  1. 21.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -0.376495361328125\n",
      "ammo [ 4.  1. 21.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: -0.6930694580078125\n",
      "ammo [ 4.  1. 21.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548DDD30>\n",
      "reward: -7.527191162109375\n",
      "ammo [ 4.  1. 21.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -8.784576416015625\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: -4.2662353515625\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0547FCE70>\n",
      "reward: -2.0064697265625\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: -0.5176544189453125\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: 0.76593017578125\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0547FCE70>\n",
      "reward: 7.9254302978515625\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: 1.993316650390625\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: 4.69659423828125\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 13.934463500976562\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0548D7730>\n",
      "reward: 12.270111083984375\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: 8.673126220703125\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF7F0>\n",
      "reward: 6.2889862060546875\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5ABF30>\n",
      "reward: 4.2418975830078125\n",
      "ammo [ 4.  1. 20.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: 2.8610687255859375\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF7F0>\n",
      "reward: -5.1840667724609375\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5ABF30>\n",
      "reward: -5.9413604736328125\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: -0.8780670166015625\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -0.5923614501953125\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5ABF30>\n",
      "reward: -0.3996429443359375\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5AAB30>\n",
      "reward: 0.77362060546875\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: 1.069610595703125\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5ABF30>\n",
      "reward: 2.58306884765625\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF7F0>\n",
      "reward: 1.9776611328125\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -0.285919189453125\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E5ABF30>\n",
      "reward: -0.7408905029296875\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF7F0>\n",
      "reward: -0.4998779296875\n",
      "ammo [ 4.  1. 19.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1DEAF0>\n",
      "reward: -0.337310791015625\n",
      "ammo [ 4.  1. 18.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B0547FCE70>\n",
      "reward: -200.17881774902344\n",
      "ammo [ 4.  1. 18.  1. 96.  5.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001B03E1CF7F0>\n",
      "////////////////// Result: -157.0032196044922\n"
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "for e in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        satate=game.get_state()\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - ammo\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions),4) # frame skip=4 time for agent to process\n",
    "        print('reward:', reward) \n",
    "        print(\"ammo\",info)\n",
    "        print(\"state\",state)\n",
    "        time.sleep(0.02)\n",
    "    print('////////////////// Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f85591b-2316-427f-abf2-547235c29511",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1caf887e-2ffa-4a19-b0db-3e1819022ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d09d280e-917b-4046-a12f-8c66c105997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(Env):\n",
    "    def __init__(self, render=False,config='./scenarios/deadly_corridor-skill-4.cfg'):\n",
    "        super().__init__()\n",
    "        self.game = vzd.DoomGame()\n",
    "        self.game.load_config(config)\n",
    "\n",
    "        # Render frame logic\n",
    "        if not render:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        self.game.init()\n",
    "\n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(7)  # 7 possible actions\n",
    "        self.actions=np.identity(7, dtype=np.float32)\n",
    "        \n",
    "\n",
    "\n",
    "    def custom_reward(self, prev_state, current_state):\n",
    "        reward = 0\n",
    "    \n",
    "        # Extract game variables\n",
    "        prev_health = prev_state.game_variables[0]  # HEALTH\n",
    "        prev_hits = prev_state.game_variables[1]  # HITCOUNT\n",
    "        prev_ammo = prev_state.game_variables[2]  # SELECTED_WEAPON_AMMO\n",
    "        prev_kills = prev_state.game_variables[3]  # KILLCOUNT\n",
    "        prev_dmg = prev_state.game_variables[4]  # KILLCOUNT\n",
    "        prev_dmg_deal = prev_state.game_variables[5]  # KILLCOUNT\n",
    "        \n",
    "        current_health = current_state.game_variables[0]  # HEALTH\n",
    "        current_hits = current_state.game_variables[1]  # HITCOUNT\n",
    "        current_ammo = current_state.game_variables[2]  # SELECTED_WEAPON_AMMO\n",
    "        current_kills = current_state.game_variables[3]  # KILLCOUNT\n",
    "        current_dmg = current_state.game_variables[4]  # KILLCOUNT\n",
    "        current_dmg_deal = current_state.game_variables[5]  # KILLCOUNT\n",
    "        \n",
    "        ammo_delta=current_ammo-prev_ammo \n",
    "        hitcount_delta= current_dmg_deal - prev_dmg_deal\n",
    "        damage_taken_delta=-current_dmg+prev_dmg\n",
    "        \n",
    "        reward = damage_taken_delta*60 + hitcount_delta*200  + ammo_delta*50 \n",
    "        \n",
    "    \n",
    "\n",
    "        return reward\n",
    "        \n",
    "    def step(self, action):\n",
    "        prev_state = self.game.get_state()  # Store the previous state\n",
    "        reward = self.game.make_action(self.actions[action], 4)  # Default reward\n",
    "        current_state = self.game.get_state()  # Get the current state\n",
    "\n",
    "        # Compute custom reward\n",
    "        if prev_state is not None and current_state is not None:\n",
    "            reward += self.custom_reward(prev_state, current_state)\n",
    "\n",
    "        terminated = self.game.is_episode_finished()\n",
    "        truncated = self.game.get_episode_time() >= self.game.get_episode_timeout()\n",
    "\n",
    "        state = np.zeros(self.observation_space.shape, dtype=np.uint8)  # Default blank state\n",
    "        info = {\"ammo\": 0}  # Default info\n",
    "\n",
    "        if not (terminated or truncated):\n",
    "            game_state = self.game.get_state()\n",
    "            if game_state is not None:\n",
    "                state = self.grayscale(game_state.screen_buffer)\n",
    "                info = {\"ammo\": game_state.game_variables[0]}\n",
    "\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Restart the game and return the initial state.\"\"\"\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state), {}\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        \"\"\"Convert the observation to grayscale and resize it.\"\"\"\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))\n",
    "        return state\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the game.\"\"\"\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236d716c-593f-4734-a553-cdc2ada4930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6db91-fe8e-4e62-bec1-1eb3677dc435",
   "metadata": {},
   "source": [
    "### Testing the model \n",
    "`./train/train_Deadly_Corridor_COMP_5_S_3/best_model_50000.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95c46d6-1407-4b3e-8328-4cd59169cc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 8848.961502075195\n",
      "Episode 2: Total Reward = 8510.800674438477\n",
      "Episode 3: Total Reward = 5338.528274536133\n",
      "Episode 4: Total Reward = 5146.283798217773\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP_5_S_3/best_model_50000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13699a9b-3a24-482a-8978-d6fefcfd21b5",
   "metadata": {},
   "source": [
    "**The agent is doing surprisingly well -- but it need more training** \n",
    "<br>\n",
    "*new reward:*<br>\n",
    "`damage_taken_delta*55 + hitcount_delta*200  + ammo_delta*45 ` <br>\n",
    "*old reward:*<br>\n",
    "`damage_taken_delta*60 + hitcount_delta*200  + ammo_delta*50 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e43627cd-2e12-41f7-a9fc-f7f275a5fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_Deadly_Corridor_COMP_5_S_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3ef85ed-06da-4a1d-be06-2e74438a4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n",
    "env=VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d739681e-fdd4-4747-8356-9e33242c96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_path = \"./train/train_Deadly_Corridor_COMP_5_S_3/best_model_50000.zip\"  \n",
    "model = PPO.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "510260a7-bd77-40c1-94d2-d88dcd8df3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_Deadly_Corridor\\PPO_16\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 140      |\n",
      "|    ep_rew_mean     | 9.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 656      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 9.64e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1318        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011291652 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.894      |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.4e+05     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    value_loss           | 4.82e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 124         |\n",
      "|    ep_rew_mean          | 9.74e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1991        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014337247 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.821      |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.97e+05    |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    value_loss           | 6.03e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 118         |\n",
      "|    ep_rew_mean          | 9.62e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2662        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012278922 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.65e+05    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 5.15e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 117         |\n",
      "|    ep_rew_mean          | 9.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3333        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015115671 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.12e+05    |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.0151      |\n",
      "|    value_loss           | 5.63e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 1.02e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4005        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008704997 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.92e+05    |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    value_loss           | 4.91e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 126        |\n",
      "|    ep_rew_mean          | 9.93e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 4655       |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01743596 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.776     |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 1.74e+05   |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | 0.014      |\n",
      "|    value_loss           | 5.01e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 131         |\n",
      "|    ep_rew_mean          | 1.07e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 5310        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011770698 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.03e+05    |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    value_loss           | 5.01e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 134          |\n",
      "|    ep_rew_mean          | 1.07e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 6030         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123305535 |\n",
      "|    clip_fraction        | 0.309        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.802       |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.34e+05     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | 0.0112       |\n",
      "|    value_loss           | 4.64e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 138         |\n",
      "|    ep_rew_mean          | 1.03e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 6738        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014707305 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.822      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.57e+05    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | 0.0149      |\n",
      "|    value_loss           | 4.57e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 1.02e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 7521        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010032708 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.02e+05    |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | 0.00926     |\n",
      "|    value_loss           | 4.71e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 133         |\n",
      "|    ep_rew_mean          | 1.12e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 8386        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011627521 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.51e+05    |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | 0.00934     |\n",
      "|    value_loss           | 4.58e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 136         |\n",
      "|    ep_rew_mean          | 1.2e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 9053        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012525436 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.818      |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.17e+05    |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | 0.0145      |\n",
      "|    value_loss           | 4.64e+05    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)\n",
    "model.learn(total_timesteps=100000, callback=callback)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551be19-8877-4b1d-89ff-7ae190673f29",
   "metadata": {},
   "source": [
    "##### **Testing the model `./train/train_Deadly_Corridor_COMP_5_S_4/best_model_100000.zip`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac03402f-e229-4153-9eb6-e5b61213fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 13780.956329345703\n",
      "Episode 2: Total Reward = 8869.434326171875\n",
      "Episode 3: Total Reward = -793.1803436279297\n",
      "Episode 4: Total Reward = 14877.097183227539\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP_5_S_4/best_model_100000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c111ee-9cbd-4213-88e4-b1664f469d2c",
   "metadata": {},
   "source": [
    "# The agent is excellent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa57e5-a3e4-4754-9396-936d7e98b94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
