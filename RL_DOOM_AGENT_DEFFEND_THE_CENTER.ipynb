{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840aeaf7-c157-4b3e-90e8-770464c9de85",
   "metadata": {},
   "source": [
    "## ENVIROMENT: DEFEND THE CENTER\n",
    "\n",
    "The map is a **large circle**. A player is spawned in the exact center. 5 melee-only, monsters are spawned along the wall. Monsters are killed after a single shot. After dying, each monster is respawned after some time. The **episode ends when the player dies (itâ€™s inevitable because of limited ammo)**.\n",
    "\n",
    "<img src=\"./DEFEND_THE_CENTER.png\"/>\n",
    "\n",
    "configuration File: `defend_the_center.cfg`<br>\n",
    "**REWARD:**\n",
    "- +1 for killing a monster\n",
    "- -1 for death<br>\n",
    "\n",
    "**AVAILABLE MOVES:**\n",
    "1. actions[0] : TURN_LEFT `[1 0 0]`\n",
    "2. actions[1] : TURN_RIGHT `[0 1 0]`\n",
    "3. actions[2] : ATTACK `[0 0 1]`<br>\n",
    "\n",
    "**difficulty level:** `doom_skill` = 3<br>\n",
    "**AMMO:** 26<br>\n",
    "**HEALTH:** 100%<br>\n",
    "**SHILD:** 0<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c12fc83a-bd4b-4157-897d-f6774342f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb647e0-6368-4af8-816b-8ea3caf011d3",
   "metadata": {},
   "source": [
    "# SETUP-GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15493055-d156-464b-a203-8dbf12e75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config(r'./scenarios/defend_the_center.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47bd952-7230-418f-90eb-ba3a6ea570b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "actions = np.identity(3, dtype=np.uint8)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd199ad-9ef9-4ad8-996e-4e75ca491654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.new_episode()\n",
    "game.is_episode_finished()\n",
    "game.make_action(random.choice(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2065135d-48a4-46bc-bf99-b2ee30a3ad1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12294B0>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1228430>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B330>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12294B0>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1228430>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B330>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12287B0>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE402B0>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B330>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12287B0>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE402B0>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12287B0>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE402B0>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE402B0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE402B0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B8F0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE402B0>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B8F0>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B8F0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [ 19. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE30BB0>\n",
      "reward: 0.0\n",
      "ammo [ 19. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 19. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE30BB0>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE325F0>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10126F0>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE325F0>\n",
      "reward: 0.0\n",
      "ammo [ 17. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10126F0>\n",
      "reward: 0.0\n",
      "ammo [ 17. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [17. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [16. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10126F0>\n",
      "reward: 0.0\n",
      "ammo [16. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE307B0>\n",
      "reward: 0.0\n",
      "ammo [16. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [16. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122AA30>\n",
      "reward: 0.0\n",
      "ammo [15. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12326F0>\n",
      "reward: 0.0\n",
      "ammo [15. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [15. 80.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122AA30>\n",
      "reward: 0.0\n",
      "ammo [15. 80.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12326F0>\n",
      "reward: 0.0\n",
      "ammo [15. 80.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [15. 80.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122AA30>\n",
      "reward: 0.0\n",
      "ammo [14. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12326F0>\n",
      "reward: 0.0\n",
      "ammo [14. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [14. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [14. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12326F0>\n",
      "reward: 0.0\n",
      "ammo [14. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: -1.0\n",
      "ammo [14. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "////////////////// Result: -1.0\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47670>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47670>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47670>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47670>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B2B0>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B2B0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B2B0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B2B0>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B930>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B930>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 1.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 19. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B930>\n",
      "reward: 0.0\n",
      "ammo [ 19. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 19. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33730>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33730>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B930>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 18. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33730>\n",
      "reward: 0.0\n",
      "ammo [ 17. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B930>\n",
      "reward: 0.0\n",
      "ammo [ 17. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 17. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BFB0>\n",
      "reward: 0.0\n",
      "ammo [ 16. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B930>\n",
      "reward: 0.0\n",
      "ammo [ 16. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [16. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [16. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [15. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [15. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [15. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [14. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [14. 88.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [14. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [14. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [13. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [13. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [13. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 1.0\n",
      "ammo [13. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E570>\n",
      "reward: 0.0\n",
      "ammo [12. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [12. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233E30>\n",
      "reward: 0.0\n",
      "ammo [12. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [12. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [12. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233E30>\n",
      "reward: 0.0\n",
      "ammo [12. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE7B770>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233E30>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE47DB0>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233E30>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233E30>\n",
      "reward: 0.0\n",
      "ammo [11. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [10. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [10. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [10. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 9. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1186E30>\n",
      "reward: 0.0\n",
      "ammo [ 9. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [ 9. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 9. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 9. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [ 9. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 8. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 8. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE44DB0>\n",
      "reward: 0.0\n",
      "ammo [ 8. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F670>\n",
      "reward: 0.0\n",
      "ammo [ 7. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 7. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE44DB0>\n",
      "reward: 0.0\n",
      "ammo [ 7. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 7. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 7. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE44DB0>\n",
      "reward: 0.0\n",
      "ammo [ 7. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 7. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [ 6. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B770>\n",
      "reward: 0.0\n",
      "ammo [ 6. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 6. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [ 6. 56.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B770>\n",
      "reward: 0.0\n",
      "ammo [ 6. 56.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 5. 56.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE44DB0>\n",
      "reward: 0.0\n",
      "ammo [ 5. 56.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122B770>\n",
      "reward: 0.0\n",
      "ammo [ 5. 56.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 5. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE44DB0>\n",
      "reward: 0.0\n",
      "ammo [ 5. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [ 5. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 4. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE44DB0>\n",
      "reward: 0.0\n",
      "ammo [ 4. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [ 4. 40.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 4. 26.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BFB0>\n",
      "reward: 0.0\n",
      "ammo [ 3. 26.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE51730>\n",
      "reward: 0.0\n",
      "ammo [ 3. 26.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: 0.0\n",
      "ammo [ 3. 26.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BFB0>\n",
      "reward: 0.0\n",
      "ammo [3. 8.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10134F0>\n",
      "reward: 0.0\n",
      "ammo [2. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5EE30>\n",
      "reward: -1.0\n",
      "ammo [2. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BFB0>\n",
      "////////////////// Result: 1.0\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10134F0>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1184F70>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10134F0>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1184F70>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BFB0>\n",
      "reward: 0.0\n",
      "ammo [ 26. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1184F70>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BFB0>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BFB0>\n",
      "reward: 0.0\n",
      "ammo [ 25. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 24. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE33E30>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A0FB9970>\n",
      "reward: 0.0\n",
      "ammo [ 23. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1195AF0>\n",
      "reward: 0.0\n",
      "ammo [ 22. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1195AF0>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 21. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10B3FB0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 20. 100.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AA49D70>\n",
      "reward: 0.0\n",
      "ammo [20. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10B3FB0>\n",
      "reward: 0.0\n",
      "ammo [20. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [19. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [19. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10B3FB0>\n",
      "reward: 0.0\n",
      "ammo [19. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 1.0\n",
      "ammo [19. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [18. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10B3FB0>\n",
      "reward: 0.0\n",
      "ammo [18. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE3DB30>\n",
      "reward: 0.0\n",
      "ammo [18. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [18. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10B3FB0>\n",
      "reward: 0.0\n",
      "ammo [18. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE3DB30>\n",
      "reward: 0.0\n",
      "ammo [17. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [17. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [17. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE3DB30>\n",
      "reward: 0.0\n",
      "ammo [17. 68.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [17. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [17. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [17. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [17. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [17. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [17. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [16. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [16. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [16. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 1.0\n",
      "ammo [16. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [15. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A107ED70>\n",
      "reward: 0.0\n",
      "ammo [15. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [15. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [15. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A107ED70>\n",
      "reward: 0.0\n",
      "ammo [15. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [14. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [14. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F6B0>\n",
      "reward: 0.0\n",
      "ammo [14. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A10CDFB0>\n",
      "reward: 0.0\n",
      "ammo [14. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [13. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F6B0>\n",
      "reward: 0.0\n",
      "ammo [13. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [13. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [13. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F6B0>\n",
      "reward: 0.0\n",
      "ammo [13. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [13. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [13. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E9B0>\n",
      "reward: 0.0\n",
      "ammo [12. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [12. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1233FB0>\n",
      "reward: 0.0\n",
      "ammo [12. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E9B0>\n",
      "reward: 0.0\n",
      "ammo [11. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [11. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1127530>\n",
      "reward: 0.0\n",
      "ammo [11. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE4ED70>\n",
      "reward: 0.0\n",
      "ammo [11. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [10. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A1127530>\n",
      "reward: 0.0\n",
      "ammo [10. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE4ED70>\n",
      "reward: 0.0\n",
      "ammo [10. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 9. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE31030>\n",
      "reward: 0.0\n",
      "ammo [ 9. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122F530>\n",
      "reward: 0.0\n",
      "ammo [ 9. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 9. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE31030>\n",
      "reward: 0.0\n",
      "ammo [ 8. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122F530>\n",
      "reward: 0.0\n",
      "ammo [ 8. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 8. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BE30>\n",
      "reward: 0.0\n",
      "ammo [ 8. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122F530>\n",
      "reward: 0.0\n",
      "ammo [ 8. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 8. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BE30>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE4ED70>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122BE30>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE338B0>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122F530>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: 0.0\n",
      "ammo [ 7. 44.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE338B0>\n",
      "reward: 0.0\n",
      "ammo [ 7. 30.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A122F530>\n",
      "reward: 0.0\n",
      "ammo [ 6. 30.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: 0.0\n",
      "ammo [ 6. 30.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE338B0>\n",
      "reward: 0.0\n",
      "ammo [ 6. 30.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A107ED70>\n",
      "reward: 1.0\n",
      "ammo [ 6. 30.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: 0.0\n",
      "ammo [ 5. 30.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE338B0>\n",
      "reward: 0.0\n",
      "ammo [ 5. 30.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [ 5. 14.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: 1.0\n",
      "ammo [5. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE338B0>\n",
      "reward: 0.0\n",
      "ammo [4. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [4. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: 0.0\n",
      "ammo [4. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F6B0>\n",
      "reward: 0.0\n",
      "ammo [3. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5E0B0>\n",
      "reward: 0.0\n",
      "ammo [3. 6.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x00000122A12311B0>\n",
      "reward: -1.0\n",
      "ammo [3. 4.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001228AE5F6B0>\n",
      "////////////////// Result: 3.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "for e in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        satate=game.get_state()\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - ammo\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions),4) # frame skip=4 time for agent to process\n",
    "        print('reward:', reward) \n",
    "        print(\"ammo\",info)\n",
    "        print(\"state\",state)\n",
    "        time.sleep(0.02)\n",
    "    print('////////////////// Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f85591b-2316-427f-abf2-547235c29511",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae116f9-e4f4-4b30-9cbb-19380653cd31",
   "metadata": {},
   "source": [
    "## Converting it to a Gymnasium Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1caf887e-2ffa-4a19-b0db-3e1819022ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1fda975-185b-4cee-ae5a-1656d22e4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config(r'./scenarios/defend_the_center.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd41c426-f0c3-4fdb-b18b-39e67dd964c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [19, 19, 11, ..., 47, 47, 55],\n",
       "        [19, 27, 19, ..., 47, 47, 47],\n",
       "        [11, 19, 19, ..., 27, 19, 19]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [19, 19, 11, ..., 47, 47, 55],\n",
       "        [19, 27, 19, ..., 47, 47, 47],\n",
       "        [11, 19, 19, ..., 27, 19, 19]],\n",
       "\n",
       "       [[23, 35, 11, ..., 23, 35, 11],\n",
       "        [23, 11, 35, ..., 11, 35, 35],\n",
       "        [35, 35, 35, ..., 11, 35, 11],\n",
       "        ...,\n",
       "        [19, 19, 11, ..., 47, 47, 55],\n",
       "        [19, 27, 19, ..., 47, 47, 47],\n",
       "        [11, 19, 19, ..., 27, 19, 19]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_state().screen_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c74d17-f276-4fbd-b2b6-4b14fdbe7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(Env): \n",
    "    def __init__(self, render=False): \n",
    "        super().__init__()\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('./scenarios/defend_the_center.cfg')\n",
    "        \n",
    "        # Render frame logic\n",
    "        if render == False: \n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)        \n",
    "        self.game.init()\n",
    "        \n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8) \n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        take action \n",
    "        Example of usages:\n",
    "            game.step(1) # Turn_Left\n",
    "            game.step(2) # Turn_Right\n",
    "            game.step(3) # attack\n",
    "        return:\n",
    "            state, reward, terminated,truncated, info (AMMO)\n",
    "        \"\"\"\n",
    "        actions = np.identity(3)\n",
    "        reward = self.game.make_action(actions[action], 4) \n",
    "        terminated = self.game.is_episode_finished()\n",
    "        truncated = self.game.get_episode_time() >= self.game.get_episode_timeout() \n",
    "\n",
    "        state = np.zeros(self.observation_space.shape)  # Default blank state\n",
    "        info = {\"info\": 0}  # Default info\n",
    "\n",
    "        # if self.game.get_state():\n",
    "        if ~truncated and ~terminated:\n",
    "            game_state = self.game.get_state()\n",
    "            if game_state is not None:  \n",
    "                state = self.grayscale(game_state.screen_buffer)\n",
    "                info = {\"info\": game_state.game_variables[0]}\n",
    "\n",
    "        \n",
    "        return state, reward, terminated,truncated, info \n",
    "    \n",
    "   \n",
    "    def render(): \n",
    "        pass\n",
    "    \n",
    "    def reset(self,seed=None, options=None): \n",
    "        \"\"\" Restart game \"\"\"\n",
    "        # super().reset(seed=seed)\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state),{}\n",
    "\n",
    "    \n",
    "    def grayscale(self, observation):\n",
    "        \"\"\" TO Grayscale \"\"\"\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "    \n",
    "    def close(self): \n",
    "        \"\"\" CLOSE \"\"\"\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3755e98d-e002-4dc1-873d-e51d231b8c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5]\n",
      "  [10]\n",
      "  [ 7]\n",
      "  ...\n",
      "  [ 4]\n",
      "  [ 6]\n",
      "  [10]]\n",
      "\n",
      " [[ 3]\n",
      "  [ 3]\n",
      "  [ 4]\n",
      "  ...\n",
      "  [ 5]\n",
      "  [ 3]\n",
      "  [ 7]]\n",
      "\n",
      " [[11]\n",
      "  [ 7]\n",
      "  [10]\n",
      "  ...\n",
      "  [ 9]\n",
      "  [ 6]\n",
      "  [ 6]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[75]\n",
      "  [63]\n",
      "  [62]\n",
      "  ...\n",
      "  [44]\n",
      "  [71]\n",
      "  [60]]\n",
      "\n",
      " [[15]\n",
      "  [48]\n",
      "  [47]\n",
      "  ...\n",
      "  [49]\n",
      "  [69]\n",
      "  [47]]\n",
      "\n",
      " [[22]\n",
      "  [14]\n",
      "  [26]\n",
      "  ...\n",
      "  [57]\n",
      "  [37]\n",
      "  [39]]]\n"
     ]
    }
   ],
   "source": [
    "env = VizDoomGym(render=True)\n",
    "state,_ = env.reset()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfbe9306-b876-4d1d-bb64-d85840daa6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287ad23b-4c6e-41ff-979e-f5f43f95a724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 5],\n",
       "         [10],\n",
       "         [ 7],\n",
       "         ...,\n",
       "         [ 4],\n",
       "         [ 6],\n",
       "         [10]],\n",
       " \n",
       "        [[ 3],\n",
       "         [ 3],\n",
       "         [ 4],\n",
       "         ...,\n",
       "         [ 5],\n",
       "         [ 3],\n",
       "         [ 7]],\n",
       " \n",
       "        [[11],\n",
       "         [ 7],\n",
       "         [10],\n",
       "         ...,\n",
       "         [ 9],\n",
       "         [ 6],\n",
       "         [ 6]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[75],\n",
       "         [63],\n",
       "         [62],\n",
       "         ...,\n",
       "         [44],\n",
       "         [71],\n",
       "         [60]],\n",
       " \n",
       "        [[15],\n",
       "         [48],\n",
       "         [47],\n",
       "         ...,\n",
       "         [49],\n",
       "         [69],\n",
       "         [47]],\n",
       " \n",
       "        [[22],\n",
       "         [14],\n",
       "         [26],\n",
       "         ...,\n",
       "         [57],\n",
       "         [37],\n",
       "         [39]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb7dcc6-7492-4b35-bcbf-c5850e19b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6065807c-095a-4d96-b236-2d1898c1100d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 6],\n",
       "         [ 9],\n",
       "         [ 6],\n",
       "         ...,\n",
       "         [ 7],\n",
       "         [11],\n",
       "         [ 6]],\n",
       " \n",
       "        [[11],\n",
       "         [ 2],\n",
       "         [10],\n",
       "         ...,\n",
       "         [ 8],\n",
       "         [ 2],\n",
       "         [ 9]],\n",
       " \n",
       "        [[ 8],\n",
       "         [ 9],\n",
       "         [ 7],\n",
       "         ...,\n",
       "         [ 8],\n",
       "         [10],\n",
       "         [ 8]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[75],\n",
       "         [63],\n",
       "         [62],\n",
       "         ...,\n",
       "         [44],\n",
       "         [71],\n",
       "         [60]],\n",
       " \n",
       "        [[15],\n",
       "         [48],\n",
       "         [47],\n",
       "         ...,\n",
       "         [49],\n",
       "         [69],\n",
       "         [47]],\n",
       " \n",
       "        [[22],\n",
       "         [14],\n",
       "         [26],\n",
       "         ...,\n",
       "         [57],\n",
       "         [37],\n",
       "         [39]]], dtype=uint8),\n",
       " 0.0,\n",
       " False,\n",
       " False,\n",
       " {'info': 25.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(1)\n",
    "env.step(0)\n",
    "env.step(1)\n",
    "env.step(2)\n",
    "env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d07f8dd8-7689-4dd4-a3fc-c17ed11941cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f5a8e20-5b3f-4f2c-8406-378056e5de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa0bdae8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFlCAYAAABLDIrrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgahJREFUeJztnQmwXVWV/g+KYCsik4SEjIQhwTCPAcoJSlQEGUS0EWmxi1ZBBWwH7IZ/OSBql4Iggjig2CJICyrYYNNBEGQIEJlEQoBASCBhUJwVh/uvfavurd9b7G+/fd97uX3z8n1VD07uO2cPaw/3vO/ba601Wq1WqzEMwzAMw+gTntOvigzDMAzDMBL88mEYhmEYRl/hlw/DMAzDMPoKv3wYhmEYhtFX+OXDMAzDMIy+wi8fhmEYhmH0FX75MAzDMAyjr/DLh2EYhmEYfYVfPgzDMAzD6Cv88mEYhmEYxvh4+TjrrLOa6dOnN89//vOb3XbbrZk/f/7KqsowDMMwjFUIa6yM3C4XXXRR87a3va0555xz2i8ep59+enPxxRc3CxcubDbeeOPis3//+9+bRx99tHnRi17UrLHGGmPdNMMwDMMwVgLS68Rvf/vbZtKkSc1znjMMt9FaCdh1111bxxxzTPfff/vb31qTJk1qnXrqqcM++8gjj6SXIf/4xz/+8Y9//NOsej/pe3w4rDnWbz7PPPNMc9tttzUnnnhi97P0BrTPPvs0N95447Pu//Of/9z+wctQ+//Pfe5z28zH8573vO7v/va3v3WvyYqU3rBI7PAZfq7u+etf/9q9XnPNNbP3J6Ymd09tHerzZMcO1l577awNWDftFH/HclXdBOsg2D/eE8thW9gO3scx4+c1dXNcSmOv+qrqJthutoljwTGKWGuttbJl8TrN8V5sQLv+5S9/GfI7Nca8VnUr0M68TlIqwXIJ2lmtK9UO9q80Xup3Nf1ju1U5ah7E8VBrXdlA1a3aV/pdzTxiW1U7FNMc+632PNbNMeZaqLETEcdbzYtebVCzP0awbt5HG/Aefl4z3s+p2JeibdkO2oD3sCw1Z2mn+D3GOvhdzfZ2nkll/ulPf2orF8NhzF8+nnzyyXZHJkyYMOTz9O977733WfefeuqpzUc/+tFnfZ463PnhZ8Ndl1BzX691jGU7eu1rqe7R2Gq0fe3VbqOpu7YdNZ/3Wt9IbDBWthnJeI9mHtTWPZo21Txbuq/m817rGEm/V/Y8GG3bR9uOlbEvjmTv7KcNRlvWaMd7VdpbSvWs1JePXpEYkhNOOKH779/85jfNlClT2m+KqQN802KHav5Sif9Wfxmpt0fFMvDNUP1FF9tY8xe9amt6k8y1r/RXi/rrhm/mygaqrTV/0ZX+Ylbt419Gqm71F0z8C6H012KurBo2h9e0X6wr/sWQK5f2UONH27K+mr8U47iSnamZz4rNqZkfsVyWpfrHazV26q/J0u/UulSsmRqLEsum2qvsz8/Z7ho2Lc5zsk9qXHk93F+spb+WaxkYQq1p9pvrWP01H/cPtT+rv+75vFqHbCv32jjerINjFlnInM1r9gki9lt9N6i+qs/Zv8iW5+qKz6t9oPN5L0dIx/zlY6ONNmpPkBUrVgz5PP17k002edb9aRA5kIZhGIZhjG+Muatteovcaaedmnnz5g15k0r/njt37lhXZxiGYRjGKoaVIrskGeXII49sdt5552bXXXdtu9r+/ve/b97+9rdXl5FoxUTlqMNp6vNIaan71OEhUm2KllKSRjzkpqSCGiqd/ag5VFeiwhXNrepT/VPyVJRd1AHNGslHSSpKbirR8IpWV5KROrSmDtWVpI8ampR1K7qytm4l8dX0VUlgtRSqWpeK0ldzTbWPNouyhKL3lf05H2sOW6pDiqW2K6lRrekaSbc011RZyoY1e1TpAGKNLKj2AGVnJX+qdpf2P8odavw4b9Q+WGpjzYFT1kHUHLZ/bvguUfuGmmvKOYNynZLWSnvLcLLX/6nsknDYYYc1TzzxRHPyySc3y5cvb7bffvvmyiuvfNYhVMMwDMMwVj+stAOnxx57bPvHMAzDMAxjoLxdFNKp3EQXKblCUX+1UKe01el0JWuwHYoCK3msEOpkvfK2IK0XbaCeV54NNbEaFK0dqXA1Zr16otTgj3/845B/14xZKUZJL22N96gT5oQ6ka5oT0WfljyrauKgKK+IGqmrds0oil3JHSyHc1t5apRkVZal9gplZ1VOlADUelA0tfJkUdKYsmu8ryZmhfKyqulP7Lfqh3pGjUUphkru/tq5rSQc1Va1Vksym7pPSbc1+/ZzKrwjS8+omFFKQlNzO36X1MRq6tzTi+zixHKGYRiGYfQVfvkwDMMwDKOvGFjZJVE6iTpSJ/cV1RipMuXhok41Kw8ERUGX6Oia9tZ4T9QE2Iq0rGqXoodr6lZUXqRlFY1ZE1xK0Ygq0E08Ua7GpsZzQPVV9SGixpunJqiWmvOlwE+KWlU0vKpbjXFJXqyREWslnF7D4dd4jRC1a3e4Z2PdNdElew2oRsQya0Ll18xntT+qukrygPKWqQnGVhP8LdahxrJGQlb3K6+S2iCLSr6r8bQk4pgqjzk1xmpPHcmarBlXyy6GYRiGYQw8/PJhGIZhGEZfMbCyy3BUWW2ekZqATYR6viZwU4lyqsmKW0vB1aAmW6gKKNVr9tMSFd5rgqnRjF38XU19NdKaov2jBNOrvFJjG9XXOC4166TGNjU2q52PNff1muelREfXtF2NZU0m1IheM1UTNWu9JCUoWU/R6moeqftL+5paM6rfNfO8ppzS72pyXtVIebXzSd1XI7WrvWyNyu+Smu+uGvm0RqapbSOz2payfRNmPgzDMAzD6Cv88mEYhmEYRl/hlw/DMAzDMPqKgT3zkbTWpC/xXMLvfve7YSNZllzSal0mc2XVlFPrgqjaXhO1Vbk9RR1Q1a1cddU5AaUdluoqRYXM1UfUREAsRQJU46oiR5Y0/eHaWtKjlUsa9d5eXT1L0VvV2PSqTdcmzlPtqomkOZp5UEpi2OuZj5qzCKWImmq9qvMLNWeHWB/viS7lyvVcrXvVV7UHlKKEqnmk1pU6j6HcUktnXdSc5PPqHo5RTftKqDmfVHNujCid86ipT51dUeXURpNWc4RJ6nivz3wYhmEYhjGQ8MuHYRiGYRh9xcDKLq973eva1BiTSjGJ2MyZM7vX9913X/f6ySefHFLOE0880b1eunRptq611147+7miexW1GaMq1kTUq0kQpajiEpVX445VQ8nXuLZFmm2s3O+UG2Yp0meNbZXUUtOmWne4GhqY80XR6ESJElZtV3brlfKudb1UboTKpVP1odblsVcZq4byVm6RJUm3dF/ufkWR18qUNXO1RtJSa7XkeqnWlZrP/LxGghmJS7kKD1AzRjXJ6kpjViMF1UQtblVGB1X7IutQsi/7Onny5O71Jpts0r1etmzZkPoOOuig7rX6Pn7hC1/Y/S74xje+UdePqrsMwzAMwzDGCH75MAzDMAyjrxhY2SWd7k4/f/jDH7K02VNPPdW9fsELXtC9nj179pByttpqq+71+uuvn6WMKNuQfrrkkkuybSN1xVPokTqsodEUNafoOOVNEKk/5YGgohiqsmoSXakkXiOJSsv6FJ2paOPa+pRngqpDlV9Czan+mnYoarkUhVBRvIpiV5KDorLjPFcUe6/yiJISlAfIaMeshv6ujWir5p1CSTrM1VfrWdWrDdS4lqLTqnmh9grV7hoJcyTzXMkoynOv1+SLpX4QSkrq1TumJJ2wHccee2z3ev78+dnvPX5XUuLj9yG/M0vHFfjd17FBzRzowMyHYRiGYRh9hV8+DMMwDMPoKwZWdkleKokWmj59elZqIU1Ukj7471/96lfZzym1kB5+05velKW9fv/733evX/ziF3evp02bNqTur3zlK9n7Fi9enC2310R0JVq2hkJV9KmiLWsT4vV6En8kSQJ7DTJWIw2MJjFZfL7mdHsNRV5DG8f7VLnKK0XZpibAXHymhpJX81HJgyUJoIa6V/fUzLtaD4SaxIBqXGvmQbRBr4nUaiQ3JSXE4IlK4qhZV2oeqXZHGp91l+TeXhJ31n5ek7iNUPIIPTV/j++Srbfeunu95ZZbDimL310qIeivf/3r7vWUKVOyNvuHf/iH7rU60vCnP/1pSN3Kzh0PFz4T50oJZj4MwzAMw+gr/PJhGIZhGEZfMbCySzqVm2QXBgkjpcOTuqTWGAQlYd111+1e/+Y3v8nKIL/97W+71+utt142YBnj2KtgLvfee++zAqV18PTTT3ev99133yz19dhjj3Wv2W9KTLGOXPtqqdUa1OT3iGXSJoqSrwlM1WuughIdquZLjVSiyo+SmZIKagIaKUpeyWeRhq/xXKoJ/KRsXgqaViMtqFwhLLdXGr1W1lMSR433Q0kmU/Ol17xRar3UrlsVVK5G0lLSTqnfvQZPJNScUuWXnq/5vNd1XJKbeN8WW2yRlTj4nTFnzpzss9zPnyPm4/Lly4fUXSNvKXmFz/L7RgVgi1IXv1soE1EK6nzP9vL9YubDMAzDMIy+wi8fhmEYhmH0FQMruyT5JNFCG264YZYmolRCaSXKLqSJeB9P9PJz0lIE62NMfMojpdPRpK5Iqa2zzjrd65e85CXZ+3m97bbbZst//PHHh9S94447dq9PO+20bB4blQ67BiowWMlzpiatN6Go35EE/6nJLdJrAKlYjpITlA1qArvV5KGJZdVIDjV1qPpKnjY1EkyN/dWzpRTrJe+Q3D01slwJqo6aQHlEjYdKSeIjatOkD9e+UsArJVGpseg190wpoB3HqcajjHVz7/vd737XvT7uuOO61wsWLMh6pURvEpbL7w96Tqp1T2+VFyDoF6X5aDMle/I+yjkvetGLhl3rNTJ4fIb3bbDBBs+SYBxkzDAMwzCMgYVfPgzDMAzD6CvWaPXq/rCSkTxSkifKIYcc0qZ7SK0xqEmvp6xjkDLSUjQB5QfSTeoUOmWeSFeRguLvlOcM+8G+UvLh/TzRTBqxRNOx3/ycnjZs6z333NO93njjjbvXN9xwQ6OQi/kf+6faWpNnpDTeNQG2ajxAVB0lar+Wrs+1YzT5R2Iba5Z0jTfCSKQu1fbanBm5MktrWvVbfa6oeiUJ9truWJ+CqrtWHuw1oFpNO2r7VzN3au4pBRNT2GuvvbLyNWVm7tuU3fm5kpzZJu5jpdxblHNYlhoLlvtHSCXqeyH+W3l9qqB+qt9q7+P3SjyiwLbze6nzear3u9/9bluiohyVg5kPwzAMwzD6Cr98GIZhGIbRVwyst0uigRJdRO8TShwMEkaKiRRYiXYjlURKbMKECd3rFStWZO+nJFKiRlmfknP4OSWR6LWTo8f4bOy3SnlPW7FPlFRIp+28885ZWx5xxBHZumK7GNiN9rzttttGTBXXeEvUBo6q8UqpCT4Wn6/xIFHB6khtKrmpNt8JofKrKO+C2lwWNV4f6sQ8UZPnKNq/JmdMTRAuJTepdVvCaCQm5eESy6kJ3lfjycL+KfmzJC8q+UjtX9ttt13Wu4+eE6U8I1wbfEZJFkwnz32N/WZ/uI/GPlCOYN3Lli3rXk+dOrV7/dBDD2VtqFLZ/wVzmd8F0ROGZbGNtAHbxz2Y9uN3q/L8imPM8eB+FyWqGpj5MAzDMAyjr/DLh2EYhmEYfcXAyi6JFkvUH+knUmWkjEgLRa8PUmoM6ELZ5uGHH87SSqTZSImxHSyzNsAP6+AzbLuiPdXJeAYri3QeKTsGwaHdeL+SgtgmUpiRRmdbKFExTfSkSZOyY0GKcNasWd3r8847LzsuS5Ys6Tm9u/JkUfR8bWp4JeGoQF818lGNDBLvUzIK6dRec32oPBCxjtGkXlfPKm+0WomKUH1SHjGlMeq1DoWaQGTRZjUSlUpvXiPLbbTRRlXtpfzKgItsB6UBFcSRNuP+WApgyL1FeR0y+CLzdqk6KLuUPE4oIVPuYH0qECPbuh7axPK5D8Z5zt9NnDgx2yb1ncF9W61D3hO/A1SQt05ZvXj8mfkwDMMwDKOv8MuHYRiGYRh9xcDKLh2ainQTKR/SWKS9IqVICom/W7p0aVY6UbILqbLaoDQqjTjbwT7xeeWVwtPbpTTIlDJUThyVup3UI1NEq0Br0dNGUfdso/KuIZX6wAMPdK/32GOPrKwTT2bXnN4nNcpxJW1Jryf2h6fIf/7znw+p+/777x/y79zzvXrzKCmoVE5NKnblkaHGuFR3Tc6eUqCwXB3KUybKICqXjGqf8lxSa4GI5StpVEk4vXpiEZtvvrn89y9/+cvsWmRQRc5n2nPGjBnZtV5a35RzFi1alL2P86gm4Jgal1LAK0LJY9wreK2kFtomBsmitx/7RCmJ+y77xM8pg/8GEkpJ4mO/VX4W9oP9o7TDPtDOSq6O7eLzuX2qZp1366++0zAMwzAMYwzglw/DMAzDMPoKv3wYhmEYhtFXDOyZj6T9pzMQueQ1JTcmnv8onalQ50dUhDueReA9rC+6kfH8AZ+nWyvPm/zqV7/KusTShY32oDYX+826qReqsyDUVlkH21frYkxdkLou+0SdmuOidGDeQ30yulZzXrDf7CttwH5Pnz49Oyeoy/J+RmuM/6YL3COPPDLsOQM1v2gnaqzR5ZTjz8iRCxYs6F7feeedw55DUe53JXd2pfOqsxbKFVglQyydb1Fzp+Y8Aevbfvvtu9fTpk3LPhv7zXm+2WabZfcW6vtc3zw7xLlWG02X97Es9ptzkOPN+phQUiUCi3OCdlBRX7k/8CwVz3qxHdw7eaaE6yLWRxuoJJ48I/foo49m+8pnuTfzOs5n9o9rj+PNutk/da7qGazpOBacO5zzrI/g3ObZH/WdUTonxn2U/eY4dfYsn/kwDMMwDGNg4ZcPwzAMwzD6ioGVXRJ9k36UuyqvSf/EqH6KviV9TqqIEgej/CnXOFKQpKSibPPrX/866/JFiYNtYrmsj5SbcvmNNB/LVTaskapqXOZKURZV1E+VvIvyA58l1RhtrtyPaQ9VR4wqmKNPOY6RjlbSBJ8n7ck2KVqVUHJftCETWlHqIg3PMWMEQ1K0rEO57sU+cY5QMtp0002z64I2o21JG9POJTqaNDnHmP3jGHP+c00q990oAbCvbLuSdBnVl2Ov1jTrjonGVMRMJSGraKfK5Z2I8gPtw/XHdnAeqYSeysWedo3yIu+jzTlX+TnXngqpoKTGuN+p9UDbqojQak61Cgn8CLZRhRqgDMh5zjoo0akkcbEd/B1tS3t26o4hH0ow82EYhmEYRl/hlw/DMAzDMPqKgZVdEr2TKCVSlaRxSV0pT4hS5EJFD2244YbDequQ6iW1GWk60lKkvkgFkuKinEA6TdG49NqI0gepUtJrKukVbaMoTIJtKtVNzwtGUKRthjtBXTotTqo315ZcWSriq4qeyHnA+RRP+rPtbC+lAsoxvF9FMqVkxj7EceH4xaiQOVuxTbQBaVlVX/TqItXMOpScoxLAkU5WSSSjxwnnDmUl0s58pibSMPcZll+SH1guZSnaQ9Hc/Jw2YL9j3SpBW5Qhc5/THoz2qzzyoteNihSqJG7ltca9iPXx2Sh1cWzUPFdSEMvleKtI1lH+ZD+4frg2lFzONimPt79jLUSZjL9T0hzHgvsubauSX9IGah+Me2/O68ayi2EYhmEYAwu/fBiGYRiG0VcMrOySaKBEjdH7RCWbUkl+InVMyok0E8vlPaTQSDEpCi2ezOa/SdkxsA/LYp9IianT2OxrrJvSDu1Deyg5RgXnovcPT1ZHz4uaAE8qcA3pcpWkiX2NSa9Im9ZQnewHk28xIBFtQxvEuUY7sx2U09Qcpg35LPtNejdSoyo5lkp4xn6TRmdbuUZo80h3k9ZVgZI4j9h2lQxLJaWLsgLXJfvE9aNszrbStqxPeaPFtnOvoCyrgt6xTZS6OA9os+iJxXFVXhxcP7QN5TDlMcexo9QR14/y1FGyMecKJRWOF++PsirHgPdxnLhfclxVEjY1f7mHxrLU/qW+D1TAPYL7SaybfaqxJ8dM7btsB20TZTYlY3Gv6NS90mSXU089tdlll13akze5aB144IHNwoULh9yTOnfMMce0z06kTe2QQw4ZEuHOMAzDMIzVGz29fFx77bXtF4ubbrqpueqqq9pvOa9+9auHvFUff/zxzWWXXdZcfPHF7fvTX5AHH3zwymi7YRiGYRirINZolRInDIMkiSQGJL1kvOxlL2vTUumU7QUXXNC88Y1vbN9z7733NrNnz25uvPHGZvfddx+2zEQvJrrwgAMOaNNLijbmNam/eBpe0ZOkMZXHisrzogJnlU5Hk07lyxpPxpOuZa6I5cuXZ+kx1Z9Svg7lWUL6jjYgRavuiVS4or9pH37OPik5jZ8rGjH2VfWP95Dypg1ZB8c+yjwEqV+OK+eBWm7qtDmf5eeUf2Jfa+ojPaqCx9UE4SqtDd5He6p1xbVKyYCfL1u2bEjd9HChRw2f4cl/encoyYH3k2qPsktNDiT2j8+rOUzqXHmJxH2O9uTcJi3O+cjPWS7HmHOC6zn+TuWfYblcV0r2Yt0qaFpJTlaee1z3tD8lDuURGec5+6S8VPi8yuGi1vpfhOdQ/LfKp6M8WdhXNVdUEMYIZZ/O56kPV1xxRXvdqFxB3T41o0BnYXY28Ntuu61d+T777NO9Z9asWc3UqVPbLx85pImWJid/DMMwDMMYvxjxy0d62zvuuOOaPffcs5kzZ073L/T0dhjDL6eDfPzrPZ4jSX/ldH6mTJky0iYZhmEYhjGevV3S2Y+77767uf7660fVgBNPPLE54YQTuv9OzEd6AUkUUvpRdK0KtBJPCfN36kS78nZReRJIV5HWK+V24X18OSOlSQmA9LCir0mfljxOajxc+LwKxKS8OSJFqHI/0G48jc1+MxAZKWg1RqX0z6TuY5CmHHWuqFRFn5ZsrqhYtr1EL+foaHVCvxTQi/UpWYMeZTUn9+N4K7qYbSeU5Mk+KXkxlsl1ouY514nKQ8PcM7SH8gSK9XGMOa41OWO4H9AGKihcnLcqxToDJhKcz2qMS8G22EbagOuV7WW/2W7l6cT2RS8+Pq8C67E+ypPKe5F7MPsQJV1KGRwzfq+wXJVTiLZ9puC5p8CyWAf7p+RW9knlP4pQkgzL6qwlJeGO2cvHscce21x++eXNT37yk2by5MlDklglY6YFwMFJ3i5McEUkg9ca3TAMwzCM1Ux2SW9T6cXj0ksvba6++upmxowZQ36/0047td+M5s2b1/0sueIuWbKkmTt37ti12jAMwzCMVRZr9iq1JE+W73//+22apnOOI1G4ifZK/3/HO97RllESlZ6ot/e85z3tF48aT5dIcSUKR532V8F4IkhFkWJU+UsYaErF6SdtRlovtoMUHOmqmkBOpLpIkSsvhcge0Vak6chIKQpaUci0X4kaZXspAZDaUwHEVEA11sF7ogcCqVHameOkgv+ocVFBgWL+BVLNLEsFAlL0d02OmTjX6CmlJDQVqI02UB4BfDbONeXhwrnK5ymNKgpZpfguBRFU/VbSLT9/5JFHhvWei5KPCkam8uaoXCQcC/abaySuC/6bbaQNOAcpXancM7Szmh+18rfKJ0JPIu4NnBOUXksehEoiZH3K847Xal+LXh+czyyX93EseH/sR25OqGBxpSBgrI/tUDmJVPA4JceXpPecNBqfHbOXj7PPPrv9/1e84hVDPj/vvPOaf/qnf2pfn3baaW3jpOBiaWLvu+++zRe/+MVeqjEMwzAMYxyjp5ePmpAg6c37rLPOav8YhmEYhmGsMrld0ktMopHUSWlSTKRuowcCaSBSRryPlBNpSJUzhtQf2xShgqIpip20s7qH/VG5M0rx+GkrUoG8h7SsSvtekl1Im5JmZT94TdukoHW5chSlGFPLK+qdZbF/bAe9blTwH0Wfluhv5RVBOpSeCbQ5x4WSDfMDJfBAN+lUPsNr5TFEe9LmtbkfSEdzzaj06So4GutQqb9Lsqo6xM57OK60P8MCMIhZ9HZRY0xb8R61B/Bz9pV9izS8yi2iaHHOI5ZLaYd1cy+Ksgvnl5JguD9QruLYK/lABYaMz6hgaUrKZj+UFxgRZTbOF9pKjQXHlWuJEukLRHC6KPWqP/ynTZvWvX7ooYey5aq8XSq3TpSTlT1ZR2ce9OLt4qy2hmEYhmH0FX75MAzDMAyjrxhY2SXRhIk2JH1HKlDJFVF+UKm5edKa9JqifvmsoufjiXQl4ZCqJKVFGpFtIn2t8pVEepL1KfmHbaeEo4I9kULmdcnjhHZWaePZV3U/6T4GgYrRdFVuF5ViXUkGBCl50sNRbqINVVA02pbzlmOvJC3amXR5baAkdcKf7VOfK2+tSHnzGZULQ3m40DZ8Vp3WL9lceXGoOcG5xvWtggNGiUpJMFyHrE9JFCpQWpSTuWY49qosgvZQ65t1l7wJOSd5H8eCduL6oYeLypMT+8A6lGcW71Fjz/moJLA4zwm2kXNQ7V9qPyBUHpr4vcT1zb1QSWD8XMlFXIfRo0zl3srtFb14u5j5MAzDMAyjr/DLh2EYhmEYfcXAyi6JPkw/6pT2pEmTsjRRpGVJA5HaI3XFcumdwVPdpMHYJtJQUXZRp4xJV5EyVVQgaS8lPUVqVJ1KVhQjr1XeA5U7IMoPpPZoHxVoinXQznxWedqwTZFiVF4mrE/R4pRa6CmjKPVS3grSqWw726FO33Oe0s7R64ZtZzsoFVDuYNA1JWuoAE3xJD4lANat5j9tq+5nfVFSJFSOJhUoj/NLeUZxjPh5pOEpfakcQfxcyY4qDxPHu7TGWK6SyrhHqlTqXEvKW67kJcH6OKdoQ+7byuuD8y7ua7Qt204vuUcffXTYIJDK46rkBaM8xNReSzvzWuWNWlvsV3Eecf1wTVMu5HcX281cSLxfyVlx/NXa6IxLTTiO7jPVdxqGYRiGYYwB/PJhGIZhGEZf4ZcPwzAMwzD6ioE+8xEjnFJbVhEoqXV1yslpkrymxqWi96lzGtRbY2Q4apKsg3o9NUkmt6IeqpLa8fxH1NpqEipRs1YuySrpmEqsFM9zqIie1I3pisdylfuXcoGO+mtsV+4Z1sfzETVjF6Pbcn6yTyxXjSt1XD7LOmjL6GrL3/HcEsebGi/rUDo6z38ofb7kJqyi2HK9qmSPKulePOPD+zjvGAGW46eiNbJ9XGPUwjln4/7AZ9T5D+U+rOY5k1wy6mosS60lfq5cj9V5GN4Tzx9wzXCO8D6uBZarEs5xXLleSmcIOF+U+zbtyc85B9U+Ec8+cC7Q/mqe0/6sj7ZZjnFlmZzLcb0rW6mko7SB2htKZ7q4TlQ014792YbhYObDMAzDMIy+wi8fhmEYhmH0FQMruyQaKFFHys2O1JCSCSJ1pqglPkO6i1QzKTRFD0eXNJW4TUW8ZF9VtEflehzpaNJxfJ7UO+nTxYsXZ58lJUm6kDaLNJ1K9KeSQrEO5UqsXCRjvwm2UbkuU/ZSSfcUrRrpWvaJMopy4yRIl/N+ldQuJhrj3GE72F6V5EzJIEpeLFHhHA+6P1LOVAkeOS4qumeca7QJ6+DYKJdYlXSMtqRtuCZjGynBUIpQyc8U9c5ySJfHfZDt4n1KFuSeo8Zb9Tu6dXM8lIzCa0pg3EeVJKXkg/hvFS4hro0cOI+USzNlr1iHkvNVdGd1ZODFIrFf/C7h2lAJA9knJTFxjPn9VpJLWJ9KzteZE45wahiGYRjGwMIvH4ZhGIZh9BUDK7sk+ivRuyqSHOkdUvKRliXtOXHixGzUSkoRMZJgjpLfdNNNu9fLli2risSo6Ha2g9TcJptskqXvlMdOTDxFipD2YYQ70mnsEyUA1kF6mHQh6dM4Niph3cKFC7MyD6lUSmC0k0oAFylNUrmkNFmH8m7is0qii3NNJQVTXgCcayrqYU2SuVI/eJ+SWlRyMdKyLDNSq6R+KTfxc46xSi62YsWKbB0sJ1LhXBsqOqiKMkoo25RsznFVNuQ8Ylmcj1wjnF8lzy0+rxKHKXsojzfaMkep5/bCqVOnZte32qs5lkrmUZGXS5GmCZarEmlGOSfXVtoj2pN7JG3Iezi3lRfZL7FuS56TnEcqKrOKoqrWNG3O6+hJpyLlch13vgPs7WIYhmEYxsDCLx+GYRiGYfQVAyu7JGop/ZBuUknKeA8pwUiDKQ8L0muK/ibV9cQTT2TrjtIKaUFSfqSO1Ul10mMqCI5KZBafUXbj5yq5FdtEypN2jtQoT1qTnqQNp0+fnv1ceUUQpSBjSuZRgc9Isy5ZsmRYz6MZM2ZIOppUs/KwoD3VqXWVRI8UK+Wz2A/KSiqhGO9h/zhPOY5sa5xrykuF40Tb8HOVGEt5h1GaKXkR0M4qaRn7wTFSSd/iPGc/1F6h9hO2W0kOyqMirhPKoZS3mGCNMq4KLsg1Qkq95EHIvVN5E0YaPzf2NXJKtJUK4qUkeSXXsq1KworP05NLfRcpGUol6FxbyGSxDhUgjZ8rOUZJgtwn4ngrT6SczKz27BzMfBiGYRiG0Vf45cMwDMMwjL5iYGWXRJcluod0EKlKQuU7iXSq8pwhraROfysvB7Yp0vD8HctSlCZpPdZB2pj94bMxEBDpMdZH+yivA4JtUkG7St4PpOZI/ynbMuiXoupLMhvrUPk6eE3qlif3lTcCqf0YzIjtom1JvdOeKvgP5UHSxpxPcbyVTZSEw3aoAFS0v5IV4tjwmmPMdcU1zflBKUHJQpRm4u84ZiqgXY3nBdexyqsUf0e7qSBvnBO0gfIQUAHA4r8pAbBcrmnOieilNVwOozjXVAA4ZRtKAxxj5Y1GxPJ5H+cw7aFkPfZbSWbKK7G0jpVEyPvZPl7/LuMxkpvnLIvPKI8rymy0uQrcSC+1CM5nJWF25nkpAGGEmQ/DMAzDMPoKv3wYhmEYhtFXDKzs0qEiSUnSc4KUHalbUk+RpiPNRBqYAaxI96qgYcpLIVJOpMR4H9uuaDrKIyqQEtMjRwlApRFXnjr0rok063CBuqLNFQ3J8VPyiApsxTpojxh0imPJfpOO5tiTEmZb1Wnx0qlwtlEF8aKUQVpceQUpKSFS55QflAcInyGdrdJkE3w2znPWR0qYVG5NPh3aQ+XTof1jP9h2Us0qmJXysFCyRLQN28j+cW0QtA3nNuvjs2xT7DdpeXq7cD5zTsRAgDnvGI4F2xdz2qigexwnleOEa0kFMlNrIbaLdbCNvFbyHceSZbIPMagcoTxylGyj5spzhEdY3FOVbTl+nPPKe4trVcn8UUZnG5UHZ2dPdW4XwzAMwzAGFn75MAzDMAyjrxhY2SXRTumHtBJpM3XSPAZAUgF1eK0CSikvExUYKZ7YVtScohtJn5IuVEGjKFFETyD2T9Gpiobn5+oEPPsW+03qUeXVUKeieY/K2VPKv0C5iu3gHFH24OdqjEhB0gsm9lWl7OY48RS5oqPV6fIIPkN6X81hjiXnl/K+4niV8ggRlACUbQgVEK3kgaD6pIIvqcBi7B+f5XhH6YNzTUkkfJ73s77ooZe7J64xyqek6FVwNc4P9juun1y74z6mylVzW3m+cN4oT67Yb46fCrZFcO7wWc5t1s1yopSdkxmirbgnc52o/CrriFxPUb6gHXjN+9gOJc3Q5krii95XHA/Wwec77VBrOwczH4ZhGIZh9BV++TAMwzAMo68YWNkl0Uad/C45Okh5u0TKSHkwKO8T0kqUYHgPpRaVq6MEVQdpfNJ/KsiLCghVyjdAe6hcArS5CpbFtkZanLTilltu2b1etGjRsPltaJuawDpRZlNBe1RwNdbNYE3qJDj7Heca71M5dBTdSxtyvFkH2zpx4sQhddNDgN4k6hnm/eB4q7wkKlhcXFekptXpfSW/sW7ahuPIdse1qOQf3kNpjbQx5yztR1kiBn5iX2mfGrlV0eU10nJc04reZ1mcB+w356OS/uIaY1mk9FVeHz6vvG44D1TwvdL6Vt8BKrAYbcD5W8pNwjpoH84dJZmy3dxD1hJ5U6KMpLw2VbBGtoPjpYLelSRx5UFFdGyrxjf7TPWdhmEYhmEYYwC/fBiGYRiG0VcMrOySaKP0U0P7q9TMkXZTFCFpUtKQpOpJXanP4wlltpfUFek4tkN51KicNKTKIhWuKGg+o3LMkJJUKZhVqvAY/Iwp0Gk3FURKUY3KkyFC5ZXhOPF5zgmV1p5tZZui1wefYYAtRX/T/uwf5yyfZVsps0TQa4rrgWNBWYPzTuXIKHleqFT2SgJQ96tU4xyv6BlCO3D90YbKi4nylgr4xr7SrqVcU5x3ynOGfaXnCstUOaTi72hP5cHAsVBrgWWqPEDR0yPKvbl2KNqffeLaUdJy3PdVDh2Vv4c24LjSBir4YclTUHmZqDxOnMO/RGAwFfAw1kH70G5qn2FZrFsFQoxB8rgeWHdOCnKQMcMwDMMwBhZ++TAMwzAMo68YWNkl0TiJklVBUUhpkfqLNKCKnU+6lxSVyotBWpb0K2msSEeroFyKiq0JjMTP1XVsF/tBmo40JKl3lb5epf6OMoiSZ9Q48Xkld6j8KvF0tTqxr+zJXDDqhD9pZqKUd+Lxxx/PzluOi/KmUp5YSq6INDDnqrIz62a/VVAmlhNtrmQw2kfJn5RE+Llqt5qDtXIA285r2pb10Qal9O6k6NXeorzOOF7K8yLONfaPbaTnBSU3JaGxTZwT3HdLki7rUHl9aE+ON+tWcyWOI/tak59F5QNT+ZN4HT1t1N7E8VNSEO3EPWcD4YkV+63qpm2516qcLypHEz/nd0Ecf/V93LFzaX1GmPkwDMMwDKOv8MuHYRiGYRh9hV8+DMMwDMPoKwb2zEfSLpOeNX369O5njzzyyLDJviKoS1Er47VKnkZ9ixpcdOdV7aAep5La8RnqboyyqNxuqRvHJEjU+ajZsR/U56g9quRI6vxGPOuioqWqswWq3YyCyjpos6gxqjM7yj2a5wSoDys7UcuOrngsd9q0ad3rJUuWDHsmRZ3ZYJnUoGNCMPaD2j3Pj9CeHEvaXEXY5P1x/qt5TntyHqmkYyrCI20Q61bReFmfWuvqzADP6yi7xvbyPtbB9tEeHGMVEVW58pbK5TxXLtTcE5V7s9qjSu6otLmK5MuxUFGA1fmn+Lxy91euxyrpGfcWtcfFcxQce9bNtnMesB9s01rifFzcW1gH+0E70w2Zz/NzjgW/V9ifeLZJueTmzuk4sZxhGIZhGAMLv3wYhmEYhtFXrNFS4SX/j5CooERhHnLIIW0qjnQVKR3lRhZpH1JwpEZJN5KKUomuVAKmUlIilSSNEUBJ8VL6YNRD5UamXDUjSLmqqKvKRUy5L5YiXioXTdpZJR1TCbooUXDsKRnEsVEuq5wjHDPSk6T6lRQRx1u5qSoXV+VeqJYk6dp4j0pqyHmr2sSyWI6KMBsjXrJc1Sd+TtuS4lW25ThGKUK5TCoJQdlZRXZVc7DWttx/1DpUNDrHO7ozq7mt9ktFlxNcV6Tao825d6p5RPB5FT2WfaVcFJPaqf1EjT2hbK7uj3IT61bu7Cq5ZE3iu7UwjnFPVZGV1XeROm6g9l0+GyVxzgtVVud7In120UUXtceZ+2kOZj4MwzAMw+gr/PJhGIZhGEZfMbDeLok+TLQQKR+VEKkku5DqJCUZaa3hTsyrSIAqkVa8j+2l9wNPp6vEX4pWVRE5Y/9I5SpZSUXKIwXKtpJyi3S0sjPbyD5RelIJ53g/20SvoFg328V2sB888a08Tlgm2xSTnHEeqjmi5pFKGMj5T/tF7yZSuSoaKfvBdaGiWapySmtMJRGr8fJRcp2SHUuRH1VZtL+SSmhL1se+xd+xH5QqOe/oRaZkBhUBN1LY7BPvU+PEeaTWlUrQGWU2JRuwr/QMoaTLflMyVQkCo5zMdqlorpwHLIv7GteYiqYb5znnmpKGlGcV7bFs2bLsPUT8LuG40tONc43t4z1qHdK2Sr4pJYvLtckRTg3DMAzDGFj45cMwDMMwjL5iYGWXRH+lH1JlpOxqTgxHekwFE1PBf0izsh2koZQHR6TBVFIpUqasm31SlKRKSBWpNhWwiXWoxFPqmvRwPB392GOPNTkwoRLHQgXQUZQibcAyS4F21JxQCetoM16TDo0UI8dAJZKipxPpbPZVeSxwHsS+qWBFKjEdqXBFTXOM2aYo8amyOLeV1wfv5xhzXbHuKDcp6bFGUlSyl/K+ih5FnAuUrmgPRfWr+aXk5BhUjlB9VZI1y1XygUomFsdPBRxT+4ySgGMSt1ybaqVDFbCM9yhvnpL3Itur5F21jimpq+Sef4Od4t7CZ1QiO/abMg/HWHlF0pYxmJ5KJpeTvVTwyDFnPj71qU+1jXLccccN2RyOOeaYdiTINKjJZZaGNwzDMAxj9caIXz5uueWW5ktf+lKz7bbbDvn8+OOPby677LLm4osvbq699trm0UcfbQ4++OCxaKthGIZhGKur7JJomMMPP7z58pe/3HziE58YQgt/9atfbS644ILmVa96Vfuz8847r5k9e3Zz0003NbvvvnvPsgspI1JPpHdKAXRIX5FaYkAvygQ1ceyVHBMDAfF3pK5IzRGkVknPs69sXynIGKnAmtP0pP9UXgdSpiWpi7+jDEKKkOUqKYMUKOl2FUynVjpRuRxIv9bkgSiB7aVHDucB56PKXaMkB1KvJaqaY0Yanv1TXkGsT8k6pXXCOcxxVfk5CM5NFTCp5M2mvIeUnWknZdsoAajcKewr20T7KxmX93Pdx32t1+BlfJ79UHsA11FcY7SV8nRS9DttXpPPhVJjKV8K9xk+wzWtAhDy87iH1wQZo52VR5OSbH4jPIziulDehVOnTu1eL168eFhpk/1jWzl20btFHVFQct9KZT6SrLLffvs1++yzz5DPb7vttvbC4+ezZs1qG+jGG2/MlpUGIg0AfwzDMAzDGL/omfm48MILmwULFrRll4jly5e335J42KWTTTP9LodTTz21+ehHP9prMwzDMAzDWB1ePlJK+/e9733NVVdd9awgKCPFiSee2JxwwgndfyfmY8qUKW2aKVFVpK5I96lTu9ELgM+T1qIEoChlRYdSNimlxlFpxEl7UmpRXgcqWBAp5Hg6WkknKo21OkXOHDPKE6iUC6AmqE2NV5HyaoiUcPQ4yoE2IC1LGp22Yd1Klot9og1JkasU8ioPB9vHfkf5h89wLJW0QLspKUm1VeUGKQWBUjQwbRaDWXVANjT9IUMwQJ3yWlD5dLhG+KwKlBQlH44Hx4/1bbLJJsOmr+c+odLER/lh0qRJWTsrrzBesx0qnw7bFOvmWCoPOOUNouY2PcLUnC/JZhwzFfRLSb1K1o7Sq8onpuaX8pSi5P8X1Kck0thGrl3uz+yTkhFVwDe2I0ooKvAax7VTd8yHM2ayS5JV0mLfcccd28ZIP+lQ6RlnnNG+ThtD2vzZwYTk7cJFSKQBSnodfwzDMAzDGL/oifnYe++9m7vuumvIZ29/+9vb5zo+9KEPtRmL9JY0b968tottwsKFC9vhxOfOnTu2LTcMwzAMY/y/fCRabc6cOUM+S9RNiunR+fwd73hHW0ZJ1FJiMd7znve0Xzx68XTpUPTphzQWvQZI1avT251yhjuFTqpIpRlWVLHKCxDrULkHFE2lJCaVSjtKH+q0P2lS3kM7k+ZWKc9JscYgROpEtZIicvRdyROC40LaPT5P27JPlM2UfKS8Y1RulkgXs98EqU6Vc0TJDyoQVoRKD6/mncrroNLVkzaOtDxtMn369O41z4gl77fcs5xTrI/XlMZiP5TnhlqHNbbleokSH6G82UiLs61KRiStzfGK5+gYO4ntYl+VdKjyHKmga1H6UN5NXGOcg8q2yvOLiJKgyp2ivDVUW5XHW8njpEYyVeuYz6p994VCBolt4bgqLxi2gzl0OJ9Zh5Kw4tioudrZQ0rHEFZ6hNPTTjut3ZHEfKSFsO+++zZf/OIXx7oawzAMwzBWUYz65eOaa64Z8u/0F8dZZ53V/jEMwzAMw1hlcrskSidRYyp19MyZM7MUd6QIFbXEA7A8IEtaT8kVpLFIscbgLKyP/SDNTQqbFC37SsqVVBfbFOlJlTKa9B0P99KGKiiNCjwUU8uzLSq9OOnhjTfeOOv9wzFSgalKXldsLwNesR20AU/cK28celtEqYu0czr/lAv+o4JtqXJVWnXOlVLOBX6uggKxHTVBrqIsxHlO6ennP/95do0xqJ/yquCcUt5JEbyvxqtLUd6cgyoFfPwdPQqUVKM83pQEQNvEfY11cLy5V3Cc+LwKkMV7St5NNVIU204JgLZVXjNElACUZMr5wvmovPVULhiORbS5kudZd5wjubo5z9cWMkb05lRBylSOLbajRmZjO0qyKmUpzq909GKlersYhmEYhmGMFn75MAzDMAyjr1ij1cvx1D4gUdeJWjvssMPa1JOSDFSq8BgYRuUYULQnKTjS6KQz+TlppkiVse00s6KzeQ/pLRXEhvJIiQrvUGKl/CqkT1X6beUJFE+Fk7ZT6daVPUmrk+5TFHQMgETbqtwkKpgS26HaSm+LKHUpGr/mVD/nigpyReo2Brziv2lD2p9185r3qKBwBGnfUu4VFUCJ1+z3ZpttNmzQtLieVa4Q5dmjgu8p7wxl1zj3WLfKN8M1zbmm7FfaW2hb2oTlct0rWVVJrKX8SdHLK1eWyivDtnItKflBrYXYLo4Zn1cyjfIKUl54UfZk21WgNdUPNR//LAKzlTywVH4ofs79R3kC1b4GqFxpnbLS7y+55JL22hguZpeZD8MwDMMw+gq/fBiGYRiG0VcMrLdLosgShcPAYqSHSaERUXZRp7FJ06kT7aSoSGeSWou0f423i0rdzvvViWiV3jieMuYzDMSlTnwTqk20uQo+FuujJwtpPtKWfJ6n4RUtyGfjyWwlaZFOJR2o5gEpUHrBqMBNEaSmSf1yDqvAQSo9tcpHFOlQ1s25quQ0laaca0HllojjwXbxvptuuql7vd1222Xrpj3Uqfk415RMynYompv1UQpSuXyi1MW2K+8J1qcCfSmvA/Yn9ltJC9wTKLUoyUDtj+x3TJdBqCBebBPrUzJPTYDEWAdtoAIYqjms9uZSmngln6rggrShCir3W9iGbSrlT+JYKlmQ7VBeNGr/ilIX/62CVHbqKMlkEWY+DMMwDMPoK/zyYRiGYRhGX+GXD8MwDMMw+oqBPfORtKmkuakzANTNlO4b9VTlnqaimlIrU4mulLtqrFsllqO2x/vZPhVtsBQBUSUtY920m9KsWa5yT4supyraJturEkSpRIDUkKnjxrM/bK/Sl1UCLdah2sfrqJkqbZyfq2SFymVORXaNmjD/rdYG6+O5HJ4LUWdgSmdSOE6cR2wvk8xtuumm2Win1KzV2MdEgmy70qPpcsr5otzAVeTNeM5G7RU8P8LnlY7PctRYqDNu8UwS62O5ah5wLbAPvIftiG1knzjeXPfKvTZGRh5ufyydo1D2UXukGiN1DiX2gzZ59NFHs/crN3Da+e/i3FeEcp8nOG+5dnkOiPZTe21sh0rcmnPH9pkPwzAMwzAGFn75MAzDMAyjrxhY2SVRYemnFOUvR81F10tSQ6SfVAIh1qFoWdJmjH5ZSqpDOiq6Aw+XyI5tZV/pchWjTrItfJ50YU1URj5L6o/3RMmHlKZyZ4zP5PqtXNJKERCV2yevSR3STsrlke1mfZRgYrvYD84RFW2QcqFyfVX0Zynxm6Lh1fxQbqlM0FVyf+R4s0+cX2pNq/WmJMFS29kOSjsE6yClrmhxzq3SfKlxTeT9lChipOJc+2Idyo1cSc6qfUqKjnKyck3l8zX7pUoIqlze431qb+GcomTHecB2qLABUU6Orta5viopQ0X+fRGkJz4bo0ZTVqI9aXPak4k0uX7UfFRRb+OaY9tpt87atexiGIZhGMbAwi8fhmEYhmH0FQObWO6ggw56FsXKf5OGYhdIs0WpRZ08J7U3YcKEbB2Kpq5NwKSkFlK5pAIj7Zaj0NRJ/9Iz0T65ftREAyVi3aXofDmQOlQSEz8vyU2KUlZeBCppGSUAlSApymyKhmc/eE1ZgjSpmnclz4mSJ0zN88NR3pGCVs+wT6RlOS7sH59VHl4qwWNpnbDtyouG9mCbKN1y3cY1rNackqGUzVVyST4b5WR6fCm5Sc15RbdzL+I+Eal0PtPrOlF1q4SZ0bODdmBZrENFaO4VJa8uzimuexWVmferqKZEjD6tEtYpGUslE+UYqaSTcbzZJ/V8Z/zSsz/84Q+dWM4wDMMwjMGDXz4MwzAMw+grBtbbJQXOSTQsE6FRDiBdxetly5YNKYd0EkFanDQW6yB1W5MgKlJlymOFdPTEiROzEpGiJJloj9Rr9B5Rwc/YJ95DyrvmRDkptUg/8z7St7QPT3bXKH+kHVlO7DftzHElRas8j9gmym+cE2xrPP2uknepU+ycB9F7Zbh5EOeakv8U7c9+KCmC11xHMZkiKWW2N0piw0lSaoxItUevD7VGVQItlWxNrRGWGSlyRfWzjRwn2kl5WbEdnENsd6xDBQfj2CuvIPa1xpswPsP9mc+z32re8X4lNdJm8T72VUmKlE64XpW0rMY+lsu9VyUSVIlClUfSMyL5aPwdx155cKokeJxHKmlorJtB7DjXcuPayykOMx+GYRiGYfQVfvkwDMMwDKOvGFjZJZ3+T3SWOhmv6B2e8o3UkMrtEr1UcrSeyvVB6jyevFf0pqK7FP2nAteoIEmRamPbYwCZ4fqhcmywzOhBo+hb3qdsw/qUp40KiBYpUJ4Er8nVorxSVACp6HlB2pO/U5QroYL/8HNSntH7QXlTKSmDNlRBktTaiX1QgYfU85xfXHtcC0oujR5XfIYeQ8o7h+OiAiLV7DO1Xl1sk5LAlPQUx7hG0mUdXGOsQ83/2oB2HGM+r3KksG7KNCqAoaL2o/zKvqr9le3g/axD5VSJQQS5jvkM1wPnlPJkUdLtBhjvKOmqdaXKZV+V1KvyysQ9ld+pyrus01cHGTMMwzAMY2Dhlw/DMAzDMPqKgZVdErWUfpQkohDlB9Jr9ISZOXPmkLpyIC1IyUB5BEQoTxF6rJDiWrp0afd6k002yZajcmFEKlydulbXPB1NupH2U+mpIxXHFNNTpkzJtknllFAeAUqeil4ATNfOtqtcLWp+qTwtpCcZ/CrOEdLnNWnE2VfeTypWyW8RHA+OJdvO9ilKl/1mXzl/S2A7OMbs61NPPZUd1xUrVnSvJ02alC0n0vhKclDzIJY13HhFm6s2EqxbBUvjGLFNpQBlKigXsXz58qz3lspXQ/vzniirKvlCrVf2b8mSJd3rqVOnZsth36J0oTx4lJygpBklaXEP5t4V9wrW/fjjj2fnI8dFrdd1YXPmT9p4442H3EcZhmuG3pK0s9rPlaemWqsR/M5huZ15VApGGGHmwzAMwzCMvsIvH4ZhGIZh9BUDm9tl//33b9PEpLpIzSnKKJ5c5u9UHgOerFf5RGrSb0f6U9GmPD2u6EKVe0ZRf5Hu6vXEt6IF2ddaSrgmDw7vod3UCX22r5T2WqVrVzljVH2kNlX+kVLeiJpU5eq0P8dbUerR5jyJrzxZVHuVtMZ5yvLpwRGfV1AeHUpSVN4gsS72iXOE65sSpspPRCiPsrhGSpLMcPNOeatwrpU8J2gHlU9ErXUlNar9Lq4xtot7i9qblPcWwXtYThwvzhE179T3hMqvonJkRS8f2qTG+47l8nO1r/2l4FGmAmHWeEKybrZVyWTcA2plrI40l9rwne98x7ldDMMwDMMYPPjlwzAMwzCMvmJgvV0SzZRoIZ6u5Qlldeo5el4oylbF/OcpdOWdoU70xrrpVcHnGbRF5fRQORBUMKqY60MF8+k1kJbKZ8A+RHvU5FlQtCDpUPZBtTvKbPwdx5X31cypGEAsh0iFq36o3CS8pg35OceY84BjEetQ1Lb6nLbhnGUfagINRSh6WUluBO9nv0tSl8qBVJurZbigU9ELQOUjUSnu1TqmDbgfqPxTsa8l74Qc1FjUBK+K1D1/RzsrbyolEanAbnEslKyk5pSSPJWcr8YltoXl8hn2lTZQsuPaGGM+y3wqcT/ifep7QgUWY5+4D0appSa/VG5+1kiwHZj5MAzDMAyjr/DLh2EYhmEYfcXAyi6JBko0F+kjRWOVcpeotMsq/wgDAZFWUgGCVJCd+DxpOpVGWdGsyruDZVKiiM8QrI91sE9KVmKwIeW5UkrXzn6zLI5F7EeuP4rOL6V+p23ZV0UDs08qv0q0k0otPxqHMuWtUsoro7ySiJr+KSo89qfGbmyT8iqiV4ryDCkF21LP0IaUlThXlPdWKfiSGlfKD6SzlTcJwXlaqosSwGOPPZaVx5SXW41Mw3GMbSJdT1txTau6CeVRQwm5FGxLrQ01V5WcViMTx36oIG9qLShvsT+hP2o/jvUR6vuHNuSeyv1fBZUrQckunXXsIGOGYRiGYQws/PJhGIZhGEZfMbCyS6IGI+2lTmaTVopeHyoQkDqtTKqZMgFzI7AO0mYxv4OqT51EVhSaOr3NdkRbqUBAKiCO8i7gNfOokCInpRjbq+pWFDnBZ5mngp4dlDpiP0hBs40cS46xSg3PukmHlgI/lXLfDDcHVQAkUppRNuRYsh20OZ9n+xRVqgISRfQqK7HfNXlNiJjuW+UbUjIU5xTXj5JIa+loQgWiY9vVHsD7ubdEbwTeN2PGjOwc5pznGHH91HgnxPHl80qi4rylTMM5xbXHeaC8NuJ9HGP2g9Ia92TWp4JDqv6UvNNU3ij2g/uUmpvPFe0olcux4XxRY6Q8x5RUHsdMeVh2voNLOacizHwYhmEYhtFX+OXDMAzDMIy+wi8fhmEYhmH0FQN75iPpSUmfpVam3CKp48YzAMpNVSVzUhEllZ7P6xittCb5E6+XLVvWvZ48eXL2HraP/VZuZFFrpmbKNvGcwcSJE7NaI23Lz6PbILVH1qeiE7J9HBfqxjGZ2XAuaPF3HCdq0GwfNVDamWdHas6qlCJVKrfWpUuXdq+nTp2avadUt0pIplxL6TrOswGbb7559p7acx3KzVRpytS8GdVRJaWKbp8qGqxyO6QNOb9UYr7S/CKU6z/bq87QcOy57tW8Kbm6q4iqrJuRWdnv6dOnZ+8pQe1N3BPUPODc5lxTe378t3LnpcsvXblpJ6577n20eSmEgHITVm67KmniUjH28eyEihLLOUz7q2RynJvsN88NxTN8Kikex6lTtyOcGoZhGIYxsPDLh2EYhmEYfcUardGEX1wJSPRbos3e9KY3tWk1Ul+kdEgxkWYjpR6pIUVhk8YinVZDeSv5ptOX3O9Yrkp2p+g7NVwxaiFpO9LOdMGiDRWlqKSSUoIuZUMmQ2PiL5X4TrlWq/tLbSfFyOfZjho3MdW3iJplxTFTZdXWV3KFHa5NnB+kaGvaF9tYGpscSEdzvSiXwCjxKRpfuS3WuL8/8cQTWbkv1q1swjaRxid9rdwcuSYp3cVIn9HlOAe1FthuZQPKLtGtm3sqaXy1V9e0Sbk0Rymbconqh4p6Syh7lCKzcp2oaM9qH62RI56HuuP9bAtlEYaZ4Hcf26dsUBMCoNR2rqVOX9NnF198cbuNSjrtwMyHYRiGYRh9hV8+DMMwDMPoKwbW26VE7UTqjxQhT//G51XUT0JJKkoCIEVFaj/ep6JIslzew9PNpNNIc5Jai5Q6KTVKC4pOVXZS/aYXRfREUSflVSRaUv01VGwp+dOjjz7avd5ss82y5dZ4DxHKNhG0FecFvZhmzpyZtSHBfitvo9J4q/nJ+fXQQw9l26SiRpaiLyqwTUoWoj0VpU7Ez9VYqgRt7IeaX4yAqxIxxrIIziOuV6432ll5qKjEliWZQUkftLOaK4TyUotlcX7SVjExWq7fXPcqgmccR5Ugj31VcpVab7QB93C2L/5b7QPq+4NeN9yXfod9kGVGm9Mm9L7jM1H2z7VDJSSkl1uUupTcTumvszfV7g0JZj4MwzAMw+gr/PJhGIZhGEZfMfCyi6LYVRK2SK2RKmMQI0oFyvNFJf4iBUbqKdL2ykuFdagT5qyb1CPlmJIXjKKj1UlwRRXz5D+TySnKtBT0qBQ0qRevAVKjkY4mJRllsFy5iiZlfTV0fryPwYM23XTTrK2UPKISRHGuRcqf9Kui4Vk3A5mp+UFwvZXmGqlf1qdkArab8tSsWbOy41iiowkV/I92U146XAv8vJS0klCypbKzsplKTBbXFelzFSiMfVLrk/eU5EXOBbad8u7jjz+eLVcl9lPyc5znSqLiGFOOVt44bB/Xp/IAjG1RyeGUXMjvG3qrrINxZQLLuM+o+am8ppQHJ59V8mLJ24Uei9xDOrLSSk0slzaIt771re1NPumC22yzTXPrrbcOMcDJJ5/cjpKZfr/PPvs0ixYt6rUawzAMwzDGKXp6+Ugp1ffcc8/229MVV1zR3HPPPc1nP/vZIQcJP/OZzzRnnHFGc8455zQ333xz+8143333HfIGahiGYRjG6ouegox9+MMfbn7605821113Xfb3qahJkyY173//+5t//dd/7VJMid75+te/3rz5zW+uDjJ25JFHtmk1nhImzUOqkTRbPMGuKEZ1kr8mD4rK81KSHxQ9rLxgFE2taL1Il6vY/qQb01jlKFAV7Ezl0SgFfiINpyQLdQ8lFUXdKo+F2C7lbVFjT9pS5YiJshRftmsCwynZhOA9cT6xr5yHlG0oa/APBuWVpTydYvuUjNWrPZXsEqU1BbXWFZScpqQ4Sp7xdyrontpnagJylWRVRW/zmfTHYgdbbLGFnLe5drCvtVQ67ak8l7guVK4otfeVbFjjJUco6a/krcF5OG3atOzeWSPjqkB8fxffMXHPow0oi1M+YluVF16va7iETh1pDnzjG98Y+yBjP/jBD5qdd965OfTQQ9suTDvssEPz5S9/ufv7xYsXt3WrJLXwxWC33XZrbrzxxmyZaSNKhuKPYRiGYRjjFz29fDz44IPN2Wef3X6L/tGPftS8613vat773ve233R4YIYHWTr/5mEa4tRTT22/oHR+pkyZMvLeGIZhGIYxvmSXRPUm5uOGG27ofpZePm655ZY2s5E+T2dCUqAnpmVPeVoSvXTRRRdlmQ/SsIn5SC8gRx11VLu+GsqvRJXVBNRRZSlvCZ5yJwUW26qCeI0mLTeh8ghEKpD0pjpVXoPadPIK6jT9Aw880L3eeuuts2OnAsSR6o1tHI1t1bPpBbyD2bNnD7lvNOeaSrlycvdEKJuQliVVzLGvsW1p7SjbqlTqCjUBq6JHWa9zmKjJ+1Ga82wv20EZWJU7mr1hJHOY3iBsK/cGtql27Gug5BEl6fLzyISzr5R2evGyGIu9QXmU3X///VnpUAXvq5l3tajxYuLnCxcu7F7PmTNHrikl9+bkqjRvzj///LGXXdILBb8cOhvwkiVLhmjeK1asGHJP+jf1cCINcGokfwzDMAzDGL/o6eUjsRp8W0q47777un9RzZgxo/2SMW/evCFvrsnrZe7cuWPVZsMwDMMwVpcgY8cff3yzxx57NJ/85CfbUsr8+fObc889t/3ToV6OO+645hOf+ET7XEh6GTnppJPaXhUHHnhgTw3r0H61ab1rAn0x8JOKj0/PEAbQUfRrKYV4zalrdT/rpocKKegSlcfn+TvVJkWB8lnl5RPpaNqBLBhpQTJhzHVQkypcpUWPbSRUsDOC7WM7aP8U1ybnTRApyV5lqZq09KSZIzXKfjO4lAoGp6jwmpP/URYaTSA5lWKdkk3JM0QFe+oVKihTyVOA7VUeDzUeFr3OiZL3nILKC0RZjnuGyrdUmw+JUPO5Jl9QzBHDtvAcIcvimUPKKDUyG/sdba6+Azgn03de7nm2g219Gp5HbHecHyrIWM13kQp6R9m4FESQ482yGCytc8xC5TvKoafVussuuzSXXnppc+KJJzYf+9jH2oY+/fTTm8MPP7x7zwc/+MH2Jnf00Ue3DbvXXns1V1555bPc1AzDMAzDWD3R858Kr3/969s/CumNK72YpB/DMAzDMIxVJrdLoofSD+kgUkmkHRm+nad2IzUUU7/nqGJV30ignidtxtPcZIdI01EiUifmR3JinzQrqXrlIUTKjvRbiZ4kbcrna+jQGpSkOPZVedrQ5srrhnZWwdhifTVQwZSU/SkFxbo4hykTpVg8ubUwmpP1vcqJJaj5xXEpSSuKgu61H6TbuRaUJBXbSw84FURNBRyrofNHuxexLNqMQej4OSUNpluPcmONlKG8t2h/dU+0Oetj25WnxyOPPNK93nbbbbN9UM+uLJvTNhNEfpW4t3ecOkr9UJJHTV4xJT2V5By2vXNPL95nzmprGIZhGEZf4ZcPwzAMwzD6ioGVXRLdligeUkk8sU16hzlfYmAwlbdCeXT0clo3ItJ0lFRUOnNSXKTB2D4ldyiqMj6vnmHgId6vqDn2QXkFlTxk1MnsmnTrI/FkqMnfkFIC5PJfqDTupbmi6Nsa+UflUWG/S5QmpRaeuFc5eFRZ6lS9CkQW+9crWC7X98MPP9y93mqrrbJztjYvDfutZDoVVEuNRUk2oNRCCYZlKW+SGDRPtVut75p1otYCP99oo426108++WRV3qgaCUZ5Fal9omRzQq0TBtbj/sXcYNOnT6/K1aUkGbU2SmtmuLGI84DfGZR+KV8rG1ASVOuefaPsWAqkSVt12tHLXmDmwzAMwzCMvsIvH4ZhGIZh9BUDK7skSied+CUVRcq19pQ76VBFfdWcaib1pDxDGAQq0l2kJ0npqxPmPO3PcpQcE/tAGlNJLaxbSRGk+1TOikgRqnaRpmM7lFzBE9+KUq8ds6eeeip7DyUKjqs6qU7EZInsK4OoKdlM9Y+2UYHFIv2sJAD2SQVBYx01AaTielP5gmpy1NRQ9aUcRjVp7fn5ggULutcp23Yv+TZif2grtS5pQ3obKXlESTORCudaUutNjYWSVdV4RZtTHuNcpRwwefLkbDtoZ7UWKOvcddddQ+recccds2XVBFLkeKXAl7lnU14yNTfZRl6rdPfKnjXy7N8L65v2jN85ufZRPlKyMcspfZfwdxzvzv7aS44dMx+GYRiGYfQVfvkwDMMwDKOv8MuHYRiGYRh9xRqt0fjJrQQk99R0tiDlhkm6FbVOFQmQ2mhtQp6Sft7BsmXLutezZs3Kal0lKLerlYE4jKUkZB089NBD2ciwNREMS2DdavwIpX/XuH2W2seogHTXjPp5DqxPuWGuLNAeyu0wZpdOGadzUR1rzseotVQzdrFdBMeJ7tjUoFWEU6699ddfXyYFrBmPfq7Dkj3YP85NRl4unePqdfyiW3IvbS1FlVX7Cc8QMKEk2xSjZw6HeO5oZY+fWnuxfzy/o87O1YRtaFWsvViuam+veyfBeRddjJW7ee7cZdorv/nNb7bts+6662br6tZZ/K1hGIZhGMYYwy8fhmEYhmH0FQPrapsow+TiU0M9khaPVBldjp544oksfUQql/dvuummWalFRU+MlFZN5DuCZdHdjJS1SkQX6Um6lpLCI8U7ceLE7vXTTz/dk/sjpZUoQ5HurRk/FTWvxiUzukhyjGfOnDliqUW5lyk3uRLUuHL8OIdVgim6aHPsIs1d64qcWwu1UksNDc9ySeUqaps2p9QyEtAGpeSDvURBjVBRkpUsyOspU6Zk3Tvpoqrc0SNUOAIl2XG8ahKBxXtqXEiZDJPrhH2lG39N1NWSS66SO2rHMvdsKZou1y77rb6LVJTj54gwCHHtqT2kJkpszfeNiogay2J7GWpg4403flaZw8HMh2EYhmEYfYVfPgzDMAzD6CsGVnYZDqR/KEWQdo9eDhtssMGwdFyvyYNqqXdFfSlpgSeFebKasgTLjAn1SFuvt956WVpdRd5k/0jXKpp5JEnfCJVQSVHn9BTgmCZMmDAhW1YNVDRQona81TOkJWuSzHG877vvvu71NttsM6QOSl9su5KbVHRV5TlWQ89HKOlKrT013vw8jotaV2qcSsm7eoWyCdur+kSKnfLuokWLslFy4xpTUqyK7Eooj5NayU3ZVu2dnPOMLEr70fOOczvuazWeZ2yHihasQEkjyksqYiztzCjQ9BrkvOWc/QuuuZfFuaXmGhPLcT9hfWoOskwVGTeCv6O01im3F5nLzIdhGIZhGH2FXz4MwzAMw+grBlZ2SVRR+lEBiUhHk4KMlCJptBrPDXXCXNHUpQR3pDEV1clnFHVO6pG0Fr05KM2U6GiVLEydUu71ZHxsI8vl+JEuVNIOQalljz32yH5eC3XyXIF9UJ4oke6l/ZVtOT9YLk+b33333VnvgOhhVCMREoqSrwlMVYKSS9SpfkWFsz/05CFtH6ntGnAsauTCWs8Jrg3lkcH6lPyz+eabd68feOCB7vX2228/pL5f/vKXPc3hGnlltAH0SonRcqA9uJc99thj8hl663EPUe3g/OJ3Bp9V/Y7rluUqrxZ+XynpQyUPfBoeh5zzCdOnT88+o77fVlYwtrEMsmjmwzAMwzCMvsIvH4ZhGIZh9BUDK7skOinRWfT6qDnZHk8oK28SUpWkgVXgFZZLurBEr5PyU0Ff1llnnWzQFgYh6gRwic+Seo91j8QrI0cvsxzSiIpez7VlOLmDMgPzknC8pk2blpVaYt2luZAD7cnxIq3Ke5THT/x3DaXP+1k3JTTWTa+lKLvQ5mrsldRSE8CNtoxUL+lsFUCM1wzQxM/ZB7XeFNVeqo9lqRP+KiBXKYhgzZ6gZFk1XmwfvWAWLFgwpG5KcGpdqaBTNR4xRJznKtCe2itUHWq8uCdGaZN7JNeDysXENtVILUQcb85b9d1Q0z+1N6yFvs6YMWPI71jfk08+me0fn6G0VrMflOQ3FQhwJHmICDMfhmEYhmH0FX75MAzDMAyjrxhY2SVR8YmGqskT0msuixL9qmh7RdGqoFElmYj5DRhIiNfqNLwK1lTyvFCo6ZMqZyQ2J1gH08PTBorypndTDKLVa7uUB44qs0RT1+Q1oLzCtrPcxx9/PCs30espjndN8KVeU8srTyXSz7EsFZytBpzPPNFP28Tyew2i1ms7SvJijd1qZA2WS9vSc2KzzTYb8gyDke24445Z7x+Vor1GAqDNSvO6xnuIe7ga19pAcJRaWDc9g1760pdm14ySp9RaiOtIBUBU6FWKeE4hbxR/xz2S48R9g9fbbrttNiCdmh8RyhtxJIEHCTMfhmEYhmH0FX75MAzDMAyjrxhY2SVR4Il66lUCiNSfCgaj0pmrE9s8ZT137tws3Re9AOi1QI8Vps0mtVoTcKk2AJKiBRUlrE6tk55UdGgM9MR8OgycQ2qPdOjOO++cPcnNfA+77rpr1iOmlhJWgc8Izh2VrnskdD7zDc2ePTtLR3OucB4wf8LSpUulxMecEjXpyZVtFPWrclPEtvTqPUEJcsstt8zan3UzuFasm+OxePHi7vVuu+2WtSH7quaEyssT6yt5QeX6oTxiWCbneQwyxqBTt99+e/d61qxZ2TVG7yjlhUeoOV/KiaNk3BqPRYW496kcT1tvvXV2vXF/5b6rAq3deeed3eu99tprSN2ULJR01WveojUr82WpdalyfXF+cH5xf2XANrX/x7lD2Ss3d2rWf7dP1XcahmEYhmGMAfzyYRiGYRhGX7FGqxeepA9I1FaikI844ogRnZwvdUcFvlHBeJQHCCk70sak1EuST80p6JphUYF1hqPJe6lb5alQAdsibcdT16RfSRfWUL//l9NUnZKvPQ1fk0eFcgIpZMpWtd4WvdqqJuiRyrFU2w6erGdZSgrlmmSeC9K+UW5SVHqNPXpdnyN5RnnVcS2oXB2l4Im0J+fRdtttl6Xba7yyRrveVL6ZGq+sUjtUHi7ep7zhaCdKxXPmzMnKn6VgWzXzayRzqgY1wfFUoEjVDpYTc+tQnintf53xPf/889t25H6fg5kPwzAMwzD6Cr98GIZhGIbRVwyst0uikCIdXHOqPn6uaF2Vz4V0Fak5Ukw8lU+KL54SVjkiiFKa7tyzrIN9I3Ubf6dSO6v8BMq2pDx5P0+BR9puiy22yJbLftBOpEljn4ZrX4lWVJS3onFVjhIizs+aU++8hx5U9IYi9V4jT412ftE2HFfKdaV2qOc5v9Rcrcntsv7662c9oKKnlMqR0isVPhLZhe1V8hjbxDXJ+lSenLi3cFwpRZHq/tnPfpYNvMVgejXrvpRaXl0T7B/XG/tQIwdE0FZq3tLOrJv5pOgZpYJ5ldqiPLNq5I7auamC/KngYEoeKXlI5jxl4jykjE50bNtL4DEzH4ZhGIZh9BV++TAMwzAMo68YWNklnUwueWmM5CQxg+6QSqJMQDqOJ/QJBv8p0YIjyR8wXDCwGqoyoteAOAqkFEm/RXmE6b55erzmxLYKijVasA7SrwxIVNOm0YKn/Snz0LbKZqU2cb6ovEWjmR+19lB2ZqCiGoqd/aHNYl4ZejBwffdjLGtAe/a6BxAlqUvdt8EGG2TzJ9FDSEldpbqVpFtDufeaX2Uk+yVRM4cpna+zzjpZm0WvD1W38lYaS/wW87zGtr2OS2k+qqMEHTv38p1i5sMwDMMwjL7CLx+GYRiGYfQVfvkwDMMwDKOvGNgzH+kcQSnCqTprUYoEqFwb6TpL7XEszxzURBWsATU3anMqSmVJ81P2pW5HPZQaKJM0xbMxPMsQNfqVDdpBRVmke9pYtk8lIeO5BJ59mDFjRnaM6FqqXOlKKM2FkZZTqwmrqLu0c40bs3LTjWDiPerttdFgVwbYP7VeVTTW0UKFFuC48LwWk+7xc7appOOrczq9Qj07krMu3I+UnWkPzhvOu80333xIHXRRpss3k/5xffc7KnNL2ECdGRzL77eRwMyHYRiGYRh9hV8+DMMwDMPoKwZWdkm0afp5+OGHs1IJ3cVIh91///1DyiG1zWtKA3RtvPfee7vXL3vZy7IJmxT1F5O71USnrIk4R6i6o7TC+tgu9mPPPffsXi9ZsiTrfnrfffdloySSXoztZlmUZ+jGFm01VlBUokr6xuisdKVjOZwf/DxS+4yIyPtoK9K9nMOsgzTw9ddf370+4IADutdPPfXUkLprqHuOk6K51XyslQbYb/WMSvA1d+7crDu7cpdMePDBB7Nu8kzIxzZRBtloo41WynzkWlRRhHmtJBG6KnPtlKQ8ljthwoRs+xgF9cYbb8wmxlQu4Ql333139/rlL395th018yVGbc31IUqIao9kfWyvagfnBMvk983rX//6Ic/84he/yIYTeOCBB7Lzk7IN3WOXLVuWHQvO35FA2YBQ8iltHvcGlsV5EedkLGc4mPkwDMMwDKOv8MuHYRiGYRh9xRqtfh/JHQaJBk909BFHHNH2xlBUEqUBJpeKiW9WRveU90ikCPsZWTHWXUM3kiKj3XhKnlIE7a9OVq/Mk/y9QkW5VJS3SopW63lB0FaUSDhXH3300WEj2vZrrvYTKkEkx4v0Lm2zYsWKIWWRqiaFzed79YT4v5ybKtpsyfNPUew1oHzz5JNPdq/32GOPrARWGwm1V3sOyjwteRD2Gol56dKlWQmMHoTPVMzTQZqrSirrrOnUn/POO68tI3M95mDmwzAMwzCMvsIvH4ZhGIZh9BUD6+2SaJtE5ZCWInXFk9k82c4T4pFWJBR1pWQelks6ju2LJ7HHKrBYDUrJg9gn3sdT1/QEqjk1XbqnhhbkPYrWU+WUTlQrDw1SmqxD2a3XpHuxDp5upxcMP6e8pWhcRXOWoGzA+Vgzz1eWIlsT3KiWWuYcVt4rvXpC1KIm4BXnKseFe4hKBMhy4hpTCfx67R89Fuhldd1112WlwjiH2T/l6TQaL77SffRypCw1mnGlXUcbhGvKlCnZshiscUsEuORaH8meujLmb7xPzbXOHK5JYjci5iNNopNOOqn9RZUaMXPmzObjH//4szTLk08+uZk4cWL7nn322adZtGhRL9UYhmEYhjGO0dPLx6c//enm7LPPbr7whS+0fZ7Tvz/zmc80Z555Zvee9O8zzjijOeecc5qbb765fbhm3333HfKWahiGYRjG6oueZJcbbrihecMb3tDst99+7X9Pnz69+fa3v93Mnz+/y3qcfvrpzb//+7+370s4//zz23LJ9773vebNb35zdV0poFii0khXkWGhnFKih2uod9LfpAj5ucphwFPJpUBffIZ0FenXsZRpWBY9gxhkjEHDSFP3SvWXaFXSsqR1FS1Le6p21MoBNUGylKcB263aGuUf5g6iFLjDDjtkPQfo9TESmYegrUiNKppaUe8qD4SyTRxXlVtkrCScWI7yXOrV80LtDUT0fuA65nqjZ8J6662XbUdNMLbSOlTjWiOzsVxeM08O+/qzn/1sSN2777571mOLY9HrHqK8vUpePkqi5fOcE0oSUGMf12RN0EhVLu05bdq0rIcR59OcOXOGlEUvr5rvCbWfKMlazYkYPI55p0YrBfXEfCT3q3nz5nWjXt5xxx3tCIyvfe1r2/9evHhxewNOUksHyW02JS9iJL24cSX3Wv4YhmEYhjF+0RPz8eEPf7j9cjBr1qz221d6uzrllFOaww8/fMhffjGsb/o3/yokTj311OajH/3oyHtgGIZhGMb4ffn4zne+03zrW99qLrjggjZlf/vttzfHHXdcM2nSpObII48cUQNOPPHE5oQTTuj+O73cpFPCiREZC6pWyRrqBHxNbHqVOr1Ey/IZ0ncrC8xRwJdBXpMuHw1q5SJS0KSmaQ+VjlzlYojUH+1MCYcyHdur7MS8KyrAD0/9xzYy9wMDuCnvB0JRyET8vCaFdm1eoBxYfjyJz+cZQGmspBaOacwnMVrPoOHkCiL2h7ISn+HnyrZKGqvxLiu1kfUxbw7nAalz5XXDtRrz3lx77bXd61133TVbX68eb0omi2uE7a3x8qmZ25RmiLg/0g7qmRpwD3gx9pkNNtggm2MszimOn/LI6VXCV3mHYhtp81wun17WfE8vHx/4wAfa7Efn7MY222zT3rwTe5FePjouhUmfSt4uHaR/b7/99tky0xdPP76MDcMwDMMYDPR05iP9BRjfitIbVucvjuSCm15A0rkQMhnJ64UZKw3DMAzDWH3RE/Ox//77t894JEo5yS7pFPTnPve55qijjupSL0mG+cQnPtFsscUW7ZeRFBckyTIHHnhgbw1bc832jwoWRHqX1FzJpZf3qZPSNUGuSC2Rko8ns/nvsaKg+fJHzxWmZE/Yaqutute9ujnXpLomYt8ocXQOJ5coRp6yJ01a4xEQpS4+Q9pUBfRKHlu5+UEal2VSfqD9IxXLgFeUZ2oCp9XkoYk2V+uE9qmZ/wTr4ByKNLySWjj/b7rppuxYbLfddqMK6qTyvnCuqXLVPGf/St4WBG27YMGCrP3TWbmRegrEttbMo+QxmHue60LJEvyc+Z3i7+hIwD8wayQYJUWroGsRyvNM5e9R461sEKWL0ch6Nfgb+hNtzt898MAD2THmnkpJhLZV+0Spb7Qt93bukR2vp16CjPX08pHieaSXiXe/+91tHTu9VPzLv/xLO6hYBx/84AfbDTz66KPb7oZ77bVXc+WVVw7ZcAzDMAzDWH3R08tHyiCZ4nikH4X0NvWxj32s/WMYhmEYhrHK5HZJNFP6IWVEGow0kaKsa08ljyZdcYmWXRlSCz0nSOczkFWJ9qyhtms8fkrB0WgTnoZXlJw6aV1D4ZX6wznCMa6ZH7QZ+8M4NFHOYl8ZfKlG1uA8J52pvAByZ69yz7CsmKZ7uPuVN0Kc82qe07ZkPimzrSzUBA1TqJValP1TXKPc55zPvaaQj/fX9EkFH+PnykuqtKcmxjvXjltvvbV7/fKXvzwbWE8F76MURBkvrlvaQeXbokRB+/NaSZilMRqNh4tCS6zvUjA95oyhDJLibOUkGGIk+bLU8xyndMyiI+ukYKQ1cFZbwzAMwzD6Cr98GIZhGIbRVwys7JJop/SjJIPa2PUqaM/KTlc8ErAd9F7hdYfeivdTZok0Pm012hwivVDIEaRGVc6F0aaxVvWpYEo1oLzFsZg8efKQ+5inodcgSzFgWa7dpMtLFHBNOvmaNtWCa+7+++/PUr/Lli3rXqeklLn5eMghhwwbJCmdOyNIOy9durR7/cpXvjIbSI79Y8CyXMCkXqDWWM18rsllEsvptY0q5w5ll1obUGphML0lS5Z0rxluITkdDBdwj/WVZHAln6q+quB4ve4Bg4Q1xBymhxf3Is7/lCIld4/KrxX3nbE6SpBg5sMwDMMwjL7CLx+GYRiGYfQVAyu7JPoxUpAjkQxUWntF+6s04uoUOinIWkpK5ZEgJUl6P4Wxz1GjqsxcIKheqNhe82XEfqtT2yORakYDFcSIdC9P2ZNupP1I15L23WWXXYbU99hjjw07F2ibmnwiCnFcOJ+5bkYjY9FOypsg4amnnupez549O2sDpmGnNEN7kqpnUEKOUWmNsY0qsBuvKdmMRGpRY9brPqXapO4ZLZTEwf4o2TbS8LQ5U2pw7qRglDmPMHrBqLxbpXw6yuNRSY2qf5xfo5Wla9aMyrf0XNG+0lxV64GSJ6XKO++8M9uObbfdNvs9FNs1ljDzYRiGYRhGX+GXD8MwDMMw+gq/fBiGYRiG0VcM7JmPpMNFPavmTAWj3sVnqP/VnO3g50o75/1Rl1XnGqizsk08z7HTTjt1r5944olh2zfapEdsK8tV1+oMTO2Zj5r7RwI+zzFWduM9jF7KceH5D7rX0lWt1D8VxZB1xHk73LOxLurWNVBzh+dFqF/TBnGMmGBv5513zrq+qkir1JM5Rvfcc0/W5tGVXp25UudESpE7ewXHgP1gHeoMAevm2HNvUG6ipTVTs5Zq7mE7os3ZXpVwkC6gvOeaa67pXr/sZS/LumKrqKQR3C9ZH8eF84NlqSjC6roWyrbqnNkauF9FZo2/U3WoBHKse8KECVkb0P09urPThVftAyNy0e/5CcMwDMMwjFHALx+GYRiGYfQVa7TGMmTZGCBR34nmSbJDop4eeOCBLK1EmoduhtHFVCUIIxVIyk65RNVQgaW6Kduo6JQsl5T+fvvtl01YRqps3XXXHVKWonujC9dw7maKtiSVF/tD25ICVYnRamhjNd5RflB0L/tE2pjULd2b99xzz6wL4Xrrrde9jq7gKine/Pnzu9dbbbVV93rjjTduekmIRze56dOnD3nmJS95SVa+YFkc45tvvjlrgyOOOCLbbt4TtwzKVQTtzCRUdBtUyc/UWo/0LstlMrMLLrgg296HHnooO1dIQasoo1FqVLJUjduzkqGU/FmSH1ifKle53vNZFUG6FDV6yy23zNqzxg1WRc6kzWK7Kc/wPiU777jjjlnJR8mwpfGmTTjvlBu/mrdKKmmN4Ku4Zg4qmZlzrbSfs1z1fGcs0me33XZbey+N30nPavuwvTMMwzAMwxhD+OXDMAzDMIy+YmBll912261Ne9UkkyM9FulJUs2kifjMvffem6UOSZWRetpoo42ykeQiJcw6br311ixlx3tIR5POZFQ/RgUkbR+HkeU+/fTT2WiUpNdIu2244YZZ6pxSEKn2SMvShpQDKCGQMlXyEal+yhXsa0zIxr5y7qgEbbQzy9pkk02y9mf5r3/964fUzfouv/zyrGzDe1gW+8cood/85je71zNnzpR0NCUj2mfOnDnd6xtuuCHrQaLkKXpZTZo0KRuxMraXUV8T/ZprE23AsjgnuJZIqTMSY5x7bCPt8eCDD3av119//WyblBTKtsaEWxwDJcsqby+Wq6QZFbE1JpKkDbh+uDexbrXfcR5wj4r7Gvc/zuFp06Zl9zJlD9pczbWIRYsWZT/nHKENOR9pMyVpKa+SOE6cU9wfWBbHjHs17bz2CGQX9q9GdmF9yrNKyW8RnEebbbbZs+pOv0/fdZZdDMMwDMMYOPjlwzAMwzCMvmJgg4wlGijRjuqUNilJXsf7VWAs5ZlAqoxUFK+VhwQp/Eg7k+5ifZSFVPAZ0nqKpuM9CStWrMjSjYpipD1IL/J0uTqJHz1OSLmSwtt0002znhtsO8vi5ww6xUR79F4onUJX8h3nBGl1UsscYwbcWbBgwZC6t9hii2zdpD1pZ5a1ZMmS7jXpSt6jkoDF+xhIaMaMGd3rW265ZVh6X5XJMY10KhPqXXHFFVnPLM5triWuC65dtVY5DxJ22GGHbJ+UpKjkFZUEjPdHj4peA/spTzO1Ry1fvjzbpviM2r+4T7Fc9kn1lWMRvX9YFuumxMo5z7nKeaBkNs4Jrr04JzkPKZNSHqbNuZ9QMuDa41yJ8gODb7HtlK74PPv9ile8Ihtc7atf/Wq23VHKZlsOPvjg7vXXvva1rKSovF1e85rXZOV1jmNcI9xTzz333Kys15Hzewk2ZubDMAzDMIy+wi8fhmEYhmH0FQMruySqJ9E/ijokradOi0fqS9G6pG4J1r148eLsPWxHSQJQYPt4yps0GOk+0t+k2SIFTEqNVCcDBKnAN6Q9mbejJmhRLJdeMfycZSnvFdKZtCWloK233npI3XfddVfWbqQS+Tntxj6RUmSbSIfS/pEi5riqgHakhEkh33///cPmfoi0rDplf99992Vtzn7TNmwH+/P4449nr6PcSK+dvffeO0v3fulLX8p6L1BWYh20U/Q44fyit4UaC44xaXgVAE95EMTn2XZC0d9KxuX8oFxa8rQh2A+26aUvfWn2cxWUjHOWMl4pkBbtobyvuK+xf9yjKN/Efm6++ebZeXHHHXdk1wn7xO8G7iEqcBYlnrgHcU7x84cffjjrXfaxj30sOxavfvWru9ff/va3Za4mriXexz2I9uAecOWVV3avP/3pT3evjzrqqGwgS0qnCYcddljWVgy42JlHKr9VDmY+DMMwDMPoK/zyYRiGYRhGXzGwskuiHxM1qfJ4KAoznignrag8OtTJbgbQoRShYuXHk74qv4E6YU6qkrQnaTpFFUcoul61T9G16kR/TVru0vMqb47K56LyzUQ6eurUqVk6m8+Q7qVkwLlCbxcGZeI4Mu9QBPuk8qtwjBVU/opIb6q8Iewr5w5lR3Van1DSTAz8xTGjJMbPDz300GywpptuuinbpqVLl2Y/j+uSfSIlTJsrqVLlmFFp0Uu5PpTXmvL4oQyo9omRrD/2j9dTpkzJ2l+VEz1OaEO2gx4kXIeUijlvue9yr+Xnca5RBuZez3W8cOHCrIRD+1NW5Vxh+ZRmYj4lJS/Qtvvvv392bl522WXZMeYcjB5olHC45zF3DYM1sn/0juHecPLJJ2cDJtKDJv7uzDPPzI5N5zujFKAswsyHYRiGYRh9hV8+DMMwDMPoKwZWdkm0daKeVEAo0jslOpr0twquQ6qTp+9VCnnSk6SB4+loUngq/j9BupH1qXwzpZTbNcGDVFm8nyfdKWPEoGYEx4ZeN6QkSbGTxuX9LIent0s5TuglQXqS9uE4MRAcqVs+S3swNw6pzRjQ6/rrr896gNCGnB/sB0/00/OF5cd5zn4zjwSDL/30pz/tXs+dOzdbVinYkJLSaBO2kfk6OMak8dk+0t+8n2NPGSn2lRKMCsbHtvMeylsco1LuDSUdsg7lRabybSgvE0oXpfWn1h7HVQXh4n5QSjlPzz/uU7TbvHnzss+zDraJ8/ef//mfs7msImg3BjDkWmL/uF5ZH4PhcUyZkynOSc4XtQ+zfQzER/tvjrVO6S7KF5SPuK4YdE/t5+q754wzzsjuidyXSsETuUd25ksvqeLMfBiGYRiG0Vf45cMwDMMwjL5iYGWXRO8kakul4lYx+OMpYXV6n/QTA1ORViJ9x3aooDkxBwLlkhoPEp56Z8Ax0t+k1lSellgHn6Gt+LmiX0ndsg6eTo9eN+w3aXWeNmeqa+YcIZXHk9n0+FEUdxwbPq+CapFuVMGeWCbpT57ujyf8SYeSSmdZpNUZIIvSBSlQ9idKIupU/84775xNX895q4K/8R4GQ6I3QbQDJRheq1P59CSiPUiL08uANoi25RiTwib9rTzE+Cznl8p7E/cWFXhLSb1cb+wT7yHNH2l4SlGsj/OW9lR5ZViuSvVOmSBh9uzZWQmANlcyNe3J+1Xwtyht0rPq5ptvznpEMfCckrRoP0o7lFriXCPY3pq9lt5zlGS///3vZ8cuzjvuA8p7iN4ntL/aN6699tpsmZQ/E/77v/+7yYHrpDNOpeCTEWY+DMMwDMPoK/zyYRiGYRhGXzGwskuijdIPKSNFS5XoaBX0hHQVKX11Ml5B0aqR9iSdrQKT8XNSh5QGSIGSHov9JG3Kk+Ck5xVFqGhSSkH0XCkFvGI7KAfwervttsu2SaEUiGn77bfP/k4FXCKYWlsFiFOp10v5LJRnA+ll2oPl0JZR1iPYLtKh1113XVbOYbm8Zvs4Z++8805J4dPj5KCDDupe/8///E/Wo4An/5mzgrLVD37wg6yHy+677z6k7quvvnrY+UWw7Rw/5bmi5Kl4H22oZEFS0rSzKlPlfYq/U0EPec09kuPFOaX2pejBwHm7YsWKrLSsbKjGhXVw/kfvpssvvzybS+sf//Efs7Ig5eHbb7892wfKg5yblJTinqfsowLDUdZ4wxvekJWVzjvvvO51lC/4bwb9+spXvjLsnCJoT+abOeWUU7rXr3rVq4Y8Q/nvC1/4QnZOdepWxxxyMPNhGIZhGEZf4ZcPwzAMwzD6ioGVXdKp40SNMeAMKT5STCpwVok+V94PioJWHi6kuyNVpigoUnOqHzy5zJPSn/vc57L0Ygw6VJKDcvfQ04NtIk3KOkqpxmkf2lm1g2OmZCgVmC2ON23OE/AMlEMKlNQhZQmmleY9y5cvz9K1EbQbx5JeHJw7lCXoAUIbkCKPddcEb2KbKAmq1PC8n+NNr6zoIcBT+QxGRQr77rvvznpOsH+c87TNj3/84yF1K+mK7SWNT6lSSQ6Um/jsvvvuO6RuFWyQY8H5yLYq2Ut5tsW1w/7Ra0Tlv+L64fxXdahAXfE+5g3hGL/lLW9pclCBIlkfvQ+jpEvvOc5hzjWuN8rXlPUox9ATS3mPxD1SBdNSRwBo53e+853d6ze+8Y1Zu3IdJhxwwAHd6//6r//Krj3lfUXZl/3jWuA4sn0Jhx12WHbNcK13vIec28UwDMMwjIGFXz4MwzAMw+gr/PJhGIZhGEZfsUarl0wwfUDS6JJr6ete97q2ZqZcs6ihlVxt1fmMUlTU3LMEdS+2o3TmQ7l31iQoov5Hl0dqlbHf6owK26hcAtUZAJX4KJ7HUH3l57S5OpejXIFVRMFSgjy6F1KbVvWpckpudUrvVGeKCNpDzdnSUlX94HhTs+ZY8lwDzy7w85IbH5NjMXLk1ltv3b2eM2dOdr0ywiP7R/dyRsCNOrw6s8OzOa985Su71xdeeGG2LJZDHZ1rjGdVom1VZFiOH89acI2p6MlqXcRya86jqbWk7lHrM4LPcH7RZZV7nFpLDCFAd+p4tonu8Nx3GAWX48IwA5zPTCDKsw/cG/hsPDNyxx13DDv27Cu/x4488sjs/d/73veq9jWeY2GCyAULFmTHgi7v3/3ud7Nlqu+6eObna1/7WjZhZmf8UjkpgWWydVyrEWY+DMMwDMPoK/zyYRiGYRhGXzGwrraJvknUE+lQ0kSkMEmrku6L/6aLIBOb0WWVn1900UXd69e+9rVZyo607DnnnCNdlEjZTp48OevSGZMo5ShQupcp6jxSq6SjSW8eeuih3evzzz8/26f58+dn7UQXsWhzUt7sE/uxbNmyrLTDSI6k+m+66abu9Uc+8pHu9QUXXDCkblKlHCdSxzXuiKQtSZ+S/iblGe3A/jE5H+l2RmMl5cq5RpszSdzZZ589pO53v/vd2URQnBcqyiuvua4I2inKi+yrSrjF+c95O3PmzGziO7oIcx5EepiUPttO+eiGG27Iym8sl9Q7+/qTn/yke73PPvvI8eacp5swx5uRfBnB9TWvec2we8sXv/jFIXXTlVXtLQ888ED3mhQ428FyOU9LCTNVxF/uOZTNlOSj3JApUUQ5ma62HGMVnZiSgXI5VZGDuQdE91xC9YmyLMuitLMFQgCU3JtVolHK8Cp68vHHH5+VRbmfMPJ1jOxKWZVgnzp9VeEUcjDzYRiGYRhGX+GXD8MwDMMw+oqBlV0SzZ7oOkoGpENJk5J+I40b//3DH/4wSwWSWmXERdJKt956a/Z+nvglVZxwzTXXdK/32GOPrDxDGpgUJqNcKoqP9Fj0OKE8w/v4/MMPP5w9vb3XXntlT56Tdqy1+ec///nu9THHHNO93myzzbLyFqUxlZCNUkT0AGFflaeUitZJmpr0KcvZdtttszaI/eY15wGTNFEm4LWaa5ybMaItJQCOMeck5Q7l6RGjl+buiWDdbBcjzJLmpucLT+gzSiXXhUqiVhonUu+ct6SzSUGrMikflMab1PRVV12VpbMpL/a6t0SvD7W3nHvuuVl5hXZjOzgunIMcU3r/5KSQXB0sl2uXEgfXIW1Lbw5G0Yz7GucR28Rx5R5Cm3P+M9ka10gpySXrU9d8nt9XnPM/xHeSkv7i+CuPOT7DtUAbcuxvu+22rBxP2TBh3rx52f5xjXVsbtnFMAzDMIyBhV8+DMMwDMPoKwY2yFiifhL9SdqM1Bzp4dLJZRUsitQVqVjSRopCYpkqMFWEOgXNz5lAS51cJgXNummnSKGSSqS0w+A4qk+k23l/baAvjgepwBq78R4VdC1CBTRi29kOemqwT6SaSXmynHgivSZwnRozFTSKnysZKc4R5c1DeplBmeipQZmBc5NlRvmB9Dmfod1UIC16QynqnTaP4FrieJBip+yiJBwVHKpmPxgt2A6ue649NZ9G2y7ag9elBGFsC8eb65LyiHqWa0HJZMoTJUIFZ+M15zZtq+SVuC9xnnP9cF2Vns99d7XEvhuD+nFuc66qpJzKBvR+UzJNBMeY40GppnNPmov333+/g4wZhmEYhjF4GLgDp523sc7bmnqj5dt+KW07n1fsQ831aJkPFZa7JrSyYhnUm25tWaodqlxl8xLzoezZK/NBlMI9K1aJfy2oftT0tTTXVP9Un0YzFhHKzqNZPzXjWFufmud8Vo1R6S/7mufVXK1ZI+p6LNFrOyJG067a/aSmvtLa6KW+mnIiauZdzV6kyozlqrlWej73bEus9RjPRu1lNfZUDF8pVYTqh+p36Xt7lZFd0gn5KVOm/F83wzAMwzCMEeCRRx4ZEvBulXj5SG9O6exDalZK5JM6MZx2NJ6QtO708uV+rx5wv93v1QHu9+rR71ar1Xa7TRFZYzLEgZddUoPTG1PnwFkasNVh0CLc79UL7vfqBfd79cLq1O8X42BvCT5wahiGYRhGX+GXD8MwDMMw+oqBfflIfs3/7//9v2fFUhjvcL/d79UB7rf7vTpgde13DQbuwKlhGIZhGOMbA8t8GIZhGIYxPuGXD8MwDMMw+gq/fBiGYRiG0Vf45cMwDMMwjL7CLx+GYRiGYfQVA/nycdZZZ7VTFqc04bvttlszf/78Zjzh1FNPbXbZZZd2auWNN964OfDAA5uFCxcOuSelWz/mmGOaDTfcsJ1q/JBDDmlWrFjRjCd86lOfaidDOu6448Z9v5ctW9a89a1vbfcrpcveZpttmltvvbX7++R0dvLJJzcTJ05s/36fffZpFi1a1KzKSImnTjrppGbGjBntPs2cObP5+Mc//qwkc6t6v3/yk580+++/fzukdJrP3/ve94b8vqaPv/zlL5vDDz+8HQVzvfXWa97xjnc0v/vd75pVtd9/+ctfmg996EPtef7CF76wfc/b3va2duqM8dzviHe+853te04//fRVvt/j/uXjoosuak444YS2b/SCBQua7bbbrtl3332bxx9/vBkvuPbaa9tfsDfddFNz1VVXtRfqq1/96ub3v/99957jjz++ueyyy5qLL764fX9atAcffHAzXnDLLbc0X/rSl5ptt912yOfjsd+/+tWvmj333LN53vOe11xxxRXNPffc03z2s59t1l9//e49n/nMZ5ozzjijOeecc5qbb765vWGneZ9exlZVfPrTn27OPvvs5gtf+ELzi1/8ov3v1M8zzzxzXPU7rdu0T6U/mnKo6WP6Ivr5z3/e3g8uv/zy9hfc0Ucf3ayq/f7DH/7Q3r/Ty2f6/yWXXNL+A+uAAw4Yct946zdx6aWXtvf49JIScfgq2O8xR2vAsOuuu7aOOeaY7r//9re/tSZNmtQ69dRTW+MVjz/+ePpTsHXttde2//3000+3nve857Uuvvji7j2/+MUv2vfceOONrVUdv/3tb1tbbLFF66qrrmq9/OUvb73vfe8b1/3+0Ic+1Nprr73k7//+97+3Ntlkk9Z//Md/dD9Ltlh77bVb3/72t1urKvbbb7/WUUcdNeSzgw8+uHX44YeP236nuXrppZd2/13Tx3vuuaf93C233NK954orrmitscYarWXLlrVWxX7nMH/+/PZ9Dz/88Ljv99KlS1ubbrpp6+67725Nmzatddppp3V/Nx76PRYYKObjmWeeaW677bY2LclEc+nfN954YzNe8etf/7r9/w022KD9/2SDxIbQDrNmzWpn+R0Pdkisz3777Tekf+O53z/4wQ+anXfeuTn00EPbMtsOO+zQfPnLX+7+fvHixc3y5cuH9DslZ0qS46rc7z322KOZN29ec99997X/fccddzTXX39989rXvnZc95uo6WP6f6Le0xzpIN2f9r7ElIynfS5JEKmv47nfKTP7EUcc0XzgAx9oXvrSlz7r9+O1371ioLLaPvnkk22deMKECUM+T/++9957m/GINFHTmYdEy8+ZM6f9Wdqs1lprre4ipR3S71ZlXHjhhW0aNskuEeO13w8++GBbfkhy4kc+8pF239/73ve2+3rkkUd2+5ab96tyvz/84Q+3s1OnF8jnPve57bV9yimntCnnhPHab6Kmj+n/6aWUWHPNNdt/jIwXOySJKZ0Bectb3tLN7jpe+53kxdSPtMZzGK/9XqVfPlZHJBbg7rvvbv9FON7xyCOPNO973/vaOmc6TLy6IL1gpr9yPvnJT7b/nZiPNObpDEB6+Riv+M53vtN861vfai644IL2X4C33357+0U7aeDjud/GUCQ2801velP74G16CR/PSOzt5z//+fYfWInlMTQGSnbZaKON2n8hRe+G9O9NNtmkGW849thj24eNfvzjHzeTJ0/ufp76miSop59+elzZIS3MdHB4xx13bL/pp590qDQdxkvX6a/B8djv5OWw9dZbD/ls9uzZzZIlS9rXnb6Nt3mfaOfEfrz5zW9uez0kKjodKE7eXuO530RNH9P/44H6v/71r22PiFXdDp0Xj4cffrj9R0eH9Riv/b7uuuvafUpScWePS31///vf3/bgHK/9XuVfPhINvdNOO7V1Yv7VmP49d+7cZrwg/QWQXjzSaeirr7667YpIJBskzwjaIZ0UT19Wq7Id9t577+auu+5q/wXc+UmMQKLhO9fjsd9JUouu1OkcxLRp09rXafzTpsN+J7ki6b+rcr+Tx0PSsYn0x0Va0+O530RNH9P/0wt3ejnvIO0LyU7pbMiq/uKR3Ir/93//t+1mTozHfqcX7DvvvHPIHpeYvvQi/qMf/Wjc9ntEaA0YLrzwwvZJ8K9//evtU8FHH310a7311mstX768NV7wrne9q/XiF7+4dc0117Qee+yx7s8f/vCH7j3vfOc7W1OnTm1dffXVrVtvvbU1d+7c9s94A71dxmu/0yn/Nddcs3XKKae0Fi1a1PrWt77VesELXtD6z//8z+49n/rUp9rz/Pvf/37rzjvvbL3hDW9ozZgxo/XHP/6xtariyCOPbJ/4v/zyy1uLFy9uXXLJJa2NNtqo9cEPfnBc9Tt5b/3sZz9r/6Qt9XOf+1z7uuPVUdPH17zmNa0ddtihdfPNN7euv/76tjfYW97yltaq2u9nnnmmdcABB7QmT57cuv3224fsc3/+85/Hbb9ziN4uq2q/xxoD9/KRcOaZZ7a/gNZaa6226+1NN93UGk9IEzb3c95553XvSRvTu9/97tb666/f/qI66KCD2gt3vL98jNd+X3bZZa05c+a0X6xnzZrVOvfcc4f8PrlknnTSSa0JEya079l7771bCxcubK3K+M1vftMe27SWn//857c222yz1r/9278N+fIZD/3+8Y9/nF3P6eWrto9PPfVU+8tnnXXWaa277rqtt7/97e0vuVW13+llU+1z6bnx2u/al4+nVsF+jzXWSP8ZGWdiGIZhGIaxip/5MAzDMAxj/MMvH4ZhGIZh9BV++TAMwzAMo6/wy4dhGIZhGH2FXz4MwzAMw+gr/PJhGIZhGEZf4ZcPwzAMwzD6Cr98GIZhGIbRV/jlwzAMwzCMvsIvH4ZhGIZh9BV++TAMwzAMo+kn/j+n7iHhWBWrMgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe80e7-a5d8-47bb-96aa-52db364137ac",
   "metadata": {},
   "source": [
    "### this is the grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "236d716c-593f-4734-a553-cdc2ada4930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43627cd-2e12-41f7-a9fc-f7f275a5fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_Defend_The_Center'\n",
    "LOG_DIR = './logs/log_Defend_The_Center'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab49e155-c2bf-4413-a885-210d9e01ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24342e15-04e5-4fcd-bf4d-ed1f67d0f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f80219f-c53b-4623-b8c7-6661fafe4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001,n_steps=4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb4b71e-d6fb-40a3-8d29-098848afc9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_Defend_The_Center\\PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.7     |\n",
      "|    ep_rew_mean     | 0.173    |\n",
      "| time/              |          |\n",
      "|    fps             | 30       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82          |\n",
      "|    ep_rew_mean          | 0.384       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010222589 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.0546     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.1         |\n",
      "|    ep_rew_mean          | 1.31         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 648          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103605315 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00323      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0204      |\n",
      "|    value_loss           | 0.107        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 104         |\n",
      "|    ep_rew_mean          | 2.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1006        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012027562 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0395     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 111         |\n",
      "|    ep_rew_mean          | 2.88        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1363        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015255447 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00149    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | 3.48        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1702        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017531108 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.987      |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00792    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 120         |\n",
      "|    ep_rew_mean          | 4.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 2039        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018525094 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.949      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 4.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 2373        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017370947 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0532     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 132         |\n",
      "|    ep_rew_mean          | 5.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 2710        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025832672 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 135         |\n",
      "|    ep_rew_mean          | 5.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 3039        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021275625 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    value_loss           | 0.154       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 139         |\n",
      "|    ep_rew_mean          | 6.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 3373        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022493478 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.818      |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000616   |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 140         |\n",
      "|    ep_rew_mean          | 6.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 3704        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022203598 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00673    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 6.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 4033        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023805337 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 149        |\n",
      "|    ep_rew_mean          | 7.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 13         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 4367       |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02969981 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.78      |\n",
      "|    explained_variance   | 0.868      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0121    |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0444    |\n",
      "|    value_loss           | 0.15       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 151         |\n",
      "|    ep_rew_mean          | 7.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 4704        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026317924 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00741    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 154        |\n",
      "|    ep_rew_mean          | 7.64       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 13         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 5040       |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02708279 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.737     |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0142     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0454    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | 8.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 5375        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028364502 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.693      |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000342    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | 8.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 5711        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029503662 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 165         |\n",
      "|    ep_rew_mean          | 8.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 6043        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030782692 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 170         |\n",
      "|    ep_rew_mean          | 8.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 6385        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029793475 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 171         |\n",
      "|    ep_rew_mean          | 9.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 6720        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033193804 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0161     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | 9.55        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 7055        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029965896 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.622      |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 179         |\n",
      "|    ep_rew_mean          | 9.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 7400        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033837296 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0413     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 186        |\n",
      "|    ep_rew_mean          | 10.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 7813       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03505981 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.566     |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0373    |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.042     |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 192        |\n",
      "|    ep_rew_mean          | 11.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 8172       |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03139279 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.516     |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0115    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0383    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6db91-fe8e-4e62-bec1-1eb3677dc435",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "258b6917-f158-4b1d-9ecf-89825c069b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PPO.load(\"./train/train_defend_the_center/best_model_90000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d89d6f2e-9535-40d1-afea-baf5078e6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9de5bd46-bd84-4f5f-a6ee-fd08f8853da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Monitor(env)\n",
    "mean_reward,_=evaluate_policy(model,env,n_eval_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e42f7380-0bf8-4228-8f3e-70f9fa3b1702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.38"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a52134-4a58-4e92-b085-78e8d994f554",
   "metadata": {},
   "source": [
    "<b style=\"color:red\">In average the agent is killing 13 player before dying </b> *`penalty for death -1 ==> nb of killed enemy 12+1=13`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4973ffde-f640-4a97-8f57-fdb2ec0ac83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3dfc4d3-776f-4077-b0e8-b5703f494c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 8.0\n",
      "Episode 2: Total Reward = 11.0\n",
      "Episode 3: Total Reward = 11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_defend_the_center/best_model_90000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 3\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.20)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56182b8c-aa59-4795-9e90-98d7eabd563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ef55c-89a2-4fd9-bfda-ffccb8e80da3",
   "metadata": {},
   "source": [
    "### DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91907a95-d63a-4b18-b048-1f80b2a2b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4746ad49-a58a-4396-ae37-f1aa543c270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = DQN('CnnPolicy',\n",
    "            env,\n",
    "            tensorboard_log=LOG_DIR,\n",
    "            verbose=1,\n",
    "            buffer_size=5000,\n",
    "            learning_starts=2000,\n",
    "            gamma=0.99,\n",
    "            learning_rate=0.0001,\n",
    "            batch_size=1024,\n",
    "            train_freq=8,\n",
    "            target_update_interval=1000,  \n",
    "            exploration_initial_eps=1.0,  \n",
    "            exploration_final_eps=0.05, \n",
    "            exploration_fraction=0.1, \n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34f67165-6e37-4ae6-a55d-437afd62eaeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_Defend_The_Center\\DQN_1\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 83.5     |\n",
      "|    ep_rew_mean      | 0        |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 334      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 85.1     |\n",
      "|    ep_rew_mean      | 0.25     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 681      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.8     |\n",
      "|    ep_rew_mean      | 0.417    |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 1018     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86       |\n",
      "|    ep_rew_mean      | 0.625    |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 1376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.8     |\n",
      "|    ep_rew_mean      | 0.55     |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 1696     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.4     |\n",
      "|    ep_rew_mean      | 0.458    |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 2026     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 3        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.9     |\n",
      "|    ep_rew_mean      | 0.5      |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 2321     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 40       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.7     |\n",
      "|    ep_rew_mean      | 0.531    |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 2647     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 80       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82       |\n",
      "|    ep_rew_mean      | 0.444    |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 2953     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 119      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.6     |\n",
      "|    ep_rew_mean      | 0.45     |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 3304     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 162      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.5     |\n",
      "|    ep_rew_mean      | 0.477    |\n",
      "|    exploration_rate | 0.655    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 3628     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00967  |\n",
      "|    n_updates        | 203      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.2     |\n",
      "|    ep_rew_mean      | 0.417    |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 3947     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 243      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.8     |\n",
      "|    ep_rew_mean      | 0.442    |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 372      |\n",
      "|    total_timesteps  | 4304     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 287      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.4     |\n",
      "|    ep_rew_mean      | 0.482    |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 400      |\n",
      "|    total_timesteps  | 4616     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 326      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.3     |\n",
      "|    ep_rew_mean      | 0.467    |\n",
      "|    exploration_rate | 0.531    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 431      |\n",
      "|    total_timesteps  | 4939     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00916  |\n",
      "|    n_updates        | 367      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.9     |\n",
      "|    ep_rew_mean      | 0.562    |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 464      |\n",
      "|    total_timesteps  | 5304     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00774  |\n",
      "|    n_updates        | 412      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.3     |\n",
      "|    ep_rew_mean      | 0.662    |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 503      |\n",
      "|    total_timesteps  | 5731     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 466      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 85.2     |\n",
      "|    ep_rew_mean      | 0.736    |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 540      |\n",
      "|    total_timesteps  | 6135     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 516      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 85.6     |\n",
      "|    ep_rew_mean      | 0.803    |\n",
      "|    exploration_rate | 0.382    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 576      |\n",
      "|    total_timesteps  | 6508     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 563      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86.1     |\n",
      "|    ep_rew_mean      | 0.85     |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 612      |\n",
      "|    total_timesteps  | 6890     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 611      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86.3     |\n",
      "|    ep_rew_mean      | 0.929    |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 646      |\n",
      "|    total_timesteps  | 7247     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 655      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 86.2     |\n",
      "|    ep_rew_mean      | 0.966    |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 679      |\n",
      "|    total_timesteps  | 7588     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 698      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 88.2     |\n",
      "|    ep_rew_mean      | 1.16     |\n",
      "|    exploration_rate | 0.229    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 728      |\n",
      "|    total_timesteps  | 8116     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 764      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 89.2     |\n",
      "|    ep_rew_mean      | 1.29     |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 772      |\n",
      "|    total_timesteps  | 8561     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 820      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.7     |\n",
      "|    ep_rew_mean      | 1.54     |\n",
      "|    exploration_rate | 0.129    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 861      |\n",
      "|    total_timesteps  | 9173     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 896      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.1     |\n",
      "|    ep_rew_mean      | 1.76     |\n",
      "|    exploration_rate | 0.0837   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 931      |\n",
      "|    total_timesteps  | 9645     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 955      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.7     |\n",
      "|    ep_rew_mean      | 2        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 1008     |\n",
      "|    total_timesteps  | 10153    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 1019     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 95.4     |\n",
      "|    ep_rew_mean      | 2.13     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 1067     |\n",
      "|    total_timesteps  | 10557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 1069     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96.4     |\n",
      "|    ep_rew_mean      | 2.24     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 1134     |\n",
      "|    total_timesteps  | 11016    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 1126     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 101      |\n",
      "|    ep_rew_mean      | 2.59     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 1249     |\n",
      "|    total_timesteps  | 11792    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 1223     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 105      |\n",
      "|    ep_rew_mean      | 2.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 1355     |\n",
      "|    total_timesteps  | 12525    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 1315     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 106      |\n",
      "|    ep_rew_mean      | 3.1      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 1421     |\n",
      "|    total_timesteps  | 12963    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 1370     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 3.36     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1502     |\n",
      "|    total_timesteps  | 13517    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 1439     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 3.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1587     |\n",
      "|    total_timesteps  | 14094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 1511     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 3.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1668     |\n",
      "|    total_timesteps  | 14650    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 1581     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 4.03     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1736     |\n",
      "|    total_timesteps  | 15127    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 1640     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 4.32     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1821     |\n",
      "|    total_timesteps  | 15725    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 1715     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 4.52     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 1890     |\n",
      "|    total_timesteps  | 16194    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 4.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2010     |\n",
      "|    total_timesteps  | 17021    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0273   |\n",
      "|    n_updates        | 1877     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 127      |\n",
      "|    ep_rew_mean      | 5.31     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2105     |\n",
      "|    total_timesteps  | 17667    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 1958     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 129      |\n",
      "|    ep_rew_mean      | 5.5      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2189     |\n",
      "|    total_timesteps  | 18234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 2029     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 5.69     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2281     |\n",
      "|    total_timesteps  | 18865    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 2108     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 133      |\n",
      "|    ep_rew_mean      | 5.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2370     |\n",
      "|    total_timesteps  | 19474    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 2184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 6.32     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2457     |\n",
      "|    total_timesteps  | 20234    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 2279     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 6.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2527     |\n",
      "|    total_timesteps  | 20979    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 2372     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 145      |\n",
      "|    ep_rew_mean      | 7        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2596     |\n",
      "|    total_timesteps  | 21709    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 2463     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 7.21     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2646     |\n",
      "|    total_timesteps  | 22251    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 2531     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 7.25     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2698     |\n",
      "|    total_timesteps  | 22795    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 2599     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 7.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2741     |\n",
      "|    total_timesteps  | 23257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 2657     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 7.32     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2800     |\n",
      "|    total_timesteps  | 23920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 2739     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 150      |\n",
      "|    ep_rew_mean      | 7.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2869     |\n",
      "|    total_timesteps  | 24659    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 2832     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 153      |\n",
      "|    ep_rew_mean      | 7.63     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2940     |\n",
      "|    total_timesteps  | 25423    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 2927     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 154      |\n",
      "|    ep_rew_mean      | 7.68     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 2992     |\n",
      "|    total_timesteps  | 25995    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 2999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 158      |\n",
      "|    ep_rew_mean      | 7.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3066     |\n",
      "|    total_timesteps  | 26789    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 3098     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 158      |\n",
      "|    ep_rew_mean      | 8.02     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3138     |\n",
      "|    total_timesteps  | 27552    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 3193     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 156      |\n",
      "|    ep_rew_mean      | 7.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3191     |\n",
      "|    total_timesteps  | 28113    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 3264     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 158      |\n",
      "|    ep_rew_mean      | 8.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3257     |\n",
      "|    total_timesteps  | 28786    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 3348     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 158      |\n",
      "|    ep_rew_mean      | 8.15     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3313     |\n",
      "|    total_timesteps  | 29345    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 3418     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 159      |\n",
      "|    ep_rew_mean      | 8.26     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3374     |\n",
      "|    total_timesteps  | 29951    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 3493     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 161      |\n",
      "|    ep_rew_mean      | 8.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3452     |\n",
      "|    total_timesteps  | 30737    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 3592     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3524     |\n",
      "|    total_timesteps  | 31456    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 3681     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3581     |\n",
      "|    total_timesteps  | 32013    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 3751     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 8.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3637     |\n",
      "|    total_timesteps  | 32581    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 3822     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.69     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3709     |\n",
      "|    total_timesteps  | 33287    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0286   |\n",
      "|    n_updates        | 3910     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 162      |\n",
      "|    ep_rew_mean      | 8.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3770     |\n",
      "|    total_timesteps  | 33900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 3987     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 161      |\n",
      "|    ep_rew_mean      | 8.54     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 3814     |\n",
      "|    total_timesteps  | 34322    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 4040     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 3897     |\n",
      "|    total_timesteps  | 35157    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 4144     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 3960     |\n",
      "|    total_timesteps  | 35808    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 4225     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 4036     |\n",
      "|    total_timesteps  | 36554    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 4319     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 4135     |\n",
      "|    total_timesteps  | 37233    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0223   |\n",
      "|    n_updates        | 4404     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4254     |\n",
      "|    total_timesteps  | 38031    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 4503     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 8.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4349     |\n",
      "|    total_timesteps  | 38675    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 4584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 8.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4467     |\n",
      "|    total_timesteps  | 39363    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 4670     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 168      |\n",
      "|    ep_rew_mean      | 8.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4561     |\n",
      "|    total_timesteps  | 40011    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 4751     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 168      |\n",
      "|    ep_rew_mean      | 9.04     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4671     |\n",
      "|    total_timesteps  | 40745    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 4843     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 8.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4761     |\n",
      "|    total_timesteps  | 41364    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 4920     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 8.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4857     |\n",
      "|    total_timesteps  | 42020    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 5002     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 9.01     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 4967     |\n",
      "|    total_timesteps  | 42616    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 5076     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 8.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 5100     |\n",
      "|    total_timesteps  | 43229    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 5153     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 8        |\n",
      "|    time_elapsed     | 5253     |\n",
      "|    total_timesteps  | 43899    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 5237     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 165      |\n",
      "|    ep_rew_mean      | 8.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 5982     |\n",
      "|    total_timesteps  | 44644    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 5330     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 8.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6023     |\n",
      "|    total_timesteps  | 45217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 5402     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 8.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6062     |\n",
      "|    total_timesteps  | 45768    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 5470     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6115     |\n",
      "|    total_timesteps  | 46299    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 5537     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6188     |\n",
      "|    total_timesteps  | 47053    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 5631     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6262     |\n",
      "|    total_timesteps  | 47803    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 5725     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 165      |\n",
      "|    ep_rew_mean      | 8.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6331     |\n",
      "|    total_timesteps  | 48476    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 5809     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 8.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6403     |\n",
      "|    total_timesteps  | 49182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 5897     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 8.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6473     |\n",
      "|    total_timesteps  | 49882    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 5985     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 9.02     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6541     |\n",
      "|    total_timesteps  | 50559    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 6069     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 168      |\n",
      "|    ep_rew_mean      | 9.17     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6596     |\n",
      "|    total_timesteps  | 51129    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 6141     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 9.11     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6674     |\n",
      "|    total_timesteps  | 51894    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 6236     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 168      |\n",
      "|    ep_rew_mean      | 9.14     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6741     |\n",
      "|    total_timesteps  | 52574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 6321     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 9.07     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6803     |\n",
      "|    total_timesteps  | 53185    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 6398     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 8.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6846     |\n",
      "|    total_timesteps  | 53611    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 6451     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 162      |\n",
      "|    ep_rew_mean      | 8.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 6910     |\n",
      "|    total_timesteps  | 54268    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 6533     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 9        |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7027     |\n",
      "|    total_timesteps  | 55061    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 6632     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7112     |\n",
      "|    total_timesteps  | 55641    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 6705     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 9.03     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7218     |\n",
      "|    total_timesteps  | 56363    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 6795     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 165      |\n",
      "|    ep_rew_mean      | 9.06     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7362     |\n",
      "|    total_timesteps  | 57213    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 6901     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 9.09     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7467     |\n",
      "|    total_timesteps  | 57926    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 6990     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 9.2      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7600     |\n",
      "|    total_timesteps  | 58728    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 7090     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 169      |\n",
      "|    ep_rew_mean      | 9.37     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7715     |\n",
      "|    total_timesteps  | 59518    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 7189     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 170      |\n",
      "|    ep_rew_mean      | 9.53     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7822     |\n",
      "|    total_timesteps  | 60258    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 7282     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 170      |\n",
      "|    ep_rew_mean      | 9.48     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 7924     |\n",
      "|    total_timesteps  | 60926    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 7365     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 169      |\n",
      "|    ep_rew_mean      | 9.48     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8070     |\n",
      "|    total_timesteps  | 61558    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 7444     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 170      |\n",
      "|    ep_rew_mean      | 9.52     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8162     |\n",
      "|    total_timesteps  | 62180    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 7522     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 172      |\n",
      "|    ep_rew_mean      | 9.66     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8283     |\n",
      "|    total_timesteps  | 62970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 7621     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 173      |\n",
      "|    ep_rew_mean      | 9.68     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8421     |\n",
      "|    total_timesteps  | 63599    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 7699     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 172      |\n",
      "|    ep_rew_mean      | 9.66     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8530     |\n",
      "|    total_timesteps  | 64270    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 7783     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 172      |\n",
      "|    ep_rew_mean      | 9.65     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8643     |\n",
      "|    total_timesteps  | 65036    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 7879     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 172      |\n",
      "|    ep_rew_mean      | 9.64     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8732     |\n",
      "|    total_timesteps  | 65652    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 7956     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 170      |\n",
      "|    ep_rew_mean      | 9.47     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8809     |\n",
      "|    total_timesteps  | 66169    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 8021     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 168      |\n",
      "|    ep_rew_mean      | 9.37     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8880     |\n",
      "|    total_timesteps  | 66725    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 8090     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 9.27     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8934     |\n",
      "|    total_timesteps  | 67283    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 8160     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 9.21     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 8991     |\n",
      "|    total_timesteps  | 67836    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 8229     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 9.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9070     |\n",
      "|    total_timesteps  | 68628    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 8328     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 168      |\n",
      "|    ep_rew_mean      | 9.24     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9142     |\n",
      "|    total_timesteps  | 69335    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 8416     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 169      |\n",
      "|    ep_rew_mean      | 9.24     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9215     |\n",
      "|    total_timesteps  | 70068    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0279   |\n",
      "|    n_updates        | 8508     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 170      |\n",
      "|    ep_rew_mean      | 9.3      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9267     |\n",
      "|    total_timesteps  | 70574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 8571     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 168      |\n",
      "|    ep_rew_mean      | 9.18     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9319     |\n",
      "|    total_timesteps  | 71081    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0223   |\n",
      "|    n_updates        | 8635     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 8.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9365     |\n",
      "|    total_timesteps  | 71464    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 8682     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 8.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9465     |\n",
      "|    total_timesteps  | 71979    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 8747     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 161      |\n",
      "|    ep_rew_mean      | 8.65     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9557     |\n",
      "|    total_timesteps  | 72486    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 8810     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 159      |\n",
      "|    ep_rew_mean      | 8.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9664     |\n",
      "|    total_timesteps  | 73081    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 8885     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 159      |\n",
      "|    ep_rew_mean      | 8.52     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9797     |\n",
      "|    total_timesteps  | 73783    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 8972     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 155      |\n",
      "|    ep_rew_mean      | 8.27     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 9874     |\n",
      "|    total_timesteps  | 74191    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 9023     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 152      |\n",
      "|    ep_rew_mean      | 8.12     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 7        |\n",
      "|    time_elapsed     | 10232    |\n",
      "|    total_timesteps  | 74713    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 9089     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[0;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:560\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    563\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py:97\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m---> 97\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[1;32mIn[11], line 29\u001b[0m, in \u001b[0;36mVizDoomGym.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03mtake action \u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03mExample of usages:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    state, reward, terminated,truncated, info (AMMO)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     30\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mis_episode_finished()\n\u001b[0;32m     31\u001b[0m truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_episode_time() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_episode_timeout() \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "141f1f8a-6783-4d22-8a56-b8ed553a8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./train/train_defend_the_center/best_model_160000.zip\"  \n",
    "model = DQN.load(model_path)\n",
    "env=VizDoomGym(render=True)\n",
    "env = Monitor(env)\n",
    "mean_reward,_=evaluate_policy(model,env,n_eval_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8a5e3ef-b94e-4105-945b-4afeab3a2c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.58"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a0558-e8c8-46db-991c-81a867c2d704",
   "metadata": {},
   "source": [
    "<b style=\"color:red\">In average the agent is killing 11 player before dying </b> *`penalty for death -1 ==> nb of killed enemy 10+1=11`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3797c119-1025-4431-a7a4-cd21fd3b33ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 10.0\n",
      "Episode 2: Total Reward = 8.0\n",
      "Episode 3: Total Reward = 11.0\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./train/train_defend_the_center/best_model_160000.zip\"  \n",
    "model = DQN.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 3\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.20)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec2d14-c259-49fc-b093-ed3ff7cb21b3",
   "metadata": {},
   "source": [
    "<b style=\"color:blue\">DQN</b> <b>VS</b> <b style=\"color:pink\">PPO</b>\n",
    "### Episode Length Mean:\n",
    "<img src=\"./Screenshot 2025-03-06 215432.png\"/><br>\n",
    "### Episode Reward Mean:\n",
    "<img src=\"./Screenshot 2025-03-06 215400.png\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91f8ca-341d-452c-af2b-f8cbd979c314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
