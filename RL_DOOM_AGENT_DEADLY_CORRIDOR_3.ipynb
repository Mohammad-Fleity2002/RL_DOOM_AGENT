{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76fb19e-7771-4ae8-8d26-dc7fe78b86f4",
   "metadata": {},
   "source": [
    "# Deadly Corridor Skill 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12fc83a-bd4b-4157-897d-f6774342f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import vizdoom as vzd\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb647e0-6368-4af8-816b-8ea3caf011d3",
   "metadata": {},
   "source": [
    "# SETUP-GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15493055-d156-464b-a203-8dbf12e75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config(r'./scenarios/deadly_corridor-skill-3.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47bd952-7230-418f-90eb-ba3a6ea570b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "actions = np.identity(7, dtype=np.uint8)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840aeaf7-c157-4b3e-90e8-770464c9de85",
   "metadata": {},
   "source": [
    "1. actions[0] : MOVE_LEFT\n",
    "2. actions[1] : MOVE_RIGHT\n",
    "3. actions[2] : ATTACK\n",
    "4. actions[3] : MOVE_FORWARD\n",
    "5. actions[4] : MOVE_BACKWARD\n",
    "6. actions[5] : TURN_LEFT\n",
    "7. actions[6] : TURN_RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd199ad-9ef9-4ad8-996e-4e75ca491654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.new_episode()\n",
    "game.is_episode_finished()\n",
    "game.make_action(random.choice(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2065135d-48a4-46bc-bf99-b2ee30a3ad1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9830F30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338770>\n",
      "reward: -0.209564208984375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E630>\n",
      "reward: -0.251495361328125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9830F30>\n",
      "reward: 0.0396728515625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338770>\n",
      "reward: -6.973663330078125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: -8.22845458984375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9830F30>\n",
      "reward: -0.3275299072265625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD98338B0>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E6F0>\n",
      "reward: -0.025421142578125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9830F30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: 0.1967315673828125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E6F0>\n",
      "reward: 7.3426513671875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: 8.686431884765625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: 6.48138427734375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E6F0>\n",
      "reward: 11.781967163085938\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: 11.044326782226562\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E770>\n",
      "reward: 7.122589111328125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E6F0>\n",
      "reward: 2.8512420654296875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338D70>\n",
      "reward: -6.8511962890625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E770>\n",
      "reward: -15.424850463867188\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E6F0>\n",
      "reward: -14.124313354492188\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD6BF0>\n",
      "reward: -2.5769500732421875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E770>\n",
      "reward: 1.91156005859375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E6F0>\n",
      "reward: -8.147552490234375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: -10.247802734375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E770>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3EBF0>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD6D30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC330EDB0>\n",
      "reward: -0.04443359375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9ABEF70>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: 5.9019622802734375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC330EDB0>\n",
      "reward: 6.95001220703125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3EBF0>\n",
      "reward: 4.687744140625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: 3.161834716796875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC330EDB0>\n",
      "reward: 2.1325836181640625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "reward: 4.65289306640625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD985E670>\n",
      "reward: 4.8264312744140625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: -197.4425048828125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "////////////////// Result: -181.1037139892578\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9ABF0B0>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC330EDB0>\n",
      "reward: 7.1137542724609375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F330>\n",
      "reward: 8.533950805664062\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9ABF0B0>\n",
      "reward: 12.815628051757812\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "reward: 5.2918243408203125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC330EDB0>\n",
      "reward: -7.1975250244140625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9ABF0B0>\n",
      "reward: -8.562225341796875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD66B0>\n",
      "reward: -5.775482177734375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC330EDB0>\n",
      "reward: -3.895721435546875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9ABF0B0>\n",
      "reward: 0.4004364013671875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: 1.8602447509765625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC330EDB0>\n",
      "reward: 4.2828521728515625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: 4.41094970703125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: 5.4410858154296875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: 6.4730224609375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: -4.3654632568359375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: -2.94464111328125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: -1.15557861328125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9981FB0>\n",
      "reward: -1.17401123046875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: -1.228240966796875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: -0.828582763671875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC370BFB0>\n",
      "reward: 6.5547943115234375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: 8.15692138671875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: 5.50189208984375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC370BFB0>\n",
      "reward: 3.711029052734375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: -4.5572052001953125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: 0.27850341796875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC370BFB0>\n",
      "reward: 3.86920166015625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: 1.7554168701171875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: -0.4658966064453125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC370BFB0>\n",
      "reward: -1.165679931640625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: 5.5167083740234375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "reward: 12.669357299804688\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC370BFB0>\n",
      "reward: 6.6461334228515625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3F470>\n",
      "reward: -1.065399169921875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "reward: -1.9778289794921875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: -1.33416748046875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A33FB0>\n",
      "reward: -1.0750579833984375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "reward: -0.817626953125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: -0.5515594482421875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A33FB0>\n",
      "reward: -0.1678924560546875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: -0.006103515625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD66B0>\n",
      "reward: -0.6319732666015625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A33FB0>\n",
      "reward: -1.2349090576171875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: -12.818145751953125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD66B0>\n",
      "reward: -24.168197631835938\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: -17.757339477539062\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD7D30>\n",
      "reward: -12.74200439453125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD66B0>\n",
      "reward: -7.5691375732421875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: -0.02581787109375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD7D30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD99266B0>\n",
      "reward: -0.000457763671875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC36FEE30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD7D30>\n",
      "reward: 0.6275482177734375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD99266B0>\n",
      "reward: 0.125030517578125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: 6.8375396728515625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD7D30>\n",
      "reward: 15.414352416992188\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD99266B0>\n",
      "reward: -192.0487823486328\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "////////////////// Result: -185.02047729492188\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD7D30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD6E30>\n",
      "reward: -7.1104888916015625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338070>\n",
      "reward: -8.530181884765625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD7D30>\n",
      "reward: -0.3075408935546875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD6E30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338070>\n",
      "reward: -0.0433807373046875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD7D30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD6E30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD995C8B0>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD6E30>\n",
      "reward: 0.0\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC37080F0>\n",
      "reward: 0.62005615234375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: 0.6106719970703125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9AD6E30>\n",
      "reward: 0.41180419921875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC37080F0>\n",
      "reward: -1.4693603515625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: -0.1175994873046875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338070>\n",
      "reward: 5.4076385498046875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: 6.2718048095703125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: -2.772857666015625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338070>\n",
      "reward: 1.5058746337890625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: -2.3609161376953125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: -5.3264923095703125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD98304F0>\n",
      "reward: -2.775848388671875\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD9A3E6B0>\n",
      "reward: -0.011322021484375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: 7.110260009765625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD98304F0>\n",
      "reward: 8.32550048828125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC37080F0>\n",
      "reward: 12.61859130859375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: 12.245223999023438\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD98304F0>\n",
      "reward: 15.369781494140625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338070>\n",
      "reward: 14.100921630859375\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC05C7E30>\n",
      "reward: 8.883453369140625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD98304F0>\n",
      "reward: 5.6622467041015625\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAC3338070>\n",
      "reward: -198.92236328125\n",
      "ammo None\n",
      "state <vizdoom.vizdoom.GameState object at 0x000001CAD99266B0>\n",
      "////////////////// Result: -130.60452270507812\n"
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "for e in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        satate=game.get_state()\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - ammo\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions),4) # frame skip=4 time for agent to process\n",
    "        print('reward:', reward) \n",
    "        print(\"ammo\",info)\n",
    "        print(\"state\",state)\n",
    "        time.sleep(0.02)\n",
    "    print('////////////////// Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f85591b-2316-427f-abf2-547235c29511",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1caf887e-2ffa-4a19-b0db-3e1819022ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d09d280e-917b-4046-a12f-8c66c105997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(Env):\n",
    "    def __init__(self, render=False,config='./scenarios/deadly_corridor-skill-3.cfg'):\n",
    "        super().__init__()\n",
    "        self.game = vzd.DoomGame()\n",
    "        self.game.load_config(config)\n",
    "\n",
    "        # Render frame logic\n",
    "        if not render:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        self.game.init()\n",
    "\n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(7)  # 7 possible actions\n",
    "        self.actions=np.identity(7, dtype=np.float32)\n",
    "        \n",
    "\n",
    "\n",
    "    def custom_reward(self, prev_state, current_state):\n",
    "        reward = 0\n",
    "    \n",
    "        # Extract game variables\n",
    "        prev_health = prev_state.game_variables[0]  # HEALTH\n",
    "        prev_hits = prev_state.game_variables[1]  # HITCOUNT\n",
    "        prev_ammo = prev_state.game_variables[2]  # SELECTED_WEAPON_AMMO\n",
    "        prev_kills = prev_state.game_variables[3]  # KILLCOUNT\n",
    "        prev_dmg = prev_state.game_variables[4]  # KILLCOUNT\n",
    "        prev_dmg_deal = prev_state.game_variables[5]  # KILLCOUNT\n",
    "        \n",
    "        current_health = current_state.game_variables[0]  # HEALTH\n",
    "        current_hits = current_state.game_variables[1]  # HITCOUNT\n",
    "        current_ammo = current_state.game_variables[2]  # SELECTED_WEAPON_AMMO\n",
    "        current_kills = current_state.game_variables[3]  # KILLCOUNT\n",
    "        current_dmg = current_state.game_variables[4]  # KILLCOUNT\n",
    "        current_dmg_deal = current_state.game_variables[5]  # KILLCOUNT\n",
    "        \n",
    "        ammo_delta=current_ammo-prev_ammo \n",
    "        hitcount_delta= current_dmg_deal - prev_dmg_deal\n",
    "        damage_taken_delta=-current_dmg+prev_dmg\n",
    "        \n",
    "        reward = damage_taken_delta*55 + hitcount_delta*200  + ammo_delta*45 \n",
    "        \n",
    "    \n",
    "\n",
    "        return reward\n",
    "        \n",
    "    def step(self, action):\n",
    "        prev_state = self.game.get_state()  # Store the previous state\n",
    "        reward = self.game.make_action(self.actions[action], 4)  # Default reward\n",
    "        current_state = self.game.get_state()  # Get the current state\n",
    "\n",
    "        # Compute custom reward\n",
    "        if prev_state is not None and current_state is not None:\n",
    "            reward += self.custom_reward(prev_state, current_state)\n",
    "\n",
    "        terminated = self.game.is_episode_finished()\n",
    "        truncated = self.game.get_episode_time() >= self.game.get_episode_timeout()\n",
    "\n",
    "        state = np.zeros(self.observation_space.shape, dtype=np.uint8)  # Default blank state\n",
    "        info = {\"ammo\": 0}  # Default info\n",
    "\n",
    "        if not (terminated or truncated):\n",
    "            game_state = self.game.get_state()\n",
    "            if game_state is not None:\n",
    "                state = self.grayscale(game_state.screen_buffer)\n",
    "                info = {\"ammo\": game_state.game_variables[0]}\n",
    "\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Restart the game and return the initial state.\"\"\"\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state), {}\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        \"\"\"Convert the observation to grayscale and resize it.\"\"\"\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))\n",
    "        return state\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the game.\"\"\"\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236d716c-593f-4734-a553-cdc2ada4930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6db91-fe8e-4e62-bec1-1eb3677dc435",
   "metadata": {},
   "source": [
    "### Testing the model \n",
    "`./train/train_Deadly_Corridor/best_model_1000000.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d95c46d6-1407-4b3e-8328-4cd59169cc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 8916.649688720703\n",
      "Episode 2: Total Reward = 7471.124237060547\n",
      "Episode 3: Total Reward = 11036.881164550781\n",
      "Episode 4: Total Reward = 11019.75570678711\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_deadly_corridor/best_model_100000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13699a9b-3a24-482a-8978-d6fefcfd21b5",
   "metadata": {},
   "source": [
    "**The agent is doing surprisingly well -- but it need one more session of training** \n",
    "<br>\n",
    "*new reward:*<br>\n",
    "`damage_taken_delta*50 + hitcount_delta*200  + ammo_delta*40 ` <br>\n",
    "*old reward:*<br>\n",
    "`damage_taken_delta*55 + hitcount_delta*200  + ammo_delta*45 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e43627cd-2e12-41f7-a9fc-f7f275a5fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_Deadly_Corridor_COMP_5_S_3'\n",
    "LOG_DIR = './logs/log_Deadly_Corridor_s3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3ef85ed-06da-4a1d-be06-2e74438a4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n",
    "env=VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d739681e-fdd4-4747-8356-9e33242c96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_path = \"./train/train_deadly_corridor/best_model_100000.zip\"  \n",
    "model = PPO.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "510260a7-bd77-40c1-94d2-d88dcd8df3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_Deadly_Corridor\\PPO_14\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 128      |\n",
      "|    ep_rew_mean     | 8.56e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 13       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 623      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 131         |\n",
      "|    ep_rew_mean          | 8.46e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1269        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015055353 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.82e+05    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.0163      |\n",
      "|    value_loss           | 5.21e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 9.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1970        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015062919 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.981      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.88e+05    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | 0.0119      |\n",
      "|    value_loss           | 5.11e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | 9.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2683        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014635846 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.52e+05    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    value_loss           | 4.27e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 136         |\n",
      "|    ep_rew_mean          | 9.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3407        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015491467 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.25e+05    |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    value_loss           | 5.32e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 9.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4111        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015108409 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.74e+05    |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | 0.0124      |\n",
      "|    value_loss           | 4.91e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 140         |\n",
      "|    ep_rew_mean          | 9.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4809        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011410337 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.04e+05    |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.0125      |\n",
      "|    value_loss           | 4.31e+05    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)\n",
    "model.learn(total_timesteps=50000, callback=callback)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551be19-8877-4b1d-89ff-7ae190673f29",
   "metadata": {},
   "source": [
    "**Testing the model `./train/train_Deadly_Corridor_COMP_5_S_3/best_model_50000.zip`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac03402f-e229-4153-9eb6-e5b61213fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 12772.429870605469\n",
      "Episode 2: Total Reward = 14418.032455444336\n",
      "Episode 3: Total Reward = 14862.190078735352\n",
      "Episode 4: Total Reward = 9491.519729614258\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP_5_S_3/best_model_50000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbcaa9-f0e1-4736-87a9-246c10553e47",
   "metadata": {},
   "source": [
    "# The agent is very good he learned how to back off sometime to avoid domage and to one shot an enemy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
