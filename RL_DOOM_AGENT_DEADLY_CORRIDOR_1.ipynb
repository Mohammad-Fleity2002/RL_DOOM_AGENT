{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840aeaf7-c157-4b3e-90e8-770464c9de85",
   "metadata": {},
   "source": [
    "## ENVIROMENT: DEADLY CORIDOR\n",
    "\n",
    "The purpose of this scenario is to teach the agent to navigate towards his fundamental **goal (the vest)** and make sure he **survives** at the same time.\n",
    "\n",
    "The map is a corridor with **shooting monsters** on both sides **(6 monsters in total)**. **A green vest** is placed at the opposite end of the corridor. The reward is proportional (negative or positive) to the change in the distance between the player and the vest. If the player ignores monsters on the sides and runs straight for the vest, he will be killed somewhere along the way. To ensure this behavior difficulty level (doom_skill) = 5 (config) is needed.\n",
    "\n",
    "<img src=\"./Screenshot 2025-03-06 223447.png\"/>\n",
    "\n",
    "configuration File: `deadly_corridor.cfg`<br>\n",
    "**DEFAULT REWARD:**\n",
    "- +dX for getting closer to the vest.\n",
    "- dX for getting further from the vest.\n",
    "- -200 for DEATH <br>\n",
    "\n",
    "**default difficulty level:** `doom_skill` = 5<br>\n",
    "**AMMO:** 52<br>\n",
    "**HEALTH:** 100%<br>\n",
    "**SHILD:** 0<br>\n",
    "\n",
    "**AVAILABLE MOVES:**\n",
    "1. actions[0] : MOVE_LEFT`[1 0 0 0 0 0 0]`\n",
    "2. actions[1] : MOVE_RIGHT`[0 1 0 0 0 0 0]`\n",
    "3. actions[2] : ATTACK `[0 0 1 0 0 0 0]`\n",
    "4. actions[3] : MOVE_FORWARD`[0 0 0 1 0 0 0]`\n",
    "5. actions[4] : MOVE_BACKWARD `[0 0 0 0 1 0 0]`\n",
    "6. actions[5] : TURN_LEFT `[0 0 0 0 0 1 0]`\n",
    "7. actions[6] : TURN_RIGHT `[0 0 0 0 0 0 1]`<br>\n",
    "\n",
    "**RETURNED VARIABLES:**\n",
    "1. HEALTH\n",
    "2. HITCOUNT\n",
    "3. SELECTED_WEAPON_AMMO\n",
    "4. KILLCOUNT\n",
    "5. DAMAGE_TAKEN\n",
    "6. DAMAGECOUNT<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12fc83a-bd4b-4157-897d-f6774342f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import vizdoom as vzd\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb647e0-6368-4af8-816b-8ea3caf011d3",
   "metadata": {},
   "source": [
    "# SETUP-GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15493055-d156-464b-a203-8dbf12e75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config(r'./scenarios/deadly_corridor.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47bd952-7230-418f-90eb-ba3a6ea570b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "actions = np.identity(7, dtype=np.uint8)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd199ad-9ef9-4ad8-996e-4e75ca491654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.new_episode()\n",
    "game.is_episode_finished()\n",
    "game.make_action(random.choice(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2065135d-48a4-46bc-bf99-b2ee30a3ad1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "ammo [100.   0.  -1.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFE530>\n",
      "reward: 0.0\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC708F0>\n",
      "reward: 2.9524078369140625\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9162F0>\n",
      "reward: -9.894577026367188\n",
      "ammo [64.  0. 52.  0. 36.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB819F0>\n",
      "reward: -8.983779907226562\n",
      "ammo [40.  0. 52.  0. 60.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC602B0>\n",
      "reward: -0.0712127685546875\n",
      "ammo [40.  0. 52.  0. 60.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9162F0>\n",
      "reward: 0.8306884765625\n",
      "ammo [40.  0. 52.  0. 60.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB819F0>\n",
      "reward: 0.9964752197265625\n",
      "ammo [40.  0. 52.  0. 60.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFE570>\n",
      "reward: 7.7321319580078125\n",
      "ammo [40.  0. 52.  0. 60.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFE870>\n",
      "reward: 8.092117309570312\n",
      "ammo [40.  0. 51.  0. 60.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB819F0>\n",
      "reward: -194.9780731201172\n",
      "ammo [40.  0. 51.  0. 60.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9F6AB0>\n",
      "////////////////// Result: -193.32382202148438\n",
      "reward: 0.0\n",
      "ammo [100.   0.  -1.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9162F0>\n",
      "reward: 0.0\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB819F0>\n",
      "reward: -5.3082275390625\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFE9B0>\n",
      "reward: -2.9799957275390625\n",
      "ammo [76.  0. 52.  0. 24.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9162F0>\n",
      "reward: -1.5535430908203125\n",
      "ammo [58.  0. 52.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB819F0>\n",
      "reward: -0.520843505859375\n",
      "ammo [58.  0. 52.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56C30>\n",
      "reward: -0.3513946533203125\n",
      "ammo [58.  0. 52.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9162F0>\n",
      "reward: 5.772705078125\n",
      "ammo [58.  0. 51.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 7.9485626220703125\n",
      "ammo [58.  0. 51.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56C30>\n",
      "reward: 5.7975921630859375\n",
      "ammo [58.  0. 51.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9F6AB0>\n",
      "reward: 3.9104156494140625\n",
      "ammo [58.  0. 51.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56DF0>\n",
      "reward: -6.6053314208984375\n",
      "ammo [58.  0. 50.  0. 42.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56C30>\n",
      "reward: -3.9793701171875\n",
      "ammo [28.  0. 50.  0. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFEAB0>\n",
      "reward: -0.3068389892578125\n",
      "ammo [28.  0. 50.  0. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56DF0>\n",
      "reward: -4.63189697265625\n",
      "ammo [28.  0. 50.  0. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFF170>\n",
      "reward: -9.872909545898438\n",
      "ammo [28.  0. 50.  0. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFEAB0>\n",
      "reward: -2.708526611328125\n",
      "ammo [28.  0. 50.  0. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: 1.3131103515625\n",
      "ammo [28.  0. 50.  0. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFF170>\n",
      "reward: 5.006256103515625\n",
      "ammo [28.  0. 50.  0. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: -6.144805908203125\n",
      "ammo [10.  0. 50.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: -0.0023345947265625\n",
      "ammo [10.  0. 50.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFE870>\n",
      "reward: 2.388702392578125\n",
      "ammo [10.  0. 50.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 4.7389068603515625\n",
      "ammo [10.  0. 50.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9F6AB0>\n",
      "reward: -1.83203125\n",
      "ammo [10.  0. 50.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: -6.021148681640625\n",
      "ammo [10.  0. 49.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 0.0\n",
      "ammo [10.  0. 49.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A9F6AB0>\n",
      "reward: 2.2035064697265625\n",
      "ammo [10.  0. 49.  0. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: 3.129791259765625\n",
      "ammo [ 4.  0. 49.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 5.448089599609375\n",
      "ammo [ 4.  0. 49.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EA576F0>\n",
      "reward: 3.9854888916015625\n",
      "ammo [ 4.  0. 49.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: -3.2194366455078125\n",
      "ammo [ 4.  0. 49.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: -5.13995361328125\n",
      "ammo [ 4.  0. 48.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EA576F0>\n",
      "reward: -6.0678863525390625\n",
      "ammo [ 4.  0. 48.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: -0.374847412109375\n",
      "ammo [ 4.  0. 48.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 2.60064697265625\n",
      "ammo [ 4.  0. 48.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EA576F0>\n",
      "reward: -197.49945068359375\n",
      "ammo [ 4.  0. 48.  0. 96.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFF770>\n",
      "////////////////// Result: -210.8769989013672\n",
      "reward: 0.0\n",
      "ammo [100.   0.  -1.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 0.0\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: 0.0\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90F770>\n",
      "reward: 0.4185791015625\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: -5.026397705078125\n",
      "ammo [100.   0.  52.   0.   0.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: -3.0361785888671875\n",
      "ammo [82.  0. 52.  0. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90F770>\n",
      "reward: -2.04803466796875\n",
      "ammo [82.  0. 52.  0. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFEB70>\n",
      "reward: 0.475128173828125\n",
      "ammo [82.  0. 52.  0. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: 8.139617919921875\n",
      "ammo [82.  1. 51.  1. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90F770>\n",
      "reward: 15.928604125976562\n",
      "ammo [82.  1. 51.  1. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267ECFEB70>\n",
      "reward: 12.481353759765625\n",
      "ammo [82.  1. 51.  1. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: 5.4526214599609375\n",
      "ammo [82.  1. 51.  1. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: -6.8082122802734375\n",
      "ammo [82.  1. 51.  1. 18.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A917C30>\n",
      "reward: -10.201766967773438\n",
      "ammo [28.  1. 51.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: -8.618942260742188\n",
      "ammo [28.  1. 51.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: -4.838714599609375\n",
      "ammo [28.  1. 51.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A55BD30>\n",
      "reward: -3.263916015625\n",
      "ammo [28.  1. 51.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 4.6425628662109375\n",
      "ammo [28.  1. 50.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: 6.725494384765625\n",
      "ammo [28.  1. 50.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A55BD30>\n",
      "reward: -1.9714508056640625\n",
      "ammo [28.  1. 50.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EC56B70>\n",
      "reward: 1.2204132080078125\n",
      "ammo [28.  1. 50.  1. 72.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: -3.6598663330078125\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: -3.85894775390625\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EA43D30>\n",
      "reward: -2.208465576171875\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: 4.0074310302734375\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: 5.109283447265625\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EA43D30>\n",
      "reward: 8.61383056640625\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A90C3F0>\n",
      "reward: 8.523773193359375\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002267EB4F2B0>\n",
      "reward: -195.38058471679688\n",
      "ammo [10.  1. 50.  1. 90.]\n",
      "state <vizdoom.vizdoom.GameState object at 0x000002266A92FDF0>\n",
      "////////////////// Result: -169.1827850341797\n"
     ]
    }
   ],
   "source": [
    "episodes = 3\n",
    "for e in range(episodes):\n",
    "    game.new_episode()\n",
    "    while not game.is_episode_finished():\n",
    "        satate=game.get_state()\n",
    "        state = game.get_state()\n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - ammo\n",
    "        info = state.game_variables\n",
    "        reward = game.make_action(random.choice(actions),4) # frame skip=4 time for agent to process\n",
    "        print('reward:', reward) \n",
    "        print(\"ammo\",info)\n",
    "        print(\"state\",state)\n",
    "        time.sleep(0.02)\n",
    "    print('////////////////// Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f85591b-2316-427f-abf2-547235c29511",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae116f9-e4f4-4b30-9cbb-19380653cd31",
   "metadata": {},
   "source": [
    "## Converting it to a Gymnasium Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1caf887e-2ffa-4a19-b0db-3e1819022ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fda975-185b-4cee-ae5a-1656d22e4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config(r'./scenarios/deadly_corridor.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd41c426-f0c3-4fdb-b18b-39e67dd964c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [19, 19, 11, ..., 47, 47, 55],\n",
       "        [19, 27, 19, ..., 47, 47, 47],\n",
       "        [11, 19, 19, ..., 27, 19, 19]],\n",
       "\n",
       "       [[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [19, 19, 11, ..., 47, 47, 55],\n",
       "        [19, 27, 19, ..., 47, 47, 47],\n",
       "        [11, 19, 19, ..., 27, 19, 19]],\n",
       "\n",
       "       [[23, 35, 11, ..., 23, 35, 11],\n",
       "        [23, 11, 35, ..., 11, 35, 35],\n",
       "        [35, 35, 35, ..., 11, 35, 11],\n",
       "        ...,\n",
       "        [19, 19, 11, ..., 47, 47, 55],\n",
       "        [19, 27, 19, ..., 47, 47, 47],\n",
       "        [11, 19, 19, ..., 27, 19, 19]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_state().screen_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09d280e-917b-4046-a12f-8c66c105997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(Env):\n",
    "    def __init__(self, render=False,config='./scenarios/deadly_corridor-skill-1.cfg'):\n",
    "        super().__init__()\n",
    "        self.game = vzd.DoomGame()\n",
    "        self.game.load_config(config)\n",
    "\n",
    "        # Render frame logic\n",
    "        if not render:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        self.game.init()\n",
    "\n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(7)  # 7 possible actions\n",
    "        self.actions=np.identity(7, dtype=np.float32)\n",
    "        \n",
    "\n",
    "\n",
    "    def custom_reward(self, prev_state, current_state):\n",
    "        reward = 0\n",
    "    \n",
    "        # Extract game variables\n",
    "        prev_health = prev_state.game_variables[0]  # HEALTH\n",
    "        prev_hits = prev_state.game_variables[1]  # HITCOUNT\n",
    "        prev_ammo = prev_state.game_variables[2]  # SELECTED_WEAPON_AMMO\n",
    "        prev_kills = prev_state.game_variables[3]  # KILLCOUNT\n",
    "        prev_dmg = prev_state.game_variables[4]  # damage_taken\n",
    "        prev_dmg_deal = prev_state.game_variables[5]  # damage_dealed\n",
    "        \n",
    "        current_health = current_state.game_variables[0]  # HEALTH\n",
    "        current_hits = current_state.game_variables[1]  # HITCOUNT\n",
    "        current_ammo = current_state.game_variables[2]  # SELECTED_WEAPON_AMMO\n",
    "        current_kills = current_state.game_variables[3]  # KILLCOUNT\n",
    "        current_dmg = current_state.game_variables[4]  # damage_taken\n",
    "        current_dmg_deal = current_state.game_variables[5]  # damage_dealed\n",
    "        \n",
    "        ammo_delta=current_ammo-prev_ammo \n",
    "        hitcount_delta= current_dmg_deal - prev_dmg_deal\n",
    "        damage_taken_delta=-current_dmg+prev_dmg\n",
    "        \n",
    "        reward = damage_taken_delta*50 + hitcount_delta*200  + ammo_delta*40 \n",
    "        \n",
    "    \n",
    "\n",
    "        return reward\n",
    "        \n",
    "    def step(self, action):\n",
    "        prev_state = self.game.get_state()  # Store the previous state\n",
    "        reward = self.game.make_action(self.actions[action], 4)  # Default reward\n",
    "        current_state = self.game.get_state()  # Get the current state\n",
    "\n",
    "        # Compute custom reward\n",
    "        if prev_state is not None and current_state is not None:\n",
    "            reward += self.custom_reward(prev_state, current_state)\n",
    "\n",
    "        terminated = self.game.is_episode_finished()\n",
    "        truncated = self.game.get_episode_time() >= self.game.get_episode_timeout()\n",
    "\n",
    "        state = np.zeros(self.observation_space.shape, dtype=np.uint8)  # Default blank state\n",
    "        info = {\"ammo\": 0}  # Default info\n",
    "\n",
    "        if not (terminated or truncated):\n",
    "            game_state = self.game.get_state()\n",
    "            if game_state is not None:\n",
    "                state = self.grayscale(game_state.screen_buffer)\n",
    "                info = {\"ammo\": game_state.game_variables[0]}\n",
    "\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Restart the game and return the initial state.\"\"\"\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state), {}\n",
    "\n",
    "    def grayscale(self, observation):\n",
    "        \"\"\"Convert the observation to grayscale and resize it.\"\"\"\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))\n",
    "        return state\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the game.\"\"\"\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06a5fd-a6a4-4c23-ac86-c567498bfb22",
   "metadata": {},
   "source": [
    "### REWARD FUNCTION EXPLAINED\n",
    "<u> **IN STEP FUNCTION:** </u><br>\n",
    "**prev_state = self.game.get_state()** *Store the previous state*<br>\n",
    "**reward = self.game.make_action(self.actions[action], 4)** *DEFAULT REWARD: -200 FOR DEATH -dx for going back +dx for going forward*<br>\n",
    "**current_state = self.game.get_state()** *Get the current state*<br>\n",
    "<br>\n",
    "<i style=\"color:red\"> the `prev_state` and `current_state` values are sent to the `custom_reward` fucntion which return a reward added to the default one </i><br>\n",
    "<u> **IN custom_reward FUNCTION:** </u><br>\n",
    "1. current_health = current_state.game_variables[0]  # HEALTH\n",
    "2. current_hits = current_state.game_variables[1]  # HITCOUNT\n",
    "3. current_ammo = current_state.game_variables[2]  # SELECTED_WEAPON_AMMO\n",
    "4. current_kills = current_state.game_variables[3]  # KILLCOUNT\n",
    "5. current_dmg = current_state.game_variables[4]  # damage_taken\n",
    "6. current_dmg_deal = current_state.game_variables[5]  # damage_dealed\n",
    "\n",
    "<br>**we calculate deltas** :<br>\n",
    "1. ammo_delta=current_ammo-prev_ammo\n",
    "2. hitcount_delta= current_dmg_deal - prev_dmg_deal\n",
    "3. damage_taken_delta=-current_dmg+prev_dmg<br>\n",
    "\n",
    "<b style=\"color:red\">REWARD:<BR>\n",
    "`reward = damage_taken_delta*50 + hitcount_delta*200  + ammo_delta*40`\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16314fc-d019-4ea9-ba04-aa4ccfef8706",
   "metadata": {},
   "source": [
    "<h4 style=\"color: red\">CURRICULUM LEARNING approach</h4><br>\n",
    "\n",
    "**IN ORDER TO GET THE AGENT TO BE ABLE TO PLAY THE VIZDOOM GAME WITH `DIFFICULTY LEVEL:` *5* WE STARTED TRAINING THE AGENT ON THE `DIFFICULTY LEVEL` *1* AND WE WENT UP ON LEVEL FOR THIS PURPOSE WE CREATED 5 ENVIROMENT:** <BR>\n",
    "1. `deadly_corridor-skill-1.cfg` FOR `SKILL LEVEL 1`.\n",
    "2. `deadly_corridor-skill-2.cfg` FOR `SKILL LEVEL 2`.\n",
    "3. `deadly_corridor-skill-3.cfg` FOR `SKILL LEVEL 3`.\n",
    "4. `deadly_corridor-skill-4.cfg` FOR `SKILL LEVEL 4`.\n",
    "5. `deadly_corridor-skill-5.cfg` FOR `SKILL LEVEL 5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3755e98d-e002-4dc1-873d-e51d231b8c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[32]\n",
      "  [33]\n",
      "  [25]\n",
      "  ...\n",
      "  [27]\n",
      "  [23]\n",
      "  [24]]\n",
      "\n",
      " [[27]\n",
      "  [33]\n",
      "  [23]\n",
      "  ...\n",
      "  [24]\n",
      "  [24]\n",
      "  [24]]\n",
      "\n",
      " [[20]\n",
      "  [35]\n",
      "  [23]\n",
      "  ...\n",
      "  [24]\n",
      "  [24]\n",
      "  [24]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[75]\n",
      "  [63]\n",
      "  [62]\n",
      "  ...\n",
      "  [44]\n",
      "  [71]\n",
      "  [60]]\n",
      "\n",
      " [[15]\n",
      "  [48]\n",
      "  [47]\n",
      "  ...\n",
      "  [49]\n",
      "  [69]\n",
      "  [47]]\n",
      "\n",
      " [[22]\n",
      "  [14]\n",
      "  [26]\n",
      "  ...\n",
      "  [57]\n",
      "  [37]\n",
      "  [39]]]\n"
     ]
    }
   ],
   "source": [
    "env = VizDoomGym(render=True)\n",
    "state,_ = env.reset()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfbe9306-b876-4d1d-bb64-d85840daa6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "287ad23b-4c6e-41ff-979e-f5f43f95a724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[32],\n",
       "         [33],\n",
       "         [25],\n",
       "         ...,\n",
       "         [27],\n",
       "         [23],\n",
       "         [24]],\n",
       " \n",
       "        [[27],\n",
       "         [33],\n",
       "         [23],\n",
       "         ...,\n",
       "         [24],\n",
       "         [24],\n",
       "         [24]],\n",
       " \n",
       "        [[20],\n",
       "         [35],\n",
       "         [23],\n",
       "         ...,\n",
       "         [24],\n",
       "         [24],\n",
       "         [24]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[75],\n",
       "         [63],\n",
       "         [62],\n",
       "         ...,\n",
       "         [44],\n",
       "         [71],\n",
       "         [60]],\n",
       " \n",
       "        [[15],\n",
       "         [48],\n",
       "         [47],\n",
       "         ...,\n",
       "         [49],\n",
       "         [69],\n",
       "         [47]],\n",
       " \n",
       "        [[22],\n",
       "         [14],\n",
       "         [26],\n",
       "         ...,\n",
       "         [57],\n",
       "         [37],\n",
       "         [39]]], dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3cb7dcc6-7492-4b35-bcbf-c5850e19b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d07f8dd8-7689-4dd4-a3fc-c17ed11941cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f5a8e20-5b3f-4f2c-8406-378056e5de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a252c1e290>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe80e7-a5d8-47bb-96aa-52db364137ac",
   "metadata": {},
   "source": [
    "### this is the grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236d716c-593f-4734-a553-cdc2ada4930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e43627cd-2e12-41f7-a9fc-f7f275a5fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_Deadly_Corridor'\n",
    "LOG_DIR = './logs/log_Deadly_Corridor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab49e155-c2bf-4413-a885-210d9e01ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24342e15-04e5-4fcd-bf4d-ed1f67d0f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f80219f-c53b-4623-b8c7-6661fafe4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.00001, n_steps=8192, clip_range=.1, gamma=.95, gae_lambda=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dbe6ee-cfab-4afc-a0f2-c86a7bf7ca6b",
   "metadata": {},
   "source": [
    "## Training phase 1\n",
    "`200000 steps`<br>\n",
    "**LOG: PPO_7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4941fe82-1dbe-4dd6-aa62-169bba279fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_Deadly_Corridor\\PPO_7\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 1.67e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 634      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 238          |\n",
      "|    ep_rew_mean          | 1.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1355         |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033908342 |\n",
      "|    clip_fraction        | 0.213        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0137       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 2.47e+04     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | 0.000996     |\n",
      "|    value_loss           | 7.65e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 243          |\n",
      "|    ep_rew_mean          | 1.83e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2018         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041395277 |\n",
      "|    clip_fraction        | 0.267        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.19e+04     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -7.51e-05    |\n",
      "|    value_loss           | 8.79e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 224          |\n",
      "|    ep_rew_mean          | 1.93e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2681         |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036160173 |\n",
      "|    clip_fraction        | 0.242        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.12e+04     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | 0.00195      |\n",
      "|    value_loss           | 9.17e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 227          |\n",
      "|    ep_rew_mean          | 2.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3344         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037462548 |\n",
      "|    clip_fraction        | 0.282        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0811       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.05e+04     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -5.98e-05    |\n",
      "|    value_loss           | 9.84e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 196          |\n",
      "|    ep_rew_mean          | 2e+03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 3999         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033803033 |\n",
      "|    clip_fraction        | 0.224        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.74e+04     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 0.00196      |\n",
      "|    value_loss           | 1.02e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 141          |\n",
      "|    ep_rew_mean          | 2.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 4669         |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054225386 |\n",
      "|    clip_fraction        | 0.226        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.64e+04     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | 0.00126      |\n",
      "|    value_loss           | 1.18e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 126          |\n",
      "|    ep_rew_mean          | 1.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5331         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036614165 |\n",
      "|    clip_fraction        | 0.238        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.4e+04      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | 0.000329     |\n",
      "|    value_loss           | 1.58e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 120         |\n",
      "|    ep_rew_mean          | 1.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6000        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003545903 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.56e+04    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.000986    |\n",
      "|    value_loss           | 1.28e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 134         |\n",
      "|    ep_rew_mean          | 2.46e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 6693        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005272057 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.08e+04    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    value_loss           | 1.37e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | 2.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 7367        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004179337 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.76e+05    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.00234     |\n",
      "|    value_loss           | 1.77e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 131          |\n",
      "|    ep_rew_mean          | 1.95e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 8086         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052388282 |\n",
      "|    clip_fraction        | 0.256        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.95e+04     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | 0.00123      |\n",
      "|    value_loss           | 1.42e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.1         |\n",
      "|    ep_rew_mean          | 2.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 8841         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063336897 |\n",
      "|    clip_fraction        | 0.266        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.82e+04     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.00162      |\n",
      "|    value_loss           | 1.31e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 111          |\n",
      "|    ep_rew_mean          | 2.7e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 9656         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054373317 |\n",
      "|    clip_fraction        | 0.301        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.55e+04     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000714    |\n",
      "|    value_loss           | 2.03e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 115          |\n",
      "|    ep_rew_mean          | 2.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 8            |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 13948        |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053608837 |\n",
      "|    clip_fraction        | 0.296        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.65e+04     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 0.00279      |\n",
      "|    value_loss           | 1.68e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 2.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 14633       |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006138148 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.39e+04    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    value_loss           | 1.58e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 136          |\n",
      "|    ep_rew_mean          | 2.91e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 15367        |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061025806 |\n",
      "|    clip_fraction        | 0.327        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.09e+04     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 0.00334      |\n",
      "|    value_loss           | 1.37e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 158          |\n",
      "|    ep_rew_mean          | 3.38e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 16103        |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043241484 |\n",
      "|    clip_fraction        | 0.276        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 6.71e+04     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.00216      |\n",
      "|    value_loss           | 1.64e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 192        |\n",
      "|    ep_rew_mean          | 3.56e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 9          |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 16833      |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00522214 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 3.61e+04   |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | 0.00413    |\n",
      "|    value_loss           | 1.14e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 239         |\n",
      "|    ep_rew_mean          | 3.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 17562       |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007631152 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.72e+04    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.00875     |\n",
      "|    value_loss           | 8.86e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 246          |\n",
      "|    ep_rew_mean          | 3.48e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 18288        |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063081463 |\n",
      "|    clip_fraction        | 0.312        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 3.78e+04     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | 0.00453      |\n",
      "|    value_loss           | 6.52e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 260          |\n",
      "|    ep_rew_mean          | 3.88e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 19004        |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044294763 |\n",
      "|    clip_fraction        | 0.268        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.21e+05     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | 0.00199      |\n",
      "|    value_loss           | 1.2e+05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 252         |\n",
      "|    ep_rew_mean          | 4.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 19687       |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007035315 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 5.08e+04    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.00315     |\n",
      "|    value_loss           | 1.09e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 275          |\n",
      "|    ep_rew_mean          | 3.93e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 20456        |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058542397 |\n",
      "|    clip_fraction        | 0.34         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 4.73e+04     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | 0.00509      |\n",
      "|    value_loss           | 8.39e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 270         |\n",
      "|    ep_rew_mean          | 4.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 21784       |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006301777 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.69e+04    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.00385     |\n",
      "|    value_loss           | 7.62e+04    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=200000, callback=callback)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6db91-fe8e-4e62-bec1-1eb3677dc435",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "258b6917-f158-4b1d-9ecf-89825c069b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PPO.load(\"./train/train_deadly_corridor/best_model_90000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d89d6f2e-9535-40d1-afea-baf5078e6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3dfc4d3-776f-4077-b0e8-b5703f494c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 2389.7539672851562\n",
      "Episode 2: Total Reward = 1955.1833953857422\n",
      "Episode 3: Total Reward = 3634.187210083008\n",
      "Episode 4: Total Reward = 2469.2147827148438\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_deadly_corridor/best_model_90000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ee137-1233-4f9f-a467-5a580f4fdd84",
   "metadata": {},
   "source": [
    "## The model is not learning to go further in the dangeon and is losing amo so we will increase penalty on amo and hitcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d7b24c4-b6dc-4539-9344-3f7f1cff3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./train/train_deadly_corridor/best_model_230000.zip\"  \n",
    "model = PPO.load(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f21caf-b961-4d9f-9cf5-37a5b868b201",
   "metadata": {},
   "source": [
    "## Training phase 2\n",
    "`10000 steps`<br>\n",
    "**LOG: PPO_8**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78fd521-3fd5-4d03-98db-713b688875dc",
   "metadata": {},
   "source": [
    "## RETRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b238a6d-7253-4c82-9553-e97cd198db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()\n",
    "CHECKPOINT_DIR = './train/train_Deadly_Corridor_COMP'\n",
    "LOG_DIR = './logs/log_Deadly_Corridor'\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b175e9c-fcbe-43d8-bf4b-c9c727a5c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95ec7055-b9e3-4acf-b4af-1c5de31d3068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_Deadly_Corridor\\PPO_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | 1.61e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 635      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | 2.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1344        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004817075 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 6.47e+04    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.00375     |\n",
      "|    value_loss           | 1.34e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | 2.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2062        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009281473 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.04e+05    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.00493     |\n",
      "|    value_loss           | 1.5e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 268         |\n",
      "|    ep_rew_mean          | 3.04e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2747        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004674851 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.69e+04    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.00414     |\n",
      "|    value_loss           | 1.51e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 260          |\n",
      "|    ep_rew_mean          | 3.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3416         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066747386 |\n",
      "|    clip_fraction        | 0.331        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.69        |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.18e+05     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 0.00363      |\n",
      "|    value_loss           | 1.79e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 257         |\n",
      "|    ep_rew_mean          | 4.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4114        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006923997 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.19e+04    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.00652     |\n",
      "|    value_loss           | 1.59e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 248         |\n",
      "|    ep_rew_mean          | 4.91e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4822        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006640624 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.98e+04    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.00442     |\n",
      "|    value_loss           | 1.95e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 223          |\n",
      "|    ep_rew_mean          | 5.23e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5535         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060602324 |\n",
      "|    clip_fraction        | 0.332        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.73e+05     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.00507      |\n",
      "|    value_loss           | 2.33e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 238         |\n",
      "|    ep_rew_mean          | 5.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6307        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007349992 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 4.17e+04    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00435     |\n",
      "|    value_loss           | 2.21e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 240         |\n",
      "|    ep_rew_mean          | 6.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 6994        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007393822 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.35e+05    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.00338     |\n",
      "|    value_loss           | 2.12e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 235          |\n",
      "|    ep_rew_mean          | 6.34e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 11           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 7667         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061069047 |\n",
      "|    clip_fraction        | 0.324        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.52e+04     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 0.00515      |\n",
      "|    value_loss           | 2.34e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 226         |\n",
      "|    ep_rew_mean          | 6.39e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 8399        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008551437 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.67e+05    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00655     |\n",
      "|    value_loss           | 2.42e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 234         |\n",
      "|    ep_rew_mean          | 6.71e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 9115        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008031023 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.49e+05    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.00643     |\n",
      "|    value_loss           | 2.3e+05     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2239bcecc90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0c7c2-22e8-4715-aab8-75d6ee3b26a6",
   "metadata": {},
   "source": [
    "**PPO 4 7 8** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0726a-94bc-47b1-ae93-515693dab53a",
   "metadata": {},
   "source": [
    "#### Testing again `./train/train_Deadly_Corridor_COMP/best_model_100000.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c73271-5537-478d-adb9-bd2e2448bd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 80.13021850585938\n",
      "Episode 2: Total Reward = 7222.541305541992\n",
      "Episode 3: Total Reward = 8597.309310913086\n",
      "Episode 4: Total Reward = 13160.359771728516\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP/best_model_100000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6e929-da57-4988-a6e1-886023c55a90",
   "metadata": {},
   "source": [
    "### The agent need more training \n",
    "`from 4 trails it hits the goal one time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e71d7b57-8dd5-494c-a52f-24fcd567a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./train/train_deadly_corridor/best_model_230000.zip\"  \n",
    "model = PPO.load(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afb5e5-76cb-409b-b31f-b0e88fce1168",
   "metadata": {},
   "source": [
    "## Training phase 3\n",
    "`10000 steps`<br>\n",
    "**LOG: PPO_9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e9f463-65be-48d0-a78e-e60118fbe9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()\n",
    "CHECKPOINT_DIR = './train/train_Deadly_Corridor_COMP_2'\n",
    "LOG_DIR = './logs/log_Deadly_Corridor'\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333feb68-c44e-47f4-be29-11abb554fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141f7f6c-1f4a-452e-9041-42c0dbd3e78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_Deadly_Corridor\\PPO_9\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 264      |\n",
      "|    ep_rew_mean     | 2.65e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 13       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 625      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 257         |\n",
      "|    ep_rew_mean          | 2.68e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1346        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006551397 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.18e+04    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.00372     |\n",
      "|    value_loss           | 1.55e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 271          |\n",
      "|    ep_rew_mean          | 3.25e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2013         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052532405 |\n",
      "|    clip_fraction        | 0.314        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.71e+04     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | 0.00386      |\n",
      "|    value_loss           | 1.73e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 290         |\n",
      "|    ep_rew_mean          | 3.46e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2699        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006595634 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.9e+05     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.00435     |\n",
      "|    value_loss           | 1.81e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 294         |\n",
      "|    ep_rew_mean          | 4.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3378        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008789311 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.76e+04    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.00472     |\n",
      "|    value_loss           | 1.28e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 321          |\n",
      "|    ep_rew_mean          | 4.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 4050         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076245796 |\n",
      "|    clip_fraction        | 0.359        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 8.18e+04     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | 0.00293      |\n",
      "|    value_loss           | 1.86e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 323         |\n",
      "|    ep_rew_mean          | 5.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4726        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007913362 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.11e+04    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.00641     |\n",
      "|    value_loss           | 1.55e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 300          |\n",
      "|    ep_rew_mean          | 5.57e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5397         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060549984 |\n",
      "|    clip_fraction        | 0.35         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.6e+05      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.00266      |\n",
      "|    value_loss           | 1.77e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 298         |\n",
      "|    ep_rew_mean          | 5.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6065        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007089996 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 8.62e+04    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00347     |\n",
      "|    value_loss           | 2e+05       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 303          |\n",
      "|    ep_rew_mean          | 5.67e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 6776         |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054159905 |\n",
      "|    clip_fraction        | 0.342        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.46e+05     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | 0.00396      |\n",
      "|    value_loss           | 1.72e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 306         |\n",
      "|    ep_rew_mean          | 5.91e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 9759        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008499951 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.39e+04    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.0052      |\n",
      "|    value_loss           | 1.36e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 303          |\n",
      "|    ep_rew_mean          | 6.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 10457        |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074064415 |\n",
      "|    clip_fraction        | 0.394        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.15e+05     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | 0.00275      |\n",
      "|    value_loss           | 1.62e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 289          |\n",
      "|    ep_rew_mean          | 6.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 11131        |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089059025 |\n",
      "|    clip_fraction        | 0.368        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.68e+04     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.00363      |\n",
      "|    value_loss           | 1.82e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2055349f610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ce386-c436-4b5d-86ee-d6e08f35c724",
   "metadata": {},
   "source": [
    "**Testing The new model:** `./train/train_Deadly_Corridor_COMP_2/best_model_90000.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3483a87-0ede-48f8-b77f-bf68a5dc0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 13140.322280883789\n",
      "Episode 2: Total Reward = 2121.351348876953\n",
      "Episode 3: Total Reward = 5939.368347167969\n",
      "Episode 4: Total Reward = 4392.720138549805\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP_2/best_model_90000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a88523-ba4a-4208-a105-6856bb786261",
   "metadata": {},
   "source": [
    "## Training phase 4\n",
    "`100000 steps`<br>\n",
    "**LOG: PPO_10**<br>\n",
    "<b style=\"color:red\">NEW REWARD</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac9a8b-1fe6-40e7-b5ea-fd96342892d6",
   "metadata": {},
   "source": [
    "**The agent is losing too much amo, but overall it's better** <br>\n",
    "**changing the reward system and retraining**<br>\n",
    "*old:*<br>\n",
    "`reward = damage_taken_delta*40 + hitcount_delta*200  + ammo_delta*20 `<br>\n",
    "*new:*<br>\n",
    "`reward = damage_taken_delta*50 + hitcount_delta*200  + ammo_delta*40`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e6536d-81df-4165-b856-e7bbf2ac1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./train/train_Deadly_Corridor_COMP_2/best_model_90000.zip\"  \n",
    "model = PPO.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c5f5b21-1ab1-4c59-ba92-92a59c9d600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()\n",
    "CHECKPOINT_DIR = './train/train_Deadly_Corridor_COMP_3'\n",
    "LOG_DIR = './logs/log_Deadly_Corridor'\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "699c8adf-608d-4d7c-80e4-70d69006d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "570d17c6-0703-49d6-832e-204d7c386b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_Deadly_Corridor\\PPO_10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 290      |\n",
      "|    ep_rew_mean     | 5.53e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 631      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 275        |\n",
      "|    ep_rew_mean          | 5.49e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1279       |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00971652 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.66      |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 1e+05      |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | 0.00388    |\n",
      "|    value_loss           | 2.04e+05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 280          |\n",
      "|    ep_rew_mean          | 5.6e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1933         |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071094697 |\n",
      "|    clip_fraction        | 0.345        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.07e+05     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | 0.00505      |\n",
      "|    value_loss           | 2.25e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 278         |\n",
      "|    ep_rew_mean          | 5.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2621        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008092662 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 7.77e+04    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00584     |\n",
      "|    value_loss           | 2.08e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 6.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3405        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012907546 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.41e+05    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.00944     |\n",
      "|    value_loss           | 2.32e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 280          |\n",
      "|    ep_rew_mean          | 7.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 10           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 4628         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070082885 |\n",
      "|    clip_fraction        | 0.356        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.34e+05     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | 0.00486      |\n",
      "|    value_loss           | 2.21e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 282       |\n",
      "|    ep_rew_mean          | 7.63e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 10        |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 5417      |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0093648 |\n",
      "|    clip_fraction        | 0.403     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.55     |\n",
      "|    explained_variance   | 0.462     |\n",
      "|    learning_rate        | 1e-05     |\n",
      "|    loss                 | 7.43e+04  |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | 0.00739   |\n",
      "|    value_loss           | 2.23e+05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 8.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 6844        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013586832 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9e+04       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00752     |\n",
      "|    value_loss           | 2.35e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 257         |\n",
      "|    ep_rew_mean          | 8.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 7586        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011431741 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.33e+05    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.00852     |\n",
      "|    value_loss           | 2.56e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 240         |\n",
      "|    ep_rew_mean          | 8.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 8298        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009895762 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.69e+05    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00739     |\n",
      "|    value_loss           | 2.68e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 249          |\n",
      "|    ep_rew_mean          | 8.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 9060         |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120725185 |\n",
      "|    clip_fraction        | 0.38         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.2e+05      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.0121       |\n",
      "|    value_loss           | 2.64e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 276         |\n",
      "|    ep_rew_mean          | 8.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 9870        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011180749 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.27e+04    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00864     |\n",
      "|    value_loss           | 2.06e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 300          |\n",
      "|    ep_rew_mean          | 8.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 9            |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 10655        |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112755615 |\n",
      "|    clip_fraction        | 0.39         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.58e+05     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | 0.00715      |\n",
      "|    value_loss           | 1.94e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x20557fde750>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aa427-965b-4d2e-bc4b-8d645a389776",
   "metadata": {},
   "source": [
    "**Testing The new model:** `./train/train_Deadly_Corridor_COMP_3/best_model_90000.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df110f4-aed6-43b8-9a31-deca938b7f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 15657.062576293945\n",
      "Episode 2: Total Reward = 6334.014587402344\n",
      "Episode 3: Total Reward = 9659.362380981445\n",
      "Episode 4: Total Reward = 1125.349624633789\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP_3/best_model_90000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4037cd-6bb0-46f6-8953-813ca89b5c8d",
   "metadata": {},
   "source": [
    "**The agent need more training**\n",
    "`from 4 trails it hits the goal 3 times`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2262a0-3f88-406b-ad43-bc1b313c2046",
   "metadata": {},
   "source": [
    "## Training phase 5\n",
    "`10000 steps`<br>\n",
    "**LOG: PPO_11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f89c0808-a7ce-47a4-b02f-d16f8677d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./train/train_Deadly_Corridor_COMP_3/best_model_90000.zip\"  \n",
    "model = PPO.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "812c5669-14df-4687-b76b-c5d4969e848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()\n",
    "CHECKPOINT_DIR = './train/train_Deadly_Corridor_COMP_4'\n",
    "LOG_DIR = './logs/log_Deadly_Corridor'\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef3e0d2c-2b71-4c61-8a63-fc2834600892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4513c6c1-1c18-4068-8060-5307523f5b44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_Deadly_Corridor\\PPO_11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 292      |\n",
      "|    ep_rew_mean     | 9.61e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 655      |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 314         |\n",
      "|    ep_rew_mean          | 9.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1379        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011990368 |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.12e+04    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 2.13e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 298         |\n",
      "|    ep_rew_mean          | 9.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2143        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010903351 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.62e+05    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.00773     |\n",
      "|    value_loss           | 1.9e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 302         |\n",
      "|    ep_rew_mean          | 9.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2820        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011324152 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.95e+05    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    value_loss           | 2.43e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 9.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3522        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012878532 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.41e+05    |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    value_loss           | 2.21e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 312        |\n",
      "|    ep_rew_mean          | 9.8e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 11         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 4327       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01165624 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | 0.49       |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 5.78e+04   |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | 0.00728    |\n",
      "|    value_loss           | 1.93e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 1.02e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 5124        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012682414 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.55e+04    |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | 0.00766     |\n",
      "|    value_loss           | 2.08e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 259         |\n",
      "|    ep_rew_mean          | 9.94e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 5829        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011853855 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.74e+05    |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    value_loss           | 2.89e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 231         |\n",
      "|    ep_rew_mean          | 1.04e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6539        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011589485 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 2.11e+05    |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | 0.00908     |\n",
      "|    value_loss           | 2.53e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 239         |\n",
      "|    ep_rew_mean          | 1.08e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 7315        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013735116 |\n",
      "|    clip_fraction        | 0.42        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 9.51e+04    |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    value_loss           | 2.53e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 222         |\n",
      "|    ep_rew_mean          | 1.04e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 8016        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008817939 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.07e+05    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    value_loss           | 2.25e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 220         |\n",
      "|    ep_rew_mean          | 1.09e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 8691        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011926552 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.23e+05    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | 0.0096      |\n",
      "|    value_loss           | 2.84e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 210         |\n",
      "|    ep_rew_mean          | 1.1e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 9362        |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013010536 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.25e+05    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    value_loss           | 2.81e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x20557e0cbd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a7f14-7c39-4068-b53c-79e1171e88a1",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d95c46d6-1407-4b3e-8328-4cd59169cc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 17079.532836914062\n",
      "Episode 2: Total Reward = 11199.851608276367\n",
      "Episode 3: Total Reward = 12779.037246704102\n",
      "Episode 4: Total Reward = 7574.6090087890625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP_4/best_model_90000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e3f92-47db-4af0-9572-59908d82b776",
   "metadata": {},
   "source": [
    "**the agent is not killing the last enemy sometimes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8a72b76-2cf8-4e10-b24e-df8373e97d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 4210.972625732422\n",
      "Episode 2: Total Reward = 11697.345169067383\n",
      "Episode 3: Total Reward = 14136.524642944336\n",
      "Episode 4: Total Reward = 6652.1153564453125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN, PPO \n",
    "import cv2\n",
    "\n",
    "\n",
    "model_path = \"./train/train_Deadly_Corridor_COMP_4/best_model_70000.zip\"  \n",
    "model = PPO.load(model_path)\n",
    "\n",
    "\n",
    "env = VizDoomGym(render=True)  \n",
    "num_episodes = 4\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    obs,_ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        time.sleep(0.10)\n",
    "        total_reward += reward\n",
    "        done=terminated or truncated\n",
    "        # time.sleep(1)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    time.sleep(2)\n",
    "  \n",
    "# Close environment\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1866ab3-285a-46b8-a9a8-a91a79b12d28",
   "metadata": {},
   "source": [
    "### WE CHOOSE THIS MODEL DUE TO THE OBSERVATION OF `EP_REW_MEAN` AND `EP_LEN_MEAN`\n",
    "<img src=\"./Screenshot 2025-03-06 231351.png\"/>\n",
    "<img src=\"./Screenshot 2025-03-06 231409.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b67a76f-3d3e-4d23-88de-d428038c4bda",
   "metadata": {},
   "source": [
    "**The model `./train/train_Deadly_Corridor_COMP_4/best_model_80000.zip` is the gest**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
